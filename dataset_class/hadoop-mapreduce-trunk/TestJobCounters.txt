Location: TestJobCounters.java

Content: 

public static JobConf createConfiguration() throws IOException {

  JobConf baseConf=new JobConf(TestJobCounters.class);

  baseConf.setOutputKeyClass(Text.class);

  baseConf.setOutputValueClass(IntWritable.class);

  baseConf.setMapperClass(WordCount.MapClass.class);

  baseConf.setCombinerClass(WordCount.Reduce.class);

  baseConf.setReducerClass(WordCount.Reduce.class);

  baseConf.setNumReduceTasks(1);

  baseConf.setInt(JobContext.IO_SORT_MB,1);

  baseConf.set(JobContext.MAP_SORT_SPILL_PERCENT,"0.50");

  baseConf.setInt(JobContext.MAP_COMBINE_MIN_SPILLS,3);

  return baseConf;

}

Location: TestJobCounters.java

Content: 

public static Job createJob() throws IOException {

  final Configuration conf=new Configuration();

  final Job baseJob=Job.getInstance(new Cluster(conf),conf);

  baseJob.setOutputKeyClass(Text.class);

  baseJob.setOutputValueClass(IntWritable.class);

  baseJob.setMapperClass(NewMapTokenizer.class);

  baseJob.setCombinerClass(NewSummer.class);

  baseJob.setReducerClass(NewSummer.class);

  baseJob.setNumReduceTasks(1);

  baseJob.getConfiguration().setInt(JobContext.IO_SORT_MB,1);

  baseJob.getConfiguration().set(JobContext.MAP_SORT_SPILL_PERCENT,"0.50");

  baseJob.getConfiguration().setInt(JobContext.MAP_COMBINE_MIN_SPILLS,3);

  org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setMinInputSplitSize(baseJob,Long.MAX_VALUE);

  return baseJob;

}

Location: TestJobCounters.java

Content: 

private static void createWordsFile(Path inpFile,Configuration conf) throws IOException {

  final FileSystem fs=inpFile.getFileSystem(conf);

  if (fs.exists(inpFile)) {

    return;

  }

  FSDataOutputStream out=fs.create(inpFile);

  try {

    int REPLICAS=5, NUMLINES=1024, NUMWORDSPERLINE=4;

    final String WORD="zymurgy";

    final Formatter fmt=new Formatter(new StringBuilder());

    for (int i=0; i < REPLICAS; i++) {

      for (int j=1; j <= NUMLINES * NUMWORDSPERLINE; j+=NUMWORDSPERLINE) {

        ((StringBuilder)fmt.out()).setLength(0);

        for (int k=0; k < NUMWORDSPERLINE; ++k) {

          fmt.format("%s%04d ",WORD,j + k);

        }

        ((StringBuilder)fmt.out()).append("\n");

        out.writeBytes(fmt.toString());

      }

    }

  }

  finally {

    out.close();

  }

}

Location: TestJobCounters.java

Content: 

@SuppressWarnings("deprecation") private long getTaskCounterUsage(JobClient client,JobID id,int numReports,int taskId,TaskType type) throws Exception {

  TaskReport[] reports=null;

  if (TaskType.MAP.equals(type)) {

    reports=client.getMapTaskReports(id);

  }

 else   if (TaskType.REDUCE.equals(type)) {

    reports=client.getReduceTaskReports(id);

  }

  assertNotNull("No reports found for task type '" + type.name() + "' in job "+ id,reports);

  assertEquals("Mismatch in task id",numReports,reports.length);

  Counters counters=reports[taskId].getCounters();

  return counters.getCounter(TaskCounter.COMMITTED_HEAP_BYTES);

}

Location: TestJobCounters.java

Content: 

@BeforeClass public static void initPaths() throws IOException {

  final Configuration conf=new Configuration();

  final Path TEST_ROOT_DIR=new Path(System.getProperty("test.build.data","/tmp"));

  testdir=new Path(TEST_ROOT_DIR,"spilledRecords.countertest");

  IN_DIR=new Path(testdir,"in");

  OUT_DIR=new Path(testdir,"out");

  FileSystem fs=FileSystem.getLocal(conf);

  testdir=new Path(TEST_ROOT_DIR,"spilledRecords.countertest");

  if (fs.exists(testdir) && !fs.delete(testdir,true)) {

    throw new IOException("Could not delete " + testdir);

  }

  if (!fs.mkdirs(IN_DIR)) {

    throw new IOException("Mkdirs failed to create " + IN_DIR);

  }

  createWordsFile(new Path(IN_DIR,"input5_2k_1"),conf);

  createWordsFile(new Path(IN_DIR,"input5_2k_2"),conf);

  createWordsFile(new Path(IN_DIR,"input5_2k_3"),conf);

}

Location: TestJobCounters.java

Content: 

private void removeWordsFile(Path inpFile,Configuration conf) throws IOException {

  final FileSystem fs=inpFile.getFileSystem(conf);

  if (fs.exists(inpFile) && !fs.delete(inpFile,false)) {

    throw new IOException("Failed to delete " + inpFile);

  }

}

Location: TestJobCounters.java

Content: 

@SuppressWarnings("deprecation") private static RunningJob runHeapUsageTestJob(JobConf conf,Path testRootDir,String heapOptions,long targetMapValue,long targetReduceValue,FileSystem fs,JobClient client,Path inDir) throws IOException {

  JobConf jobConf=new JobConf(conf);

  jobConf.setNumMapTasks(1);

  jobConf.setNumReduceTasks(1);

  jobConf.setMapperClass(MemoryLoaderMapper.class);

  jobConf.setReducerClass(MemoryLoaderReducer.class);

  jobConf.setInputFormat(TextInputFormat.class);

  jobConf.setOutputKeyClass(LongWritable.class);

  jobConf.setOutputValueClass(Text.class);

  jobConf.setMaxMapAttempts(1);

  jobConf.setMaxReduceAttempts(1);

  jobConf.set(JobConf.MAPRED_TASK_JAVA_OPTS,heapOptions);

  jobConf.setLong(MemoryLoaderMapper.TARGET_VALUE,targetMapValue);

  jobConf.setLong(MemoryLoaderReducer.TARGET_VALUE,targetReduceValue);

  FileInputFormat.setInputPaths(jobConf,inDir);

  Path outDir=new Path(testRootDir,"out");

  fs.delete(outDir,true);

  FileOutputFormat.setOutputPath(jobConf,outDir);

  RunningJob job=client.submitJob(jobConf);

  job.waitForCompletion();

  JobID jobID=job.getID();

  assertTrue("Job " + jobID + " failed!",job.isSuccessful());

  return job;

}

Location: TestJobCounters.java

Content: 

/** 

 * Tests  {@link TaskCounter}'s  {@link TaskCounter.COMMITTED_HEAP_BYTES}.  The test consists of running a low-memory job which consumes less heap  memory and then running a high-memory job which consumes more heap memory,  and then ensuring that COMMITTED_HEAP_BYTES of low-memory job is smaller  than that of the high-memory job.

 * @throws IOException

 */

@Test @SuppressWarnings("deprecation") public void testHeapUsageCounter() throws Exception {

  JobConf conf=new JobConf();

  FileSystem fileSystem=FileSystem.getLocal(conf);

  Path rootDir=new Path(System.getProperty("test.build.data","/tmp"));

  Path testRootDir=new Path(rootDir,"testHeapUsageCounter");

  fileSystem.delete(testRootDir,true);

  fileSystem.setWorkingDirectory(testRootDir);

  fileSystem.deleteOnExit(testRootDir);

  MiniMRCluster mrCluster=new MiniMRCluster(1,fileSystem.getUri().toString(),1);

  try {

    conf=mrCluster.createJobConf();

    JobClient jobClient=new JobClient(conf);

    Path inDir=new Path(testRootDir,"in");

    createWordsFile(inDir,conf);

    RunningJob lowMemJob=runHeapUsageTestJob(conf,testRootDir,"-Xms32m -Xmx1G",0,0,fileSystem,jobClient,inDir);

    JobID lowMemJobID=lowMemJob.getID();

    long lowMemJobMapHeapUsage=getTaskCounterUsage(jobClient,lowMemJobID,1,0,TaskType.MAP);

    System.out.println("Job1 (low memory job) map task heap usage: " + lowMemJobMapHeapUsage);

    long lowMemJobReduceHeapUsage=getTaskCounterUsage(jobClient,lowMemJobID,1,0,TaskType.REDUCE);

    System.out.println("Job1 (low memory job) reduce task heap usage: " + lowMemJobReduceHeapUsage);

    RunningJob highMemJob=runHeapUsageTestJob(conf,testRootDir,"-Xms32m -Xmx1G",lowMemJobMapHeapUsage + 256 * 1024 * 1024,lowMemJobReduceHeapUsage + 256 * 1024 * 1024,fileSystem,jobClient,inDir);

    JobID highMemJobID=highMemJob.getID();

    long highMemJobMapHeapUsage=getTaskCounterUsage(jobClient,highMemJobID,1,0,TaskType.MAP);

    System.out.println("Job2 (high memory job) map task heap usage: " + highMemJobMapHeapUsage);

    long highMemJobReduceHeapUsage=getTaskCounterUsage(jobClient,highMemJobID,1,0,TaskType.REDUCE);

    System.out.println("Job2 (high memory job) reduce task heap usage: " + highMemJobReduceHeapUsage);

    assertTrue("Incorrect map heap usage reported by the map task",lowMemJobMapHeapUsage < highMemJobMapHeapUsage);

    assertTrue("Incorrect reduce heap usage reported by the reduce task",lowMemJobReduceHeapUsage < highMemJobReduceHeapUsage);

  }

  finally {

    mrCluster.shutdown();

    try {

      fileSystem.delete(testRootDir,true);

    }

 catch (    IOException ioe) {

    }

  }

}

Location: TestJobCounters.java

Content: 

@Test public void testNewCounterA() throws Exception {

  final Job job=createJob();

  final Configuration conf=job.getConfiguration();

  conf.setInt(JobContext.IO_SORT_FACTOR,2);

  removeWordsFile(new Path(IN_DIR,"input5_2k_4"),conf);

  removeWordsFile(new Path(IN_DIR,"input5_2k_5"),conf);

  org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job,IN_DIR);

  org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(job,new Path(OUT_DIR,"outputN0"));

  assertTrue(job.waitForCompletion(true));

  final Counters c1=Counters.downgrade(job.getCounters());

  validateCounters(c1,90112,15360,61440);

}

Location: TestJobCounters.java

Content: 

@Test public void testNewCounterB() throws Exception {

  final Job job=createJob();

  final Configuration conf=job.getConfiguration();

  conf.setInt(JobContext.IO_SORT_FACTOR,2);

  createWordsFile(new Path(IN_DIR,"input5_2k_4"),conf);

  removeWordsFile(new Path(IN_DIR,"input5_2k_5"),conf);

  org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job,IN_DIR);

  org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(job,new Path(OUT_DIR,"outputN1"));

  assertTrue(job.waitForCompletion(true));

  final Counters c1=Counters.downgrade(job.getCounters());

  validateCounters(c1,131072,20480,81920);

}

Location: TestJobCounters.java

Content: 

@Test public void testNewCounterC() throws Exception {

  final Job job=createJob();

  final Configuration conf=job.getConfiguration();

  conf.setInt(JobContext.IO_SORT_FACTOR,3);

  createWordsFile(new Path(IN_DIR,"input5_2k_4"),conf);

  createWordsFile(new Path(IN_DIR,"input5_2k_5"),conf);

  org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job,IN_DIR);

  org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(job,new Path(OUT_DIR,"outputN2"));

  assertTrue(job.waitForCompletion(true));

  final Counters c1=Counters.downgrade(job.getCounters());

  validateCounters(c1,147456,25600,102400);

}

Location: TestJobCounters.java

Content: 

@Test public void testOldCounterA() throws Exception {

  JobConf conf=createConfiguration();

  conf.setNumMapTasks(3);

  conf.setInt(JobContext.IO_SORT_FACTOR,2);

  removeWordsFile(new Path(IN_DIR,"input5_2k_4"),conf);

  removeWordsFile(new Path(IN_DIR,"input5_2k_5"),conf);

  FileInputFormat.setInputPaths(conf,IN_DIR);

  FileOutputFormat.setOutputPath(conf,new Path(OUT_DIR,"outputO0"));

  RunningJob myJob=JobClient.runJob(conf);

  Counters c1=myJob.getCounters();

  validateCounters(c1,90112,15360,61440);

}

Location: TestJobCounters.java

Content: 

@Test public void testOldCounterB() throws Exception {

  JobConf conf=createConfiguration();

  createWordsFile(new Path(IN_DIR,"input5_2k_4"),conf);

  removeWordsFile(new Path(IN_DIR,"input5_2k_5"),conf);

  conf.setNumMapTasks(4);

  conf.setInt(JobContext.IO_SORT_FACTOR,2);

  FileInputFormat.setInputPaths(conf,IN_DIR);

  FileOutputFormat.setOutputPath(conf,new Path(OUT_DIR,"outputO1"));

  RunningJob myJob=JobClient.runJob(conf);

  Counters c1=myJob.getCounters();

  validateCounters(c1,131072,20480,81920);

}

Location: TestJobCounters.java

Content: 

@Test public void testOldCounterC() throws Exception {

  JobConf conf=createConfiguration();

  createWordsFile(new Path(IN_DIR,"input5_2k_4"),conf);

  createWordsFile(new Path(IN_DIR,"input5_2k_5"),conf);

  conf.setNumMapTasks(4);

  conf.setInt(JobContext.IO_SORT_FACTOR,3);

  FileInputFormat.setInputPaths(conf,IN_DIR);

  FileOutputFormat.setOutputPath(conf,new Path(OUT_DIR,"outputO2"));

  RunningJob myJob=JobClient.runJob(conf);

  Counters c1=myJob.getCounters();

  validateCounters(c1,147456,25600,102400);

}

Location: TestJobCounters.java

Content: 

private void validateCounters(Counters counter,long spillRecCnt,long mapInputRecords,long mapOutputRecords){

  assertEquals(spillRecCnt,counter.findCounter(TaskCounter.SPILLED_RECORDS).getCounter());

  assertEquals(mapInputRecords,counter.findCounter(TaskCounter.MAP_INPUT_RECORDS).getCounter());

  assertEquals(mapOutputRecords,counter.findCounter(TaskCounter.MAP_OUTPUT_RECORDS).getCounter());

}

