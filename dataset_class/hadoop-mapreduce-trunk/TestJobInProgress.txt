Location: TestJobInProgress.java

Content: 

static void checkTaskCounts(JobInProgress jip,int runningMaps,int pendingMaps,int runningReduces,int pendingReduces){

  Counters counter=jip.getJobCounters();

  long totalTaskCount=counter.getCounter(JobCounter.TOTAL_LAUNCHED_MAPS) + counter.getCounter(JobCounter.TOTAL_LAUNCHED_REDUCES);

  LOG.info("totalTaskCount is " + totalTaskCount);

  LOG.info(" Running Maps:" + jip.runningMaps() + " Pending Maps:"+ jip.pendingMaps()+ " Running Reds:"+ jip.runningReduces()+ " Pending Reds:"+ jip.pendingReduces());

  assertEquals(jip.getNumTaskCompletionEvents(),totalTaskCount);

  assertEquals(runningMaps,jip.runningMaps());

  assertEquals(pendingMaps,jip.pendingMaps());

  assertEquals(runningReduces,jip.runningReduces());

  assertEquals(pendingReduces,jip.pendingReduces());

}

Location: TestJobInProgress.java

Content: 

public void testJobSummary() throws Exception {

  int numMaps=2;

  int numReds=2;

  JobConf conf=new JobConf();

  conf.setNumMapTasks(numMaps);

  conf.setNumReduceTasks(numReds);

  MyFakeJobInProgress jspy=spy(new MyFakeJobInProgress(conf,jobTracker));

  jspy.initTasks();

  TaskAttemptID tid;

  for (int i=0; i < numMaps; i++) {

    jspy.maps[i].setExecStartTime(i + 1);

    tid=jspy.findAndRunNewTask(true,trackers[i],hosts[i],clusterSize,numUniqueHosts);

    jspy.finishTask(tid);

  }

  for (int i=0; i < numReds; i++) {

    jspy.reduces[i].setExecStartTime(i + numMaps + 1);

    tid=jspy.findAndRunNewTask(false,trackers[i],hosts[i],clusterSize,numUniqueHosts);

    jspy.finishTask(tid);

  }

  verify(jspy,times(4)).setFirstTaskLaunchTime(any(TaskInProgress.class));

  ClusterStatus cspy=spy(new ClusterStatus(4,0,0,0,0,4,4,JobTrackerStatus.RUNNING,0));

  JobInProgress.JobSummary.logJobSummary(jspy,cspy);

  verify(jspy).getStatus();

  verify(jspy).getProfile();

  verify(jspy).getJobCounters();

  verify(jspy,atLeastOnce()).getJobID();

  verify(jspy).getStartTime();

  verify(jspy).getFirstTaskLaunchTimes();

  verify(jspy).getFinishTime();

  verify(jspy).getTasks(TaskType.MAP);

  verify(jspy).getTasks(TaskType.REDUCE);

  verify(jspy).getNumSlotsPerMap();

  verify(jspy).getNumSlotsPerReduce();

  verify(cspy).getMaxMapTasks();

  verify(cspy).getMaxReduceTasks();

  assertEquals("firstMapTaskLaunchTime",1,jspy.getFirstTaskLaunchTimes().get(TaskType.MAP).longValue());

  assertEquals("firstReduceTaskLaunchTime",3,jspy.getFirstTaskLaunchTimes().get(TaskType.REDUCE).longValue());

}

Location: TestJobInProgress.java

Content: 

public void testPendingMapTaskCount() throws Exception {

  int numMaps=4;

  int numReds=4;

  JobConf conf=new JobConf();

  conf.setNumMapTasks(numMaps);

  conf.setNumReduceTasks(numReds);

  conf.setSpeculativeExecution(false);

  conf.setBoolean(JobContext.SETUP_CLEANUP_NEEDED,false);

  MyFakeJobInProgress job1=new MyFakeJobInProgress(conf,jobTracker);

  job1.initTasks();

  TaskAttemptID[] tid=new TaskAttemptID[numMaps];

  for (int i=0; i < numMaps; i++) {

    tid[i]=job1.findAndRunNewTask(true,trackers[i],hosts[i],clusterSize,numUniqueHosts);

  }

  for (int i=0; i < numMaps; i++) {

    job1.failTask(tid[i]);

  }

  MyFakeJobInProgress job2=new MyFakeJobInProgress(conf,jobTracker);

  job2.initTasks();

  for (int i=0; i < numMaps; i++) {

    tid[i]=job2.findAndRunNewTask(true,trackers[i],hosts[i],clusterSize,numUniqueHosts);

    job2.finishTask(tid[i]);

  }

  for (int i=0; i < numReds / 2; i++) {

    tid[i]=job2.findAndRunNewTask(false,trackers[i],hosts[i],clusterSize,numUniqueHosts);

  }

  for (int i=0; i < numReds / 4; i++) {

    job2.finishTask(tid[i]);

  }

  for (int i=numReds / 4; i < numReds / 2; i++) {

    job2.failTask(tid[i]);

  }

  checkTaskCounts(job1,0,numMaps,0,numReds);

  checkTaskCounts(job2,0,0,0,3 * numReds / 4);

}

Location: TestJobInProgress.java

Content: 

public void testRunningTaskCount() throws Exception {

  testRunningTaskCount(false);

  testRunningTaskCount(true);

}

Location: TestJobInProgress.java

Content: 

/** 

 * Test if running tasks are correctly maintained for various types of jobs

 */

static void testRunningTaskCount(boolean speculation) throws Exception {

  LOG.info("Testing running jobs with speculation : " + speculation);

  JobConf conf=new JobConf();

  conf.setNumMapTasks(2);

  conf.setNumReduceTasks(2);

  conf.setSpeculativeExecution(speculation);

  MyFakeJobInProgress jip=new MyFakeJobInProgress(conf,jobTracker);

  jip.initTasks();

  TaskAttemptID[] tid=new TaskAttemptID[4];

  for (int i=0; i < 2; i++) {

    tid[i]=jip.findAndRunNewTask(true,trackers[i],hosts[i],clusterSize,numUniqueHosts);

  }

  Set<TaskInProgress> uniqueTasks=new HashSet<TaskInProgress>();

  for (  Map.Entry<Node,Set<TaskInProgress>> s : jip.getRunningMapCache().entrySet()) {

    uniqueTasks.addAll(s.getValue());

  }

  uniqueTasks.addAll(jip.getNonLocalRunningMaps());

  assertEquals("Running map count doesnt match for jobs with speculation " + speculation,jip.runningMaps(),uniqueTasks.size());

  for (int i=0; i < 2; i++) {

    tid[i]=jip.findAndRunNewTask(false,trackers[i],hosts[i],clusterSize,numUniqueHosts);

  }

  assertEquals("Running reducer count doesnt match for" + " jobs with speculation " + speculation,jip.runningReduces(),jip.getRunningReduces().size());

}

