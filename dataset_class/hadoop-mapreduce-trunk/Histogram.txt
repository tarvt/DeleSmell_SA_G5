Location: Histogram.java

Content: 

public void dump(PrintStream stream){

  stream.print("dumping Histogram " + name + ":\n");

  Iterator<Map.Entry<Long,Long>> iter=iterator();

  while (iter.hasNext()) {

    Map.Entry<Long,Long> ent=iter.next();

    stream.print("val/count pair: " + (long)ent.getKey() + ", "+ (long)ent.getValue()+ "\n");

  }

  stream.print("*** end *** \n");

}

Location: Histogram.java

Content: 

public void enter(long value){

  Long existingValue=content.get(value);

  if (existingValue == null) {

    content.put(value,1L);

  }

 else {

    content.put(value,existingValue + 1L);

  }

  ++totalCount;

}

Location: Histogram.java

Content: 

/** 

 * Produces a discrete approximation of the CDF. The user provides the points on the  {@code Y} axis he wants, and we give the corresponding points on the{@code X} axis, plus the minimum and maximum from the data.

 * @param scale the denominator applied to every element of buckets. For example, if  {@code scale} is {@code 1000}, a  {@code buckets} element of 500will specify the median in that output slot.

 * @param buckets an array of int, all less than scale and each strictly greater than its predecessor if any. We don't check these requirements.

 * @return a {@code long[]}, with two more elements than  {@code buckets} has.The first resp. last element is the minimum resp. maximum value that was ever  {@code enter}ed. The rest of the elements correspond to the elements of  {@code buckets} and carry the first elementwhose rank is no less than  {@code #content elements * scale /bucket}.

 */

public long[] getCDF(int scale,int[] buckets){

  if (totalCount == 0) {

    return null;

  }

  long[] result=new long[buckets.length + 2];

  result[0]=content.firstEntry().getKey();

  result[buckets.length + 1]=content.lastEntry().getKey();

  Iterator<Map.Entry<Long,Long>> iter=content.entrySet().iterator();

  long cumulativeCount=0;

  int bucketCursor=0;

  while (iter.hasNext()) {

    long targetCumulativeCount=buckets[bucketCursor] * totalCount / scale;

    Map.Entry<Long,Long> elt=iter.next();

    cumulativeCount+=elt.getValue();

    while (cumulativeCount >= targetCumulativeCount) {

      result[bucketCursor + 1]=elt.getKey();

      ++bucketCursor;

      if (bucketCursor < buckets.length) {

        targetCumulativeCount=buckets[bucketCursor] * totalCount / scale;

      }

 else {

        break;

      }

    }

    if (bucketCursor == buckets.length) {

      break;

    }

  }

  return result;

}

Location: Histogram.java

Content: 

public long getTotalCount(){

  return totalCount;

}

Location: Histogram.java

Content: 

public long get(long key){

  Long result=content.get(key);

  return result == null ? 0 : result;

}

Location: Histogram.java

Content: 

public Histogram(){

  this("(anonymous)");

}

Location: Histogram.java

Content: 

public Histogram(String name){

  super();

  this.name=name;

  totalCount=0L;

}

Location: Histogram.java

Content: 

public Iterator<Map.Entry<Long,Long>> iterator(){

  return content.entrySet().iterator();

}

