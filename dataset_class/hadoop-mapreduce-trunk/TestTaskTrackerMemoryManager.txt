Location: TestTaskTrackerMemoryManager.java

Content: 

private boolean isProcfsBasedTreeAvailable(){

  try {

    if (!ProcfsBasedProcessTree.isAvailable()) {

      LOG.info("Currently ProcessTree has only one implementation " + "ProcfsBasedProcessTree, which is not available on this " + "system. Not testing");

      return false;

    }

  }

 catch (  Exception e) {

    LOG.info(StringUtils.stringifyException(e));

    return false;

  }

  return true;

}

Location: TestTaskTrackerMemoryManager.java

Content: 

private void runAndCheckSuccessfulJob(JobConf conf) throws IOException {

  Pattern taskOverLimitPattern=Pattern.compile(String.format(taskOverLimitPatternString,"[0-9]*"));

  Matcher mat=null;

  int ret;

  try {

    ret=runSleepJob(conf);

  }

 catch (  Exception e) {

    ret=1;

  }

  assertTrue(ret == 0);

  JobClient jClient=new JobClient(conf);

  JobStatus[] jStatus=jClient.getAllJobs();

  JobStatus js=jStatus[0];

  RunningJob rj=jClient.getJob(js.getJobID());

  TaskCompletionEvent[] taskComplEvents=rj.getTaskCompletionEvents(0);

  for (  TaskCompletionEvent tce : taskComplEvents) {

    String[] diagnostics=rj.getTaskDiagnostics(tce.getTaskAttemptId());

    if (diagnostics != null) {

      for (      String str : diagnostics) {

        mat=taskOverLimitPattern.matcher(str);

        assertFalse(mat.find());

      }

    }

  }

}

Location: TestTaskTrackerMemoryManager.java

Content: 

/** 

 * Runs a job which should fail the when run by the memory monitor.

 * @param doPhysicalMemory If it is true, use physical memory limit.Otherwise use virtual memory limit.

 * @throws IOException

 */

private void runJobExceedingMemoryLimit(boolean doPhysicalMemory) throws IOException {

  long PER_TASK_LIMIT=1L;

  Pattern taskOverLimitPattern=Pattern.compile(String.format(taskOverLimitPatternString,String.valueOf(PER_TASK_LIMIT * 1024 * 1024L)));

  Matcher mat=null;

  JobConf conf=new JobConf(miniMRCluster.createJobConf());

  if (doPhysicalMemory) {

    conf.setLong(MRJobConfig.MAP_MEMORY_PHYSICAL_MB,PER_TASK_LIMIT);

    conf.setLong(MRJobConfig.REDUCE_MEMORY_PHYSICAL_MB,PER_TASK_LIMIT);

  }

 else {

    conf.setMemoryForMapTask(PER_TASK_LIMIT);

    conf.setMemoryForReduceTask(PER_TASK_LIMIT);

  }

  conf.setMaxMapAttempts(1);

  conf.setMaxReduceAttempts(1);

  int ret=0;

  try {

    ret=runSleepJob(conf);

  }

 catch (  Exception e) {

    ret=1;

  }

  assertTrue(ret != 0);

  JobClient jClient=new JobClient(conf);

  JobStatus[] jStatus=jClient.getAllJobs();

  JobStatus js=jStatus[0];

  RunningJob rj=jClient.getJob(js.getJobID());

  TaskCompletionEvent[] taskComplEvents=rj.getTaskCompletionEvents(0);

  for (  TaskCompletionEvent tce : taskComplEvents) {

    assertTrue("Failure expected, task: " + tce.getTaskStatus(),tce.getTaskStatus() == TaskCompletionEvent.Status.TIPFAILED || tce.getTaskStatus() == TaskCompletionEvent.Status.FAILED);

    String[] diagnostics=rj.getTaskDiagnostics(tce.getTaskAttemptId());

    assertNotNull(diagnostics);

    for (    String str : diagnostics) {

      mat=taskOverLimitPattern.matcher(str);

      assertTrue(mat.find());

    }

  }

}

Location: TestTaskTrackerMemoryManager.java

Content: 

private void startCluster(JobConf conf) throws Exception {

  conf.set(JTConfig.JT_IPC_HANDLER_COUNT,"1");

  conf.set(TTConfig.TT_MAP_SLOTS,"1");

  conf.set(TTConfig.TT_REDUCE_SLOTS,"1");

  conf.set(TTConfig.TT_SLEEP_TIME_BEFORE_SIG_KILL,"0");

  miniMRCluster=new MiniMRCluster(1,"file:///",1,null,null,conf);

}

Location: TestTaskTrackerMemoryManager.java

Content: 

/** 

 * Test to verify the check for whether a process tree is over limit or not.

 * @throws IOException if there was a problem setting up thefake procfs directories or files.

 */

@Test public void testProcessTreeLimits() throws IOException {

  File procfsRootDir=new File(TEST_ROOT_DIR,"proc");

  String[] pids={"100","200","300","400","500","600","700"};

  try {

    TestProcfsBasedProcessTree.setupProcfsRootDir(procfsRootDir);

    TestProcfsBasedProcessTree.setupPidDirs(procfsRootDir,pids);

    TestProcfsBasedProcessTree.ProcessStatInfo[] procs=new TestProcfsBasedProcessTree.ProcessStatInfo[7];

    procs[0]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"100","proc1","1","100","100","100000"});

    procs[1]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"200","proc2","1","200","200","200000"});

    procs[2]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"300","proc3","200","200","200","300000"});

    procs[3]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"400","proc4","200","200","200","400000"});

    procs[4]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"500","proc5","100","100","100","1500000"});

    procs[5]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"600","proc6","1","600","600","100000"});

    procs[6]=new TestProcfsBasedProcessTree.ProcessStatInfo(new String[]{"700","proc7","600","600","600","100000"});

    TestProcfsBasedProcessTree.writeStatFiles(procfsRootDir,pids,procs);

    long limit=700000;

    TaskMemoryManagerThread test=new TaskMemoryManagerThread(1000000L,5000L);

    ProcfsBasedProcessTree pTree=new ProcfsBasedProcessTree("100",true,100L,procfsRootDir.getAbsolutePath());

    pTree.getProcessTree();

    assertTrue("tree rooted at 100 should be over limit " + "after first iteration.",test.isProcessTreeOverLimit(pTree,"dummyId",limit));

    pTree=new ProcfsBasedProcessTree("200",true,100L,procfsRootDir.getAbsolutePath());

    pTree.getProcessTree();

    assertFalse("tree rooted at 200 shouldn't be over limit " + "after one iteration.",test.isProcessTreeOverLimit(pTree,"dummyId",limit));

    pTree.getProcessTree();

    assertTrue("tree rooted at 200 should be over limit after 2 iterations",test.isProcessTreeOverLimit(pTree,"dummyId",limit));

    pTree=new ProcfsBasedProcessTree("600",true,100L,procfsRootDir.getAbsolutePath());

    pTree.getProcessTree();

    assertFalse("tree rooted at 600 should never be over limit.",test.isProcessTreeOverLimit(pTree,"dummyId",limit));

    pTree.getProcessTree();

    assertFalse("tree rooted at 600 should never be over limit.",test.isProcessTreeOverLimit(pTree,"dummyId",limit));

  }

  finally {

    FileUtil.fullyDelete(procfsRootDir);

  }

}

Location: TestTaskTrackerMemoryManager.java

Content: 

/** 

 * Runs tests with tasks beyond limit and using old configuration values for the TaskTracker.

 * @throws Exception

 */

@Ignore("Intermittent, unexpected task success causes test to fail.") @Test public void testTaskMemoryMonitoringWithDeprecatedConfiguration() throws Exception {

  if (!isProcfsBasedTreeAvailable()) {

    return;

  }

  JobConf fConf=new JobConf();

  fConf.setInt(TTConfig.TT_MEMORY_MANAGER_MONITORING_INTERVAL,100);

  fConf.setLong(JobConf.MAPRED_TASK_DEFAULT_MAXVMEM_PROPERTY,(2L * 1024L * 1024L* 1024L));

  fConf.setLong(JobConf.UPPER_LIMIT_ON_TASK_VMEM_PROPERTY,(3L * 1024L * 1024L* 1024L));

  startCluster(fConf);

  runJobExceedingMemoryLimit(false);

}

Location: TestTaskTrackerMemoryManager.java

Content: 

/** 

 * Test for verifying that tasks that go beyond limits get killed.

 * @throws Exception

 */

@Ignore("Intermittent, unexpected task success causes test to fail.") @Test public void testTasksBeyondLimits() throws Exception {

  if (!isProcfsBasedTreeAvailable()) {

    return;

  }

  JobConf fConf=new JobConf();

  fConf.setInt(TTConfig.TT_MEMORY_MANAGER_MONITORING_INTERVAL,100);

  fConf.setLong(MRConfig.MAPMEMORY_MB,2 * 1024);

  fConf.setLong(MRConfig.REDUCEMEMORY_MB,2 * 1024);

  startCluster(fConf);

  runJobExceedingMemoryLimit(false);

}

Location: TestTaskTrackerMemoryManager.java

Content: 

/** 

 * Test for verifying that tasks that go beyond physical limits get killed.

 * @throws Exception

 */

@Ignore("Intermittent, unexpected task success causes test to fail.") @Test public void testTasksBeyondPhysicalLimits() throws Exception {

  if (!isProcfsBasedTreeAvailable()) {

    return;

  }

  JobConf fConf=new JobConf();

  fConf.setInt(TTConfig.TT_MEMORY_MANAGER_MONITORING_INTERVAL,100);

  fConf.setLong(TTConfig.TT_RESERVED_PHYSCIALMEMORY_MB,1L);

  startCluster(fConf);

  runJobExceedingMemoryLimit(true);

}

Location: TestTaskTrackerMemoryManager.java

Content: 

/** 

 * Test for verifying that tasks causing cumulative usage to go beyond TT's limit get killed even though they all are under individual limits. Memory management for tasks with disabled task-limits also traverses the same code-path, so we don't need a separate testTaskLimitsDisabled.

 * @throws Exception

 */

@Test public void testTasksCumulativelyExceedingTTLimits() throws Exception {

  if (!isProcfsBasedTreeAvailable()) {

    return;

  }

  long PER_TASK_LIMIT=100 * 1024L;

  JobConf fConf=new JobConf();

  fConf.setLong(MRConfig.MAPMEMORY_MB,1L);

  fConf.setLong(MRConfig.REDUCEMEMORY_MB,1L);

  long TASK_TRACKER_LIMIT=2 * 1024 * 1024L;

  fConf.setInt(TTConfig.TT_MEMORY_MANAGER_MONITORING_INTERVAL,100);

  startCluster(fConf);

  Pattern taskOverLimitPattern=Pattern.compile(String.format(taskOverLimitPatternString,String.valueOf(PER_TASK_LIMIT)));

  Pattern trackerOverLimitPattern=Pattern.compile("Killing one of the least progress tasks - .*, as " + "the cumulative memory usage of all the tasks on the TaskTracker" + " exceeds virtual memory limit " + TASK_TRACKER_LIMIT + ".");

  Matcher mat=null;

  JobConf conf=new JobConf(miniMRCluster.createJobConf());

  conf.setMemoryForMapTask(PER_TASK_LIMIT);

  conf.setMemoryForReduceTask(PER_TASK_LIMIT);

  JobClient jClient=new JobClient(conf);

  SleepJob sleepJob=new SleepJob();

  sleepJob.setConf(conf);

  Job job=sleepJob.createJob(1,1,5000,1,1000,1);

  job.submit();

  boolean TTOverFlowMsgPresent=false;

  while (true) {

    List<TaskReport> allTaskReports=new ArrayList<TaskReport>();

    allTaskReports.addAll(Arrays.asList(jClient.getSetupTaskReports(JobID.downgrade(job.getJobID()))));

    allTaskReports.addAll(Arrays.asList(jClient.getMapTaskReports(JobID.downgrade(job.getJobID()))));

    for (    TaskReport tr : allTaskReports) {

      String[] diag=tr.getDiagnostics();

      for (      String str : diag) {

        mat=taskOverLimitPattern.matcher(str);

        assertFalse(mat.find());

        mat=trackerOverLimitPattern.matcher(str);

        if (mat.find()) {

          TTOverFlowMsgPresent=true;

        }

      }

    }

    if (TTOverFlowMsgPresent) {

      break;

    }

    try {

      Thread.sleep(1000);

    }

 catch (    InterruptedException e) {

    }

  }

  job.killJob();

}

Location: TestTaskTrackerMemoryManager.java

Content: 

/** 

 * Test for verifying that tasks causing cumulative usage of physical memory to go beyond TT's limit get killed.

 * @throws Exception

 */

@Test public void testTasksCumulativelyExceedingTTPhysicalLimits() throws Exception {

  if (!isProcfsBasedTreeAvailable()) {

    return;

  }

  JobConf fConf=new JobConf();

  fConf.setInt(TTConfig.TT_MEMORY_MANAGER_MONITORING_INTERVAL,100);

  LinuxResourceCalculatorPlugin memoryCalculatorPlugin=new LinuxResourceCalculatorPlugin();

  long totalPhysicalMemory=memoryCalculatorPlugin.getPhysicalMemorySize();

  long reservedPhysicalMemory=totalPhysicalMemory / (1024 * 1024) + 1;

  fConf.setLong(TTConfig.TT_RESERVED_PHYSCIALMEMORY_MB,reservedPhysicalMemory);

  long maxRssMemoryAllowedForAllTasks=totalPhysicalMemory - reservedPhysicalMemory * 1024 * 1024L;

  Pattern physicalMemoryOverLimitPattern=Pattern.compile("Killing one of the memory-consuming tasks - .*" + ", as the cumulative RSS memory usage of all the tasks on " + "the TaskTracker exceeds physical memory limit " + maxRssMemoryAllowedForAllTasks + ".");

  startCluster(fConf);

  Matcher mat=null;

  JobConf conf=new JobConf(miniMRCluster.createJobConf());

  conf.setLong(MRJobConfig.MAP_MEMORY_PHYSICAL_MB,2 * 1024L);

  conf.setLong(MRJobConfig.REDUCE_MEMORY_PHYSICAL_MB,2 * 1024L);

  JobClient jClient=new JobClient(conf);

  SleepJob sleepJob=new SleepJob();

  sleepJob.setConf(conf);

  Job job=sleepJob.createJob(1,1,100000,1,100000,1);

  job.submit();

  boolean TTOverFlowMsgPresent=false;

  while (true) {

    List<TaskReport> allTaskReports=new ArrayList<TaskReport>();

    allTaskReports.addAll(Arrays.asList(jClient.getSetupTaskReports(JobID.downgrade(job.getJobID()))));

    allTaskReports.addAll(Arrays.asList(jClient.getMapTaskReports(JobID.downgrade(job.getJobID()))));

    for (    TaskReport tr : allTaskReports) {

      String[] diag=tr.getDiagnostics();

      for (      String str : diag) {

        mat=physicalMemoryOverLimitPattern.matcher(str);

        if (mat.find()) {

          TTOverFlowMsgPresent=true;

        }

      }

    }

    if (TTOverFlowMsgPresent) {

      break;

    }

    assertFalse("Job should not finish successfully",job.isSuccessful());

    try {

      Thread.sleep(1000);

    }

 catch (    InterruptedException e) {

    }

  }

  job.killJob();

}

Location: TestTaskTrackerMemoryManager.java

Content: 

/** 

 * Test for verifying that tasks within limits, with the cumulative usage also under TT's limits succeed.

 * @throws Exception

 */

@Test public void testTasksWithinLimits() throws Exception {

  if (!isProcfsBasedTreeAvailable()) {

    return;

  }

  long PER_TASK_LIMIT=2 * 1024L;

  JobConf fConf=new JobConf();

  fConf.setLong(MRConfig.MAPMEMORY_MB,2 * 1024L);

  fConf.setLong(MRConfig.REDUCEMEMORY_MB,2 * 1024L);

  fConf.setLong(TTConfig.TT_RESERVED_PHYSCIALMEMORY_MB,1L);

  startCluster(new JobConf());

  JobConf conf=new JobConf(miniMRCluster.createJobConf());

  conf.setMemoryForMapTask(PER_TASK_LIMIT);

  conf.setMemoryForReduceTask(PER_TASK_LIMIT);

  conf.setLong(MRJobConfig.MAP_MEMORY_PHYSICAL_MB,PER_TASK_LIMIT);

  conf.setLong(MRJobConfig.REDUCE_MEMORY_PHYSICAL_MB,PER_TASK_LIMIT);

  runAndCheckSuccessfulJob(conf);

}

Location: TestTaskTrackerMemoryManager.java

Content: 

/** 

 * Test for verifying that nothing is killed when memory management is disabled on the TT, even when the tasks run over their limits.

 * @throws Exception

 */

@Test public void testTTLimitsDisabled() throws Exception {

  if (!isProcfsBasedTreeAvailable()) {

    return;

  }

  startCluster(new JobConf());

  long PER_TASK_LIMIT=1L;

  JobConf conf=miniMRCluster.createJobConf();

  conf.setMemoryForMapTask(PER_TASK_LIMIT);

  conf.setMemoryForReduceTask(PER_TASK_LIMIT);

  runAndCheckSuccessfulJob(conf);

}

