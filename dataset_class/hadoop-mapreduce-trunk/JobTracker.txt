Location: JobTracker.java

Content: 

/** 

 * Returns true if the tasktracker is in the hosts list and  not in the exclude list. 

 */

private boolean acceptTaskTracker(TaskTrackerStatus status){

  return (inHostsList(status) && !inExcludedHostsList(status));

}

Location: JobTracker.java

Content: 

/** 

 * Get the active task tracker statuses in the cluster

 * @return {@link Collection} of active {@link TaskTrackerStatus} 

 */

synchronized public Collection<TaskTrackerStatus> activeTaskTrackers(){

  Collection<TaskTrackerStatus> activeTrackers=new ArrayList<TaskTrackerStatus>();

synchronized (taskTrackers) {

    for (    TaskTracker tt : taskTrackers.values()) {

      TaskTrackerStatus status=tt.getStatus();

      if (!faultyTrackers.isBlacklisted(status.getHost())) {

        activeTrackers.add(status);

      }

    }

  }

  return activeTrackers;

}

Location: JobTracker.java

Content: 

private Node addHostToNodeMapping(String host,String networkLoc){

  Node node=null;

synchronized (nodesAtMaxLevel) {

    if ((node=clusterMap.getNode(networkLoc + "/" + host)) == null) {

      node=new NodeBase(host,networkLoc);

      clusterMap.add(node);

      if (node.getLevel() < getNumTaskCacheLevels()) {

        LOG.fatal("Got a host whose level is: " + node.getLevel() + "."+ " Should get at least a level of value: "+ getNumTaskCacheLevels());

        try {

          stopTracker();

        }

 catch (        IOException ie) {

          LOG.warn("Exception encountered during shutdown: " + StringUtils.stringifyException(ie));

          System.exit(-1);

        }

      }

      hostnameToNodeMap.put(host,node);

      nodesAtMaxLevel.add(getParentNode(node,getNumTaskCacheLevels() - 1));

    }

  }

  return node;

}

Location: JobTracker.java

Content: 

/** 

 * Add a job to cleanup for the tracker.

 */

private void addJobForCleanup(JobID id){

  for (  String taskTracker : taskTrackers.keySet()) {

    if (LOG.isDebugEnabled()) {

      LOG.debug("Marking job " + id + " for cleanup by tracker "+ taskTracker);

    }

synchronized (trackerToJobsToCleanup) {

      Set<JobID> jobsToKill=trackerToJobsToCleanup.get(taskTracker);

      if (jobsToKill == null) {

        jobsToKill=new HashSet<JobID>();

        trackerToJobsToCleanup.put(taskTracker,jobsToKill);

      }

      jobsToKill.add(id);

    }

  }

}

Location: JobTracker.java

Content: 

public void addJobInProgressListener(JobInProgressListener listener){

  jobInProgressListeners.add(listener);

}

Location: JobTracker.java

Content: 

/** 

 * Adds a job to the jobtracker. Make sure that the checks are inplace before adding a job. This is the core job submission logic

 * @param jobId The id for the job submitted which needs to be added

 */

synchronized JobStatus addJob(JobID jobId,JobInProgress job){

  totalSubmissions++;

synchronized (jobs) {

synchronized (taskScheduler) {

      jobs.put(job.getProfile().getJobID(),job);

      for (      JobInProgressListener listener : jobInProgressListeners) {

        try {

          listener.jobAdded(job);

        }

 catch (        IOException ioe) {

          LOG.warn("Failed to add and so skipping the job : " + job.getJobID() + ". Exception : "+ ioe);

        }

      }

    }

  }

  myInstrumentation.submitJob(job.getJobConf(),jobId);

  LOG.info("Job " + jobId + " added successfully for user '"+ job.getJobConf().getUser()+ "' to queue '"+ job.getJobConf().getQueueName()+ "'");

  return job.getStatus();

}

Location: JobTracker.java

Content: 

/** 

 * Adds a new node to the jobtracker. It involves adding it to the expiry thread and adding it for resolution Assumes JobTracker, taskTrackers and trackerExpiryQueue are locked on entry

 * @param status Task Tracker's status

 */

void addNewTracker(TaskTracker taskTracker){

  TaskTrackerStatus status=taskTracker.getStatus();

  trackerExpiryQueue.add(status);

  String hostname=status.getHost();

  if (getNode(status.getTrackerName()) == null) {

    resolveAndAddToTopology(hostname);

  }

  Set<TaskTracker> trackers=hostnameToTaskTracker.get(hostname);

  if (trackers == null) {

    trackers=Collections.synchronizedSet(new HashSet<TaskTracker>());

    hostnameToTaskTracker.put(hostname,trackers);

  }

  statistics.taskTrackerAdded(status.getTrackerName());

  getInstrumentation().addTrackers(1);

  LOG.info("Adding tracker " + status.getTrackerName() + " to host "+ hostname);

  trackers.add(taskTracker);

}

Location: JobTracker.java

Content: 

/** 

 * Are ACLs for authorization checks enabled on the MR cluster ?

 * @return true if ACLs(job acls and queue acls) are enabled

 */

boolean areACLsEnabled(){

  return conf.getBoolean(MRConfig.MR_ACLS_ENABLED,false);

}

Location: JobTracker.java

Content: 

/** 

 * Get the blacklisted task tracker statuses in the cluster

 * @return {@link Collection} of blacklisted {@link TaskTrackerStatus} 

 */

synchronized public Collection<TaskTrackerStatus> blacklistedTaskTrackers(){

  Collection<TaskTrackerStatus> blacklistedTrackers=new ArrayList<TaskTrackerStatus>();

synchronized (taskTrackers) {

    for (    TaskTracker tt : taskTrackers.values()) {

      TaskTrackerStatus status=tt.getStatus();

      if (faultyTrackers.isBlacklisted(status.getHost())) {

        blacklistedTrackers.add(status);

      }

    }

  }

  return blacklistedTrackers;

}

Location: JobTracker.java

Content: 

void checkExpiredTrackers(){

synchronized (JobTracker.this) {

synchronized (taskTrackers) {

synchronized (trackerExpiryQueue) {

        long now=clock.getTime();

        TaskTrackerStatus leastRecent=null;

        while ((trackerExpiryQueue.size() > 0) && (leastRecent=trackerExpiryQueue.first()) != null && ((now - leastRecent.getLastSeen()) > tasktrackerExpiryInterval)) {

          trackerExpiryQueue.remove(leastRecent);

          String trackerName=leastRecent.getTrackerName();

          TaskTracker current=getTaskTracker(trackerName);

          TaskTrackerStatus newProfile=(current == null) ? null : current.getStatus();

          if (newProfile != null) {

            if ((now - newProfile.getLastSeen()) > tasktrackerExpiryInterval) {

              removeTracker(current);

              String hostname=newProfile.getHost();

              hostnameToTaskTracker.get(hostname).remove(trackerName);

            }

 else {

              trackerExpiryQueue.add(newProfile);

            }

          }

        }

      }

    }

  }

}

Location: JobTracker.java

Content: 

/** 

 * Check the job if it has invalid requirements and throw and IOException if does have.

 * @param job

 * @throws IOException 

 */

void checkMemoryRequirements(JobInProgress job) throws IOException {

  if (!perTaskMemoryConfigurationSetOnJT()) {

    if (LOG.isDebugEnabled()) {

      LOG.debug("Per-Task memory configuration is not set on JT. " + "Not checking the job for invalid memory requirements.");

    }

    return;

  }

  boolean invalidJob=false;

  String msg="";

  long maxMemForMapTask=job.getMemoryForMapTask();

  long maxMemForReduceTask=job.getMemoryForReduceTask();

  if (maxMemForMapTask == JobConf.DISABLED_MEMORY_LIMIT || maxMemForReduceTask == JobConf.DISABLED_MEMORY_LIMIT) {

    invalidJob=true;

    msg="Invalid job requirements.";

  }

  if (maxMemForMapTask > limitMaxMemForMapTasks || maxMemForReduceTask > limitMaxMemForReduceTasks) {

    invalidJob=true;

    msg="Exceeds the cluster's max-memory-limit.";

  }

  if (invalidJob) {

    StringBuilder jobStr=new StringBuilder().append(job.getJobID().toString()).append("(").append(maxMemForMapTask).append(" memForMapTasks ").append(maxMemForReduceTask).append(" memForReduceTasks): ");

    LOG.warn(jobStr.toString() + msg);

    throw new IOException(jobStr.toString() + msg);

  }

}

Location: JobTracker.java

Content: 

/** 

 * For a JobInProgress that is being submitted, check whether  queue that the job has been submitted to exists and is RUNNING.

 * @param job The JobInProgress object being submitted.

 * @throws IOException

 */

public void checkQueueValidity(JobInProgress job) throws IOException {

  String queue=job.getProfile().getQueueName();

  if (!(queueManager.getLeafQueueNames().contains(queue))) {

    throw new IOException("Queue \"" + queue + "\" does not exist");

  }

  if (!queueManager.isRunning(queue)) {

    throw new IOException("Queue \"" + queue + "\" is not running");

  }

}

Location: JobTracker.java

Content: 

public Vector<JobInProgress> completedJobs(){

  Vector<JobInProgress> v=new Vector<JobInProgress>();

  for (Iterator it=jobs.values().iterator(); it.hasNext(); ) {

    JobInProgress jip=(JobInProgress)it.next();

    JobStatus status=jip.getStatus();

    if (status.getRunState() == JobStatus.SUCCEEDED) {

      v.add(jip);

    }

  }

  return v;

}

Location: JobTracker.java

Content: 

private synchronized void completeEmptyJob(JobInProgress job){

  job.completeEmptyJob();

}

Location: JobTracker.java

Content: 

void createTaskEntry(TaskAttemptID taskid,String taskTracker,TaskInProgress tip){

  LOG.info("Adding task (" + tip.getAttemptType(taskid) + ") "+ "'"+ taskid+ "' to tip "+ tip.getTIPId()+ ", for tracker '"+ taskTracker+ "'");

  taskidToTrackerMap.put(taskid,taskTracker);

  Set<TaskAttemptID> taskset=trackerToTaskMap.get(taskTracker);

  if (taskset == null) {

    taskset=new TreeSet<TaskAttemptID>();

    trackerToTaskMap.put(taskTracker,taskset);

  }

  taskset.add(taskid);

  taskidToTIPMap.put(taskid,tip);

}

Location: JobTracker.java

Content: 

synchronized void decommissionNodes(Set<String> hosts) throws IOException {

  LOG.info("Decommissioning " + hosts.size() + " nodes");

synchronized (taskTrackers) {

synchronized (trackerExpiryQueue) {

      int trackersDecommissioned=0;

      for (      String host : hosts) {

        LOG.info("Decommissioning host " + host);

        Set<TaskTracker> trackers=hostnameToTaskTracker.remove(host);

        if (trackers != null) {

          for (          TaskTracker tracker : trackers) {

            LOG.info("Decommission: Losing tracker " + tracker.getTrackerName() + " on host "+ host);

            removeTracker(tracker);

          }

          trackersDecommissioned+=trackers.size();

        }

        LOG.info("Host " + host + " is ready for decommissioning");

      }

      getInstrumentation().setDecommissionedTrackers(trackersDecommissioned);

    }

  }

}

Location: JobTracker.java

Content: 

void decrementReservations(TaskType type,int reservedSlots){

  if (type.equals(TaskType.MAP)) {

    reservedMapSlots-=reservedSlots;

  }

 else   if (type.equals(TaskType.REDUCE)) {

    reservedReduceSlots-=reservedSlots;

  }

}

Location: JobTracker.java

Content: 

/** 

 * Recursively delete the contents of a directory without deleting the directory itself.

 */

private void deleteContents(FileSystem fs,Path dir) throws IOException {

  for (  FileStatus stat : fs.listStatus(dir)) {

    if (!fs.delete(stat.getPath(),true)) {

      throw new IOException("Unable to delete " + stat.getPath());

    }

  }

}

Location: JobTracker.java

Content: 

/** 

 * Dumps the configuration properties in Json format

 * @param writer {@link}Writer object to which the output is written

 * @throws IOException

 */

private static void dumpConfiguration(Writer writer) throws IOException {

  Configuration.dumpConfiguration(new JobConf(),writer);

  writer.write("\n");

}

Location: JobTracker.java

Content: 

public Vector<JobInProgress> failedJobs(){

  Vector<JobInProgress> v=new Vector<JobInProgress>();

  for (Iterator it=jobs.values().iterator(); it.hasNext(); ) {

    JobInProgress jip=(JobInProgress)it.next();

    JobStatus status=jip.getStatus();

    if ((status.getRunState() == JobStatus.FAILED) || (status.getRunState() == JobStatus.KILLED)) {

      v.add(jip);

    }

  }

  return v;

}

Location: JobTracker.java

Content: 

/** 

 * Fail a job and inform the listeners. Other components in the framework  should use this to fail a job.

 */

public synchronized void failJob(JobInProgress job){

  if (null == job) {

    LOG.info("Fail on null job is not valid");

    return;

  }

  JobStatus prevStatus=(JobStatus)job.getStatus().clone();

  LOG.info("Failing job " + job.getJobID());

  job.fail();

  JobStatus newStatus=(JobStatus)job.getStatus().clone();

  if (prevStatus.getRunState() != newStatus.getRunState()) {

    JobStatusChangeEvent event=new JobStatusChangeEvent(job,EventType.RUN_STATE_CHANGED,prevStatus,newStatus);

    updateJobInProgressListeners(event);

  }

}

Location: JobTracker.java

Content: 

/** 

 * Safe clean-up all data structures at the end of the  job (success/failure/killed). Here we also ensure that for a given user we maintain  information for only MAX_COMPLETE_USER_JOBS_IN_MEMORY jobs  on the JobTracker.

 * @param job completed job.

 */

synchronized void finalizeJob(JobInProgress job){

  markCompletedJob(job);

  JobEndNotifier.registerNotification(job.getJobConf(),job.getStatus());

  JobID id=job.getStatus().getJobID();

  try {

    jobHistory.markCompleted(id);

  }

 catch (  IOException ioe) {

    LOG.info("Failed to mark job " + id + " as completed!",ioe);

  }

  final JobTrackerInstrumentation metrics=getInstrumentation();

  metrics.finalizeJob(conf,id);

  addJobForCleanup(id);

  if (job.getStatus().getRunState() == JobStatus.SUCCEEDED) {

    if (job.getNoOfBlackListedTrackers() > 0) {

      for (      String hostName : job.getBlackListedTrackers()) {

        faultyTrackers.incrementFaults(hostName);

      }

    }

  }

}

Location: JobTracker.java

Content: 

private static String generateNewIdentifier(){

  return getDateFormat().format(new Date());

}

Location: JobTracker.java

Content: 

ACLsManager getACLsManager(){

  return aclsManager;

}

Location: JobTracker.java

Content: 

public static InetSocketAddress getAddress(Configuration conf){

  String jobTrackerStr=conf.get(JT_IPC_ADDRESS,"localhost:8012");

  return NetUtils.createSocketAddr(jobTrackerStr);

}

Location: JobTracker.java

Content: 

/** 

 * Get tracker name for a given task id.

 * @param taskId the name of the task

 * @return The name of the task tracker

 */

public synchronized String getAssignedTracker(TaskAttemptID taskId){

  return taskidToTrackerMap.get(taskId);

}

Location: JobTracker.java

Content: 

/** 

 * Get the number of blacklisted trackers across all the jobs

 * @return

 */

int getBlacklistedTrackerCount(){

  return faultyTrackers.numBlacklistedTrackers;

}

Location: JobTracker.java

Content: 

public String getBuildVersion() throws IOException {

  return VersionInfo.getBuildVersion();

}

Location: JobTracker.java

Content: 

/** 

 * @param jobid

 * @return array of TaskReport

 * @deprecated Use {@link #getTaskReports(org.apache.hadoop.mapreduce.JobID,TaskType)} instead

 */

@Deprecated public synchronized TaskReport[] getCleanupTaskReports(JobID jobid){

  JobInProgress job=jobs.get(jobid);

  if (job == null || !isJobInited(job)) {

    return EMPTY_TASK_REPORTS;

  }

 else {

    Vector<TaskReport> reports=new Vector<TaskReport>();

    Vector<TaskInProgress> completeTasks=job.reportCleanupTIPs(true);

    for (Iterator<TaskInProgress> it=completeTasks.iterator(); it.hasNext(); ) {

      TaskInProgress tip=it.next();

      reports.add(tip.generateSingleReport());

    }

    Vector<TaskInProgress> incompleteTasks=job.reportCleanupTIPs(false);

    for (Iterator<TaskInProgress> it=incompleteTasks.iterator(); it.hasNext(); ) {

      TaskInProgress tip=it.next();

      reports.add(tip.generateSingleReport());

    }

    return reports.toArray(new TaskReport[reports.size()]);

  }

}

Location: JobTracker.java

Content: 

/** 

 * Returns JobTracker's clock. Note that the correct clock implementation will be obtained only when the JobTracker is initialized. If the JobTracker is not initialized then the default clock i.e  {@link Clock} is returned. 

 */

static Clock getClock(){

  return clock == null ? DEFAULT_CLOCK : clock;

}

Location: JobTracker.java

Content: 

public synchronized ClusterStatus getClusterStatus(boolean detailed){

synchronized (taskTrackers) {

    if (detailed) {

      List<List<String>> trackerNames=taskTrackerNames();

      Collection<BlackListInfo> blackListedTrackers=getBlackListedTrackers();

      return new ClusterStatus(trackerNames.get(0),blackListedTrackers,tasktrackerExpiryInterval,totalMaps,totalReduces,totalMapTaskCapacity,totalReduceTaskCapacity,JobTrackerStatus.valueOf(state.name()),getExcludedNodes().size());

    }

 else {

      return new ClusterStatus(taskTrackers.size() - getBlacklistedTrackerCount(),getBlacklistedTrackerCount(),tasktrackerExpiryInterval,totalMaps,totalReduces,totalMapTaskCapacity,totalReduceTaskCapacity,JobTrackerStatus.valueOf(state.name()),getExcludedNodes().size());

    }

  }

}

Location: JobTracker.java

Content: 

public synchronized List<JobInProgress> getCompletedJobs(){

synchronized (jobs) {

    return completedJobs();

  }

}

Location: JobTracker.java

Content: 

private static SimpleDateFormat getDateFormat(){

  return new SimpleDateFormat("yyyyMMddHHmm");

}

Location: JobTracker.java

Content: 

/** 

 * Returns the delegation token secret manager instance in JobTracker.

 * @return DelegationTokenSecretManager object

 */

public DelegationTokenSecretManager getDelegationTokenSecretManager(){

  return secretManager;

}

Location: JobTracker.java

Content: 

/** 

 * Returns a set of excluded nodes.

 */

Collection<String> getExcludedNodes(){

  return hostsReader.getExcludedHosts();

}

Location: JobTracker.java

Content: 

synchronized String getFaultReport(String host){

  FaultInfo fi=faultyTrackers.getFaultInfo(host,false);

  if (fi == null) {

    return "";

  }

  return fi.getTrackerFaultReport();

}

Location: JobTracker.java

Content: 

@Override public String[] getGroupsForUser(String user) throws IOException {

  if (LOG.isDebugEnabled()) {

    LOG.debug("Getting groups for user " + user);

  }

  return UserGroupInformation.createRemoteUser(user).getGroupNames();

}

Location: JobTracker.java

Content: 

public int getInfoPort(){

  return infoPort;

}

Location: JobTracker.java

Content: 

JobTrackerInstrumentation getInstrumentation(){

  return myInstrumentation;

}

Location: JobTracker.java

Content: 

public static Class<? extends JobTrackerInstrumentation> getInstrumentationClass(Configuration conf){

  return conf.getClass(JT_INSTRUMENTATION,JobTrackerMetricsInst.class,JobTrackerInstrumentation.class);

}

Location: JobTracker.java

Content: 

JobACLsManager getJobACLsManager(){

  return aclsManager.getJobACLsManager();

}

Location: JobTracker.java

Content: 

/** 

 * see {@link ClientProtocol#getJobCounters(org.apache.hadoop.mapreduce.JobID)}

 * @throws IOException

 * @throws AccessControlException

 */

@Override public org.apache.hadoop.mapreduce.Counters getJobCounters(org.apache.hadoop.mapreduce.JobID jobid) throws AccessControlException, IOException {

  JobID oldJobID=JobID.downgrade(jobid);

  JobInProgress job;

synchronized (this) {

    job=jobs.get(oldJobID);

  }

  if (job != null) {

    aclsManager.checkAccess(job,UserGroupInformation.getCurrentUser(),Operation.VIEW_JOB_COUNTERS);

    if (!isJobInited(job)) {

      return EMPTY_COUNTERS;

    }

    Counters counters=job.getCounters();

    if (counters != null) {

      return new org.apache.hadoop.mapreduce.Counters(counters);

    }

    return null;

  }

  Counters counters=completedJobStatusStore.readCounters(oldJobID);

  if (counters != null) {

    return new org.apache.hadoop.mapreduce.Counters(counters);

  }

  return null;

}

Location: JobTracker.java

Content: 

/** 

 * Return the JT's job history handle.

 * @return the jobhistory handle

 */

JobHistory getJobHistory(){

  return jobHistory;

}

Location: JobTracker.java

Content: 

/** 

 * @deprecated Use {@link #getJobProfile(org.apache.hadoop.mapreduce.JobID)} instead

 */

@Deprecated public JobProfile getJobProfile(JobID jobid){

synchronized (this) {

    JobInProgress job=jobs.get(jobid);

    if (job != null) {

      return job.getProfile();

    }

  }

  return completedJobStatusStore.readJobProfile(jobid);

}

Location: JobTracker.java

Content: 

public JobProfile getJobProfile(org.apache.hadoop.mapreduce.JobID jobid){

  return getJobProfile(JobID.downgrade(jobid));

}

Location: JobTracker.java

Content: 

@Deprecated public JobQueueInfo[] getJobQueues() throws IOException {

  return queueManager.getJobQueueInfos();

}

Location: JobTracker.java

Content: 

/** 

 * A tracker wants to know if any job needs cleanup because the job completed.

 */

private List<TaskTrackerAction> getJobsForCleanup(String taskTracker){

  Set<JobID> jobs=null;

synchronized (trackerToJobsToCleanup) {

    jobs=trackerToJobsToCleanup.remove(taskTracker);

  }

  if (jobs != null) {

    List<TaskTrackerAction> killList=new ArrayList<TaskTrackerAction>();

    for (    JobID killJobId : jobs) {

      killList.add(new KillJobAction(killJobId));

      if (LOG.isDebugEnabled()) {

        LOG.debug(taskTracker + " -> KillJobAction: " + killJobId);

      }

    }

    return killList;

  }

  return null;

}

Location: JobTracker.java

Content: 

public org.apache.hadoop.mapreduce.JobStatus[] getJobsFromQueue(String queue) throws IOException {

  Collection<JobInProgress> jips=null;

  if (queueManager.getLeafQueueNames().contains(queue)) {

    jips=taskScheduler.getJobs(queue);

  }

  return getJobStatus(jips,false);

}

Location: JobTracker.java

Content: 

private synchronized JobStatus[] getJobStatus(Collection<JobInProgress> jips,boolean toComplete){

  if (jips == null || jips.isEmpty()) {

    return new JobStatus[]{};

  }

  ArrayList<JobStatus> jobStatusList=new ArrayList<JobStatus>();

  for (  JobInProgress jip : jips) {

    JobStatus status=jip.getStatus();

    status.setStartTime(jip.getStartTime());

    status.setUsername(jip.getProfile().getUser());

    if (toComplete) {

      if (status.getRunState() == JobStatus.RUNNING || status.getRunState() == JobStatus.PREP) {

        jobStatusList.add(status);

      }

    }

 else {

      jobStatusList.add(status);

    }

  }

  return jobStatusList.toArray(new JobStatus[jobStatusList.size()]);

}

Location: JobTracker.java

Content: 

/** 

 * see  {@link ClientProtocol#getJobStatus(org.apache.hadoop.mapreduce.JobID)}

 */

@Override public JobStatus getJobStatus(org.apache.hadoop.mapreduce.JobID jobid){

  return getJobStatus(JobID.downgrade(jobid));

}

Location: JobTracker.java

Content: 

JobTokenSecretManager getJobTokenSecretManager(){

  return jobTokenSecretManager;

}

Location: JobTracker.java

Content: 

public String getJobTrackerMachine(){

  return localMachine;

}

Location: JobTracker.java

Content: 

/** 

 * Remove the job_ from jobids to get the unique string.

 */

static String getJobUniqueString(String jobid){

  return jobid.substring(4);

}

Location: JobTracker.java

Content: 

/** 

 * Get JobTracker's LocalFileSystem handle. This is used by jobs for  localizing job files to the local disk.

 */

LocalFileSystem getLocalFileSystem() throws IOException {

  return localFs;

}

Location: JobTracker.java

Content: 

/** 

 * Get the path of the locally stored job file

 * @param jobId id of the job

 * @return the path of the job file on the local file system 

 */

String getLocalJobFilePath(org.apache.hadoop.mapreduce.JobID jobId){

  return System.getProperty("hadoop.log.dir") + File.separator + jobId+ "_conf.xml";

}

Location: JobTracker.java

Content: 

/** 

 * @param jobid

 * @return array of TaskReport

 * @deprecated Use {@link #getTaskReports(org.apache.hadoop.mapreduce.JobID,TaskType)} instead

 */

@Deprecated public synchronized TaskReport[] getMapTaskReports(JobID jobid){

  JobInProgress job=jobs.get(jobid);

  if (job == null || !isJobInited(job)) {

    return EMPTY_TASK_REPORTS;

  }

 else {

    Vector<TaskReport> reports=new Vector<TaskReport>();

    Vector<TaskInProgress> completeMapTasks=job.reportTasksInProgress(true,true);

    for (Iterator it=completeMapTasks.iterator(); it.hasNext(); ) {

      TaskInProgress tip=(TaskInProgress)it.next();

      reports.add(tip.generateSingleReport());

    }

    Vector<TaskInProgress> incompleteMapTasks=job.reportTasksInProgress(true,false);

    for (Iterator it=incompleteMapTasks.iterator(); it.hasNext(); ) {

      TaskInProgress tip=(TaskInProgress)it.next();

      reports.add(tip.generateSingleReport());

    }

    return reports.toArray(new TaskReport[reports.size()]);

  }

}

Location: JobTracker.java

Content: 

/** 

 * Returns the confgiured maximum number of tasks for a single job

 */

int getMaxTasksPerJob(){

  return conf.getInt(JT_TASKS_PER_JOB,-1);

}

Location: JobTracker.java

Content: 

UserGroupInformation getMROwner(){

  return aclsManager.getMROwner();

}

Location: JobTracker.java

Content: 

/** 

 * Calculates next heartbeat interval using cluster size. Heartbeat interval is incremented by 1 second for every 100 nodes by default. 

 * @return next heartbeat interval.

 */

public int getNextHeartbeatInterval(){

  int clusterSize=getClusterStatus().getTaskTrackers();

  int heartbeatInterval=Math.max((int)(1000 * HEARTBEATS_SCALING_FACTOR * ((double)clusterSize / NUM_HEARTBEATS_IN_SECOND)),HEARTBEAT_INTERVAL_MIN);

  return heartbeatInterval;

}

Location: JobTracker.java

Content: 

/** 

 * Returns a collection of nodes at the max level

 */

public Collection<Node> getNodesAtMaxLevel(){

  return nodesAtMaxLevel;

}

Location: JobTracker.java

Content: 

/** 

 * Return the Node in the network topology that corresponds to the hostname

 */

public Node getNode(String name){

  return hostnameToNodeMap.get(name);

}

Location: JobTracker.java

Content: 

public int getNumberOfUniqueHosts(){

  return uniqueHostsMap.size();

}

Location: JobTracker.java

Content: 

public int getNumResolvedTaskTrackers(){

  return numResolved;

}

Location: JobTracker.java

Content: 

public int getNumTaskCacheLevels(){

  return numTaskCacheLevels;

}

Location: JobTracker.java

Content: 

public static Node getParentNode(Node node,int level){

  for (int i=0; i < level; ++i) {

    node=node.getParent();

  }

  return node;

}

Location: JobTracker.java

Content: 

@Override public ProtocolSignature getProtocolSignature(String protocol,long clientVersion,int clientMethodsHash) throws IOException {

  return ProtocolSignature.getProtocolSignature(this,protocol,clientVersion,clientMethodsHash);

}

Location: JobTracker.java

Content: 

public long getProtocolVersion(String protocol,long clientVersion) throws IOException {

  if (protocol.equals(InterTrackerProtocol.class.getName())) {

    return InterTrackerProtocol.versionID;

  }

 else   if (protocol.equals(ClientProtocol.class.getName())) {

    return ClientProtocol.versionID;

  }

 else   if (protocol.equals(RefreshAuthorizationPolicyProtocol.class.getName())) {

    return RefreshAuthorizationPolicyProtocol.versionID;

  }

 else   if (protocol.equals(AdminOperationsProtocol.class.getName())) {

    return AdminOperationsProtocol.versionID;

  }

 else   if (protocol.equals(RefreshUserMappingsProtocol.class.getName())) {

    return RefreshUserMappingsProtocol.versionID;

  }

 else   if (protocol.equals(GetUserMappingsProtocol.class.getName())) {

    return GetUserMappingsProtocol.versionID;

  }

 else {

    throw new IOException("Unknown protocol to job tracker: " + protocol);

  }

}

Location: JobTracker.java

Content: 

private QueueInfo[] getQueueInfoArray(JobQueueInfo[] queues) throws IOException {

  for (  JobQueueInfo queue : queues) {

    queue.setJobStatuses(getJobsFromQueue(queue.getQueueName()));

  }

  return queues;

}

Location: JobTracker.java

Content: 

@Deprecated public JobQueueInfo getQueueInfo(String queue) throws IOException {

  return queueManager.getJobQueueInfo(queue);

}

Location: JobTracker.java

Content: 

/** 

 * Return the  {@link QueueManager} associated with the JobTracker.

 */

public QueueManager getQueueManager(){

  return queueManager;

}

Location: JobTracker.java

Content: 

synchronized Set<ReasonForBlackListing> getReasonForBlackList(String host){

  FaultInfo fi=faultyTrackers.getFaultInfo(host,false);

  if (fi == null) {

    return new HashSet<ReasonForBlackListing>();

  }

  return fi.getReasonforblacklisting();

}

Location: JobTracker.java

Content: 

/** 

 * How long the jobtracker took to recover from restart.

 */

public long getRecoveryDuration(){

  return recoveryDuration;

}

Location: JobTracker.java

Content: 

/** 

 * @param jobid

 * @return array of TaskReport

 * @deprecated Use {@link #getTaskReports(org.apache.hadoop.mapreduce.JobID,TaskType)} instead

 */

@Deprecated public synchronized TaskReport[] getReduceTaskReports(JobID jobid){

  JobInProgress job=jobs.get(jobid);

  if (job == null || !isJobInited(job)) {

    return EMPTY_TASK_REPORTS;

  }

 else {

    Vector<TaskReport> reports=new Vector<TaskReport>();

    Vector completeReduceTasks=job.reportTasksInProgress(false,true);

    for (Iterator it=completeReduceTasks.iterator(); it.hasNext(); ) {

      TaskInProgress tip=(TaskInProgress)it.next();

      reports.add(tip.generateSingleReport());

    }

    Vector incompleteReduceTasks=job.reportTasksInProgress(false,false);

    for (Iterator it=incompleteReduceTasks.iterator(); it.hasNext(); ) {

      TaskInProgress tip=(TaskInProgress)it.next();

      reports.add(tip.generateSingleReport());

    }

    return reports.toArray(new TaskReport[reports.size()]);

  }

}

Location: JobTracker.java

Content: 

/** 

 * Gets the root level queues.

 * @return array of JobQueueInfo object.

 * @throws java.io.IOException

 */

@Deprecated public JobQueueInfo[] getRootJobQueues() throws IOException {

  return queueManager.getRootQueues();

}

Location: JobTracker.java

Content: 

TaskScheduler getScheduler(){

  return taskScheduler;

}

Location: JobTracker.java

Content: 

synchronized List<Task> getSetupAndCleanupTasks(TaskTrackerStatus taskTracker) throws IOException {

  int maxMapTasks=taskTracker.getMaxMapSlots();

  int maxReduceTasks=taskTracker.getMaxReduceSlots();

  int numMaps=taskTracker.countOccupiedMapSlots();

  int numReduces=taskTracker.countOccupiedReduceSlots();

  int numTaskTrackers=getClusterStatus().getTaskTrackers();

  int numUniqueHosts=getNumberOfUniqueHosts();

  boolean hasFailedUncleanTask=hasFailedUncleanTask(taskTracker);

  Task t=null;

synchronized (jobs) {

    if (numMaps < maxMapTasks) {

      for (Iterator<JobInProgress> it=jobs.values().iterator(); it.hasNext(); ) {

        JobInProgress job=it.next();

        t=job.obtainJobCleanupTask(taskTracker,numTaskTrackers,numUniqueHosts,true);

        if (t != null) {

          return Collections.singletonList(t);

        }

      }

      if (!hasFailedUncleanTask) {

        for (Iterator<JobInProgress> it=jobs.values().iterator(); it.hasNext(); ) {

          JobInProgress job=it.next();

          t=job.obtainTaskCleanupTask(taskTracker,true);

          if (t != null) {

            return Collections.singletonList(t);

          }

        }

      }

      for (Iterator<JobInProgress> it=jobs.values().iterator(); it.hasNext(); ) {

        JobInProgress job=it.next();

        t=job.obtainJobSetupTask(taskTracker,numTaskTrackers,numUniqueHosts,true);

        if (t != null) {

          return Collections.singletonList(t);

        }

      }

    }

    if (numReduces < maxReduceTasks) {

      for (Iterator<JobInProgress> it=jobs.values().iterator(); it.hasNext(); ) {

        JobInProgress job=it.next();

        t=job.obtainJobCleanupTask(taskTracker,numTaskTrackers,numUniqueHosts,false);

        if (t != null) {

          return Collections.singletonList(t);

        }

      }

      if (!hasFailedUncleanTask) {

        for (Iterator<JobInProgress> it=jobs.values().iterator(); it.hasNext(); ) {

          JobInProgress job=it.next();

          t=job.obtainTaskCleanupTask(taskTracker,false);

          if (t != null) {

            return Collections.singletonList(t);

          }

        }

      }

      for (Iterator<JobInProgress> it=jobs.values().iterator(); it.hasNext(); ) {

        JobInProgress job=it.next();

        t=job.obtainJobSetupTask(taskTracker,numTaskTrackers,numUniqueHosts,false);

        if (t != null) {

          return Collections.singletonList(t);

        }

      }

    }

  }

  return null;

}

Location: JobTracker.java

Content: 

/** 

 * @param jobid

 * @return array of TaskReport

 * @deprecated Use {@link #getTaskReports(org.apache.hadoop.mapreduce.JobID,TaskType)} instead

 */

@Deprecated public synchronized TaskReport[] getSetupTaskReports(JobID jobid){

  JobInProgress job=jobs.get(jobid);

  if (job == null || !isJobInited(job)) {

    return EMPTY_TASK_REPORTS;

  }

 else {

    Vector<TaskReport> reports=new Vector<TaskReport>();

    Vector<TaskInProgress> completeTasks=job.reportSetupTIPs(true);

    for (Iterator<TaskInProgress> it=completeTasks.iterator(); it.hasNext(); ) {

      TaskInProgress tip=it.next();

      reports.add(tip.generateSingleReport());

    }

    Vector<TaskInProgress> incompleteTasks=job.reportSetupTIPs(false);

    for (Iterator<TaskInProgress> it=incompleteTasks.iterator(); it.hasNext(); ) {

      TaskInProgress tip=it.next();

      reports.add(tip.generateSingleReport());

    }

    return reports.toArray(new TaskReport[reports.size()]);

  }

}

Location: JobTracker.java

Content: 

JobTrackerStatistics getStatistics(){

  return statistics;

}

Location: JobTracker.java

Content: 

/** 

 * Get all task tracker statuses on given host Assumes JobTracker is locked on the entry

 * @param hostName

 * @return {@link java.util.List} of {@link TaskTrackerStatus}

 */

private List<TaskTrackerStatus> getStatusesOnHost(String hostName){

  List<TaskTrackerStatus> statuses=new ArrayList<TaskTrackerStatus>();

synchronized (taskTrackers) {

    for (    TaskTracker tt : taskTrackers.values()) {

      TaskTrackerStatus status=tt.getStatus();

      if (hostName.equals(status.getHost())) {

        statuses.add(status);

      }

    }

  }

  return statuses;

}

Location: JobTracker.java

Content: 

Path getSystemDirectoryForJob(JobID id){

  return new Path(getSystemDir(),id.toString());

}

Location: JobTracker.java

Content: 

Path getSystemFileForJob(JobID id){

  return new Path(getSystemDirectoryForJob(id) + "/" + JOB_INFO_FILE);

}

Location: JobTracker.java

Content: 

public TaskCompletionEvent[] getTaskCompletionEvents(org.apache.hadoop.mapreduce.JobID jobid,int fromEventId,int maxEvents) throws IOException {

  return getTaskCompletionEvents(JobID.downgrade(jobid),fromEventId,maxEvents);

}

Location: JobTracker.java

Content: 

/** 

 * Get the diagnostics for a given task

 * @param taskId the id of the task

 * @return an array of the diagnostic messages

 */

public synchronized String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID taskId) throws IOException {

  return getTaskDiagnostics(TaskAttemptID.downgrade(taskId));

}

Location: JobTracker.java

Content: 

/** 

 * see {@link ClientProtocol#getTaskReports(org.apache.hadoop.mapreduce.JobID,TaskType)}

 * @throws IOException 

 * @throws AccessControlException 

 */

@Override public synchronized TaskReport[] getTaskReports(org.apache.hadoop.mapreduce.JobID jobid,TaskType type) throws AccessControlException, IOException {

  JobInProgress job=jobs.get(jobid);

  if (job != null) {

    aclsManager.checkAccess(job,UserGroupInformation.getCurrentUser(),Operation.VIEW_JOB_DETAILS);

  }

 else {

    return EMPTY_TASK_REPORTS;

  }

switch (type) {

case MAP:

    return getMapTaskReports(JobID.downgrade(jobid));

case REDUCE:

  return getReduceTaskReports(JobID.downgrade(jobid));

case JOB_CLEANUP:

return getCleanupTaskReports(JobID.downgrade(jobid));

case JOB_SETUP:

return getSetupTaskReports(JobID.downgrade(jobid));

}

return EMPTY_TASK_REPORTS;

}

Location: JobTracker.java

Content: 

/** 

 * Returns the configured task scheduler for this job tracker.

 * @return the configured task scheduler

 */

TaskScheduler getTaskScheduler(){

  return taskScheduler;

}

Location: JobTracker.java

Content: 

/** 

 * Get all the TaskStatuses from the tipid. 

 */

TaskStatus[] getTaskStatuses(TaskID tipid){

  TaskInProgress tip=getTip(tipid);

  return (tip == null ? new TaskStatus[0] : tip.getTaskStatuses());

}

Location: JobTracker.java

Content: 

/** 

 * Returns the TaskStatus for a particular taskid. 

 */

TaskStatus getTaskStatus(TaskAttemptID taskid){

  TaskInProgress tip=getTip(taskid.getTaskID());

  return (tip == null ? null : tip.getTaskStatus(taskid));

}

Location: JobTracker.java

Content: 

/** 

 * A tracker wants to know if any of its Tasks have been closed (because the job completed, whether successfully or not)

 */

synchronized List<TaskTrackerAction> getTasksToKill(String taskTracker){

  Set<TaskAttemptID> taskIds=trackerToTaskMap.get(taskTracker);

  List<TaskTrackerAction> killList=new ArrayList<TaskTrackerAction>();

  if (taskIds != null) {

    for (    TaskAttemptID killTaskId : taskIds) {

      TaskInProgress tip=taskidToTIPMap.get(killTaskId);

      if (tip == null) {

        continue;

      }

      if (tip.shouldClose(killTaskId)) {

        if (!tip.getJob().isComplete()) {

          killList.add(new KillTaskAction(killTaskId));

          if (LOG.isDebugEnabled()) {

            LOG.debug(taskTracker + " -> KillTaskAction: " + killTaskId);

          }

        }

      }

    }

  }

synchronized (trackerToTasksToCleanup) {

    Set<TaskAttemptID> set=trackerToTasksToCleanup.remove(taskTracker);

    if (set != null) {

      for (      TaskAttemptID id : set) {

        killList.add(new KillTaskAction(id));

      }

    }

  }

  return killList;

}

Location: JobTracker.java

Content: 

/** 

 * A tracker wants to know if any of its Tasks can be committed 

 */

synchronized List<TaskTrackerAction> getTasksToSave(TaskTrackerStatus tts){

  List<TaskStatus> taskStatuses=tts.getTaskReports();

  if (taskStatuses != null) {

    List<TaskTrackerAction> saveList=new ArrayList<TaskTrackerAction>();

    for (    TaskStatus taskStatus : taskStatuses) {

      if (taskStatus.getRunState() == TaskStatus.State.COMMIT_PENDING) {

        TaskAttemptID taskId=taskStatus.getTaskID();

        TaskInProgress tip=taskidToTIPMap.get(taskId);

        if (tip == null) {

          continue;

        }

        if (tip.shouldCommit(taskId)) {

          saveList.add(new CommitTaskAction(taskId));

          if (LOG.isDebugEnabled()) {

            LOG.debug(tts.getTrackerName() + " -> CommitTaskAction: " + taskId);

          }

        }

      }

    }

    return saveList;

  }

  return null;

}

Location: JobTracker.java

Content: 

synchronized public TaskTrackerStatus getTaskTrackerStatus(String trackerID){

  TaskTracker taskTracker;

synchronized (taskTrackers) {

    taskTracker=taskTrackers.get(trackerID);

  }

  return (taskTracker == null) ? null : taskTracker.getStatus();

}

Location: JobTracker.java

Content: 

synchronized public TaskTracker getTaskTracker(String trackerID){

synchronized (taskTrackers) {

    return taskTrackers.get(trackerID);

  }

}

Location: JobTracker.java

Content: 

/** 

 * Returns the counters for the specified task in progress.

 */

Counters getTipCounters(TaskID tipid){

  TaskInProgress tip=getTip(tipid);

  return (tip == null ? null : tip.getCounters());

}

Location: JobTracker.java

Content: 

/** 

 * Returns specified TaskInProgress, or null.

 */

public TaskInProgress getTip(TaskID tipid){

  JobInProgress job=jobs.get(tipid.getJobID());

  return (job == null ? null : job.getTaskInProgress(tipid));

}

Location: JobTracker.java

Content: 

public int getTotalSubmissions(){

  return totalSubmissions;

}

Location: JobTracker.java

Content: 

/** 

 * Get the unique identifier (ie. timestamp) of this job tracker start.

 * @return a string with a unique identifier

 */

public String getTrackerIdentifier(){

  return trackerIdentifier;

}

Location: JobTracker.java

Content: 

public int getTrackerPort(){

  return port;

}

Location: JobTracker.java

Content: 

/** 

 * Whether this tracker has tasks with FAILED_UNCLEAN state.   

 */

static boolean hasFailedUncleanTask(TaskTrackerStatus taskTracker){

  for (  TaskStatus taskStatus : taskTracker.getTaskReports()) {

    if (taskStatus.getRunState() == TaskStatus.State.FAILED_UNCLEAN) {

      return true;

    }

  }

  return false;

}

Location: JobTracker.java

Content: 

/** 

 * Whether the JT has recovered upon restart

 */

public boolean hasRecovered(){

  return hasRecovered;

}

Location: JobTracker.java

Content: 

/** 

 * The periodic heartbeat mechanism between the  {@link TaskTracker} andthe  {@link JobTracker}. The  {@link JobTracker} processes the status information sent by the {@link TaskTracker} and responds with instructions to start/stop tasks or jobs, and also 'reset' instructions during contingencies. 

 */

public synchronized HeartbeatResponse heartbeat(TaskTrackerStatus status,boolean restarted,boolean initialContact,boolean acceptNewTasks,short responseId) throws IOException {

  if (LOG.isDebugEnabled()) {

    LOG.debug("Got heartbeat from: " + status.getTrackerName() + " (restarted: "+ restarted+ " initialContact: "+ initialContact+ " acceptNewTasks: "+ acceptNewTasks+ ")"+ " with responseId: "+ responseId);

  }

  if (!acceptTaskTracker(status)) {

    throw new DisallowedTaskTrackerException(status);

  }

  String trackerName=status.getTrackerName();

  long now=clock.getTime();

  boolean isBlacklisted=false;

  if (restarted) {

    faultyTrackers.markTrackerHealthy(status.getHost());

  }

 else {

    isBlacklisted=faultyTrackers.shouldAssignTasksToTracker(status.getHost(),now);

  }

  HeartbeatResponse prevHeartbeatResponse=trackerToHeartbeatResponseMap.get(trackerName);

  if (initialContact != true) {

    if (prevHeartbeatResponse == null) {

      LOG.warn("Serious problem, cannot find record of 'previous' " + "heartbeat for '" + trackerName + "'; reinitializing the tasktracker");

      return new HeartbeatResponse(responseId,new TaskTrackerAction[]{new ReinitTrackerAction()});

    }

 else {

      if (prevHeartbeatResponse.getResponseId() != responseId) {

        LOG.info("Ignoring 'duplicate' heartbeat from '" + trackerName + "'; resending the previous 'lost' response");

        return prevHeartbeatResponse;

      }

    }

  }

  short newResponseId=(short)(responseId + 1);

  status.setLastSeen(now);

  if (!processHeartbeat(status,initialContact)) {

    if (prevHeartbeatResponse != null) {

      trackerToHeartbeatResponseMap.remove(trackerName);

    }

    return new HeartbeatResponse(newResponseId,new TaskTrackerAction[]{new ReinitTrackerAction()});

  }

  HeartbeatResponse response=new HeartbeatResponse(newResponseId,null);

  List<TaskTrackerAction> actions=new ArrayList<TaskTrackerAction>();

  isBlacklisted=faultyTrackers.isBlacklisted(status.getHost());

  if (acceptNewTasks && !isBlacklisted) {

    TaskTrackerStatus taskTrackerStatus=getTaskTrackerStatus(trackerName);

    if (taskTrackerStatus == null) {

      LOG.warn("Unknown task tracker polling; ignoring: " + trackerName);

    }

 else {

      List<Task> tasks=getSetupAndCleanupTasks(taskTrackerStatus);

      if (tasks == null) {

        tasks=taskScheduler.assignTasks(taskTrackers.get(trackerName));

      }

      if (tasks != null) {

        for (        Task task : tasks) {

          expireLaunchingTasks.addNewTask(task.getTaskID());

          if (LOG.isDebugEnabled()) {

            LOG.debug(trackerName + " -> LaunchTask: " + task.getTaskID());

          }

          actions.add(new LaunchTaskAction(task));

        }

      }

    }

  }

  List<TaskTrackerAction> killTasksList=getTasksToKill(trackerName);

  if (killTasksList != null) {

    actions.addAll(killTasksList);

  }

  List<TaskTrackerAction> killJobsList=getJobsForCleanup(trackerName);

  if (killJobsList != null) {

    actions.addAll(killJobsList);

  }

  List<TaskTrackerAction> commitTasksList=getTasksToSave(status);

  if (commitTasksList != null) {

    actions.addAll(commitTasksList);

  }

  int nextInterval=getNextHeartbeatInterval();

  response.setHeartbeatInterval(nextInterval);

  response.setActions(actions.toArray(new TaskTrackerAction[actions.size()]));

  trackerToHeartbeatResponseMap.put(trackerName,response);

  removeMarkedTasks(trackerName);

  return response;

}

Location: JobTracker.java

Content: 

/** 

 * Test method to increment the fault This method is synchronized to make sure that the locking order  "faultyTrackers.potentiallyFaultyTrackers lock followed by taskTrackers  lock" is under JobTracker lock to avoid deadlocks.

 */

synchronized void incrementFaults(String hostName){

  faultyTrackers.incrementFaults(hostName);

}

Location: JobTracker.java

Content: 

void incrementReservations(TaskType type,int reservedSlots){

  if (type.equals(TaskType.MAP)) {

    reservedMapSlots+=reservedSlots;

  }

 else   if (type.equals(TaskType.REDUCE)) {

    reservedReduceSlots+=reservedSlots;

  }

}

Location: JobTracker.java

Content: 

/** 

 * Return if the specified tasktracker is in the exclude list.

 */

private boolean inExcludedHostsList(TaskTrackerStatus status){

  Set<String> excludeList=hostsReader.getExcludedHosts();

  return excludeList.contains(status.getHost());

}

Location: JobTracker.java

Content: 

/** 

 * Return if the specified tasktracker is in the hosts list,  if one was configured.  If none was configured, then this  returns true.

 */

private boolean inHostsList(TaskTrackerStatus status){

  Set<String> hostsList=hostsReader.getHosts();

  return (hostsList.isEmpty() || hostsList.contains(status.getHost()));

}

Location: JobTracker.java

Content: 

private void initializeTaskMemoryRelatedConfig(){

  memSizeForMapSlotOnJT=JobConf.normalizeMemoryConfigValue(conf.getLong(MAPMEMORY_MB,JobConf.DISABLED_MEMORY_LIMIT));

  memSizeForReduceSlotOnJT=JobConf.normalizeMemoryConfigValue(conf.getLong(REDUCEMEMORY_MB,JobConf.DISABLED_MEMORY_LIMIT));

  if (conf.get(JobConf.UPPER_LIMIT_ON_TASK_VMEM_PROPERTY) != null) {

    LOG.warn(JobConf.deprecatedString(JobConf.UPPER_LIMIT_ON_TASK_VMEM_PROPERTY) + " instead use " + JTConfig.JT_MAX_MAPMEMORY_MB+ " and "+ JTConfig.JT_MAX_REDUCEMEMORY_MB);

    limitMaxMemForMapTasks=limitMaxMemForReduceTasks=JobConf.normalizeMemoryConfigValue(conf.getLong(JobConf.UPPER_LIMIT_ON_TASK_VMEM_PROPERTY,JobConf.DISABLED_MEMORY_LIMIT));

    if (limitMaxMemForMapTasks != JobConf.DISABLED_MEMORY_LIMIT && limitMaxMemForMapTasks >= 0) {

      limitMaxMemForMapTasks=limitMaxMemForReduceTasks=limitMaxMemForMapTasks / (1024 * 1024);

    }

  }

 else {

    limitMaxMemForMapTasks=JobConf.normalizeMemoryConfigValue(conf.getLong(JTConfig.JT_MAX_MAPMEMORY_MB,JobConf.DISABLED_MEMORY_LIMIT));

    limitMaxMemForReduceTasks=JobConf.normalizeMemoryConfigValue(conf.getLong(JTConfig.JT_MAX_REDUCEMEMORY_MB,JobConf.DISABLED_MEMORY_LIMIT));

  }

  LOG.info(new StringBuilder().append("Scheduler configured with ").append("(memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT,").append(" limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (").append(memSizeForMapSlotOnJT).append(", ").append(memSizeForReduceSlotOnJT).append(", ").append(limitMaxMemForMapTasks).append(", ").append(limitMaxMemForReduceTasks).append(")"));

}

Location: JobTracker.java

Content: 

/** 

 * Initialize a job and inform the listeners about a state change, if any. Other components in the framework should use this api to initialize a job.

 */

public void initJob(JobInProgress job){

  if (null == job) {

    LOG.info("Init on null job is not valid");

    return;

  }

  try {

    JobStatus prevStatus=(JobStatus)job.getStatus().clone();

    LOG.info("Initializing " + job.getJobID());

    job.initTasks();

    if (job.isJobEmpty()) {

      completeEmptyJob(job);

    }

 else     if (!job.isSetupCleanupRequired()) {

      job.completeSetup();

    }

    JobStatus newStatus=(JobStatus)job.getStatus().clone();

    if (prevStatus.getRunState() != newStatus.getRunState()) {

      JobStatusChangeEvent event=new JobStatusChangeEvent(job,EventType.RUN_STATE_CHANGED,prevStatus,newStatus);

synchronized (JobTracker.this) {

        updateJobInProgressListeners(event);

      }

    }

  }

 catch (  KillInterruptedException kie) {

    LOG.error("Job initialization interrupted :\n" + StringUtils.stringifyException(kie));

    killJob(job);

  }

catch (  Throwable t) {

    LOG.error("Job initialization failed:\n" + StringUtils.stringifyException(t));

    failJob(job);

  }

}

Location: JobTracker.java

Content: 

/** 

 * @return true if delegation token operation is allowed

 */

private boolean isAllowedDelegationTokenOp() throws IOException {

  AuthenticationMethod authMethod=UserGroupInformation.getRealAuthenticationMethod(UserGroupInformation.getCurrentUser());

  if (UserGroupInformation.isSecurityEnabled() && (authMethod != AuthenticationMethod.KERBEROS)) {

    return false;

  }

  return true;

}

Location: JobTracker.java

Content: 

/** 

 * Whether the tracker is blacklisted or not

 * @param trackerID

 * @return true if blacklisted, false otherwise

 */

synchronized public boolean isBlacklisted(String trackerID){

  TaskTrackerStatus status=getTaskTrackerStatus(trackerID);

  if (status != null) {

    return faultyTrackers.isBlacklisted(status.getHost());

  }

  return false;

}

Location: JobTracker.java

Content: 

/** 

 * Check if the <code>job</code> has been initialized.

 * @param job {@link JobInProgress} to be checked

 * @return <code>true</code> if the job has been initialized,<code>false</code> otherwise

 */

private boolean isJobInited(JobInProgress job){

  return job.inited();

}

Location: JobTracker.java

Content: 

public JobStatus[] jobsToComplete(){

  return getJobStatus(jobs.values(),true);

}

Location: JobTracker.java

Content: 

JobTracker(){

  hostsReader=null;

  retiredJobsCacheSize=0;

  infoServer=null;

  queueManager=null;

  aclsManager=null;

  taskScheduler=null;

  trackerIdentifier=null;

  recoveryManager=null;

  jobHistory=null;

  completedJobStatusStore=null;

  tasktrackerExpiryInterval=0;

  myInstrumentation=new JobTrackerMetricsInst(this,new JobConf());

  secretManager=null;

  localFs=null;

}

Location: JobTracker.java

Content: 

JobTracker(JobConf conf) throws IOException, InterruptedException {

  this(conf,new Clock());

}

Location: JobTracker.java

Content: 

/** 

 * Start the JobTracker process, listen on the indicated port

 */

JobTracker(JobConf conf,Clock clock) throws IOException, InterruptedException {

  this(conf,clock,generateNewIdentifier());

}

Location: JobTracker.java

Content: 

JobTracker(final JobConf conf,Clock clock,boolean ignoredForSimulation) throws IOException {

  this.clock=clock;

  this.conf=conf;

  trackerIdentifier=getDateFormat().format(new Date());

  if (fs == null) {

    fs=FileSystem.get(conf);

  }

  this.localFs=FileSystem.getLocal(conf);

  tasktrackerExpiryInterval=conf.getLong("mapred.tasktracker.expiry.interval",10 * 60 * 1000);

  retiredJobsCacheSize=conf.getInt("mapred.job.tracker.retiredjobs.cache.size",1000);

  MAX_BLACKLISTS_PER_TRACKER=conf.getInt("mapred.max.tracker.blacklists",4);

  NUM_HEARTBEATS_IN_SECOND=conf.getInt("mapred.heartbeats.in.second",100);

  InetSocketAddress addr=getAddress(conf);

  this.localMachine=addr.getHostName();

  this.port=addr.getPort();

  UserGroupInformation.setConfiguration(conf);

  SecurityUtil.login(conf,JTConfig.JT_KEYTAB_FILE,JTConfig.JT_USER_NAME,localMachine);

  secretManager=null;

  this.hostsReader=new HostsFileReader(conf.get(JTConfig.JT_HOSTS_FILENAME,""),conf.get(JTConfig.JT_HOSTS_EXCLUDE_FILENAME,""));

  Configuration clusterConf=new Configuration(this.conf);

  queueManager=new QueueManager(clusterConf);

  aclsManager=new ACLsManager(conf,new JobACLsManager(conf),queueManager);

  LOG.info("Starting jobtracker with owner as " + getMROwner().getShortUserName());

  Class<? extends TaskScheduler> schedulerClass=conf.getClass(JTConfig.JT_TASK_SCHEDULER,JobQueueTaskScheduler.class,TaskScheduler.class);

  taskScheduler=(TaskScheduler)ReflectionUtils.newInstance(schedulerClass,conf);

  InetSocketAddress infoSocAddr=NetUtils.createSocketAddr(conf.get(JTConfig.JT_HTTP_ADDRESS,"0.0.0.0:50030"));

  String infoBindAddress=infoSocAddr.getHostName();

  int tmpInfoPort=infoSocAddr.getPort();

  this.startTime=clock.getTime();

  infoServer=new HttpServer("job",infoBindAddress,tmpInfoPort,tmpInfoPort == 0,conf);

  infoServer.setAttribute("job.tracker",this);

  FileSystem historyFS=null;

  jobHistory=new JobHistory();

  final JobTracker jtFinal=this;

  try {

    historyFS=getMROwner().doAs(new PrivilegedExceptionAction<FileSystem>(){

      public FileSystem run() throws IOException {

        jobHistory.init(jtFinal,conf,jtFinal.localMachine,jtFinal.startTime);

        jobHistory.initDone(conf,fs);

        final String historyLogDir=jobHistory.getCompletedJobHistoryLocation().toString();

        infoServer.setAttribute("historyLogDir",historyLogDir);

        return new Path(historyLogDir).getFileSystem(conf);

      }

    }

);

  }

 catch (  InterruptedException e1) {

    throw (IOException)new IOException().initCause(e1);

  }

  infoServer.setAttribute("fileSys",historyFS);

  infoServer.addServlet("reducegraph","/taskgraph",TaskGraphServlet.class);

  infoServer.start();

  this.infoPort=this.infoServer.getPort();

  JobTrackerInstrumentation tmp;

  try {

    Class<? extends JobTrackerInstrumentation> metricsInst=getInstrumentationClass(conf);

    java.lang.reflect.Constructor<? extends JobTrackerInstrumentation> c=metricsInst.getConstructor(new Class[]{JobTracker.class,JobConf.class});

    tmp=c.newInstance(this,conf);

  }

 catch (  Exception e) {

    LOG.error("failed to initialize job tracker metrics",e);

    tmp=new JobTrackerMetricsInst(this,conf);

  }

  myInstrumentation=tmp;

  recoveryManager=new RecoveryManager();

  this.dnsToSwitchMapping=ReflectionUtils.newInstance(conf.getClass(CommonConfigurationKeys.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY,ScriptBasedMapping.class,DNSToSwitchMapping.class),conf);

  this.numTaskCacheLevels=conf.getInt("mapred.task.cache.levels",NetworkTopology.DEFAULT_HOST_LEVEL);

  completedJobStatusStore=new CompletedJobStatusStore(conf,aclsManager);

}

Location: JobTracker.java

Content: 

JobTracker(final JobConf conf,Clock newClock,String jobtrackerIndentifier) throws IOException, InterruptedException {

  InetSocketAddress addr=getAddress(conf);

  this.localMachine=addr.getHostName();

  this.port=addr.getPort();

  UserGroupInformation.setConfiguration(conf);

  SecurityUtil.login(conf,JTConfig.JT_KEYTAB_FILE,JTConfig.JT_USER_NAME,localMachine);

  clock=newClock;

  long secretKeyInterval=conf.getLong(MRConfig.DELEGATION_KEY_UPDATE_INTERVAL_KEY,MRConfig.DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT);

  long tokenMaxLifetime=conf.getLong(MRConfig.DELEGATION_TOKEN_MAX_LIFETIME_KEY,MRConfig.DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT);

  long tokenRenewInterval=conf.getLong(MRConfig.DELEGATION_TOKEN_RENEW_INTERVAL_KEY,MRConfig.DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT);

  secretManager=new DelegationTokenSecretManager(secretKeyInterval,tokenMaxLifetime,tokenRenewInterval,DELEGATION_TOKEN_GC_INTERVAL);

  secretManager.startThreads();

  tasktrackerExpiryInterval=conf.getLong(JT_TRACKER_EXPIRY_INTERVAL,10 * 60 * 1000);

  retiredJobsCacheSize=conf.getInt(JT_RETIREJOB_CACHE_SIZE,1000);

  MAX_BLACKLISTS_PER_TRACKER=conf.getInt(JTConfig.JT_MAX_TRACKER_BLACKLISTS,4);

  NUM_HEARTBEATS_IN_SECOND=conf.getInt(JT_HEARTBEATS_IN_SECOND,DEFAULT_NUM_HEARTBEATS_IN_SECOND);

  if (NUM_HEARTBEATS_IN_SECOND < MIN_NUM_HEARTBEATS_IN_SECOND) {

    NUM_HEARTBEATS_IN_SECOND=DEFAULT_NUM_HEARTBEATS_IN_SECOND;

  }

  HEARTBEATS_SCALING_FACTOR=conf.getFloat(JT_HEARTBEATS_SCALING_FACTOR,DEFAULT_HEARTBEATS_SCALING_FACTOR);

  if (HEARTBEATS_SCALING_FACTOR < MIN_HEARTBEATS_SCALING_FACTOR) {

    HEARTBEATS_SCALING_FACTOR=DEFAULT_HEARTBEATS_SCALING_FACTOR;

  }

  HEARTBEAT_INTERVAL_MIN=conf.getInt(JT_HEARTBEAT_INTERVAL_MIN,JT_HEARTBEAT_INTERVAL_MIN_DEFAULT);

  AVERAGE_BLACKLIST_THRESHOLD=conf.getFloat(JTConfig.JT_AVG_BLACKLIST_THRESHOLD,0.5f);

  this.conf=conf;

  JobConf jobConf=new JobConf(conf);

  initializeTaskMemoryRelatedConfig();

  this.hostsReader=new HostsFileReader(conf.get(JTConfig.JT_HOSTS_FILENAME,""),conf.get(JTConfig.JT_HOSTS_EXCLUDE_FILENAME,""));

  Configuration clusterConf=new Configuration(this.conf);

  queueManager=new QueueManager(clusterConf);

  aclsManager=new ACLsManager(conf,new JobACLsManager(conf),queueManager);

  LOG.info("Starting jobtracker with owner as " + getMROwner().getShortUserName());

  Class<? extends TaskScheduler> schedulerClass=conf.getClass(JT_TASK_SCHEDULER,JobQueueTaskScheduler.class,TaskScheduler.class);

  taskScheduler=(TaskScheduler)ReflectionUtils.newInstance(schedulerClass,conf);

  int handlerCount=conf.getInt(JT_IPC_HANDLER_COUNT,10);

  this.interTrackerServer=RPC.getServer(ClientProtocol.class,this,addr.getHostName(),addr.getPort(),handlerCount,false,conf,secretManager);

  if (conf.getBoolean(CommonConfigurationKeys.HADOOP_SECURITY_AUTHORIZATION,false)) {

    this.interTrackerServer.refreshServiceAcl(conf,new MapReducePolicyProvider());

  }

  if (LOG.isDebugEnabled()) {

    Properties p=System.getProperties();

    for (Iterator it=p.keySet().iterator(); it.hasNext(); ) {

      String key=(String)it.next();

      String val=p.getProperty(key);

      if (LOG.isDebugEnabled()) {

        LOG.debug("Property '" + key + "' is "+ val);

      }

    }

  }

  InetSocketAddress infoSocAddr=NetUtils.createSocketAddr(conf.get(JT_HTTP_ADDRESS,"0.0.0.0:50030"));

  String infoBindAddress=infoSocAddr.getHostName();

  int tmpInfoPort=infoSocAddr.getPort();

  this.startTime=clock.getTime();

  infoServer=new HttpServer("job",infoBindAddress,tmpInfoPort,tmpInfoPort == 0,conf,aclsManager.getAdminsAcl());

  infoServer.setAttribute("job.tracker",this);

  jobHistory=new JobHistory();

  jobHistory.init(this,conf,this.localMachine,this.startTime);

  infoServer.addServlet("reducegraph","/taskgraph",TaskGraphServlet.class);

  infoServer.start();

  this.trackerIdentifier=jobtrackerIndentifier;

  JobTrackerInstrumentation tmp;

  try {

    Class<? extends JobTrackerInstrumentation> metricsInst=getInstrumentationClass(jobConf);

    java.lang.reflect.Constructor<? extends JobTrackerInstrumentation> c=metricsInst.getConstructor(new Class[]{JobTracker.class,JobConf.class});

    tmp=c.newInstance(this,jobConf);

  }

 catch (  Exception e) {

    LOG.error("failed to initialize job tracker metrics",e);

    tmp=new JobTrackerMetricsInst(this,jobConf);

  }

  myInstrumentation=tmp;

  this.port=interTrackerServer.getListenerAddress().getPort();

  this.conf.set(JT_IPC_ADDRESS,(this.localMachine + ":" + this.port));

  this.localFs=FileSystem.getLocal(conf);

  LOG.info("JobTracker up at: " + this.port);

  this.infoPort=this.infoServer.getPort();

  this.conf.set(JT_HTTP_ADDRESS,infoBindAddress + ":" + this.infoPort);

  LOG.info("JobTracker webserver: " + this.infoServer.getPort());

  recoveryManager=new RecoveryManager();

  while (!Thread.currentThread().isInterrupted()) {

    try {

      if (fs == null) {

        fs=getMROwner().doAs(new PrivilegedExceptionAction<FileSystem>(){

          public FileSystem run() throws IOException {

            return FileSystem.get(conf);

          }

        }

);

      }

      if (systemDir == null) {

        systemDir=new Path(getSystemDir());

      }

      try {

        FileStatus systemDirStatus=fs.getFileStatus(systemDir);

        if (!systemDirStatus.getOwner().equals(getMROwner().getShortUserName())) {

          throw new AccessControlException("The systemdir " + systemDir + " is not owned by "+ getMROwner().getShortUserName());

        }

        if (!systemDirStatus.getPermission().equals(SYSTEM_DIR_PERMISSION)) {

          LOG.warn("Incorrect permissions on " + systemDir + ". Setting it to "+ SYSTEM_DIR_PERMISSION);

          fs.setPermission(systemDir,new FsPermission(SYSTEM_DIR_PERMISSION));

        }

      }

 catch (      FileNotFoundException fnf) {

      }

      FileStatus[] systemDirData;

      try {

        systemDirData=fs.listStatus(this.systemDir);

      }

 catch (      FileNotFoundException fnfe) {

        systemDirData=null;

      }

      if (conf.getBoolean(JT_RESTART_ENABLED,false) && systemDirData != null) {

        for (        FileStatus status : systemDirData) {

          try {

            recoveryManager.addJobForRecovery(status);

          }

 catch (          Throwable t) {

            LOG.warn("Failed to add the job " + status.getPath().getName(),t);

          }

        }

        if (recoveryManager.shouldRecover()) {

          break;

        }

      }

      if (!fs.exists(systemDir)) {

        LOG.info("Creating the system directory");

        if (FileSystem.mkdirs(fs,systemDir,new FsPermission(SYSTEM_DIR_PERMISSION))) {

          break;

        }

 else {

          LOG.error("Mkdirs failed to create " + systemDir);

        }

      }

 else {

        LOG.info("Cleaning up the system directory");

        fs.setPermission(systemDir,new FsPermission(SYSTEM_DIR_PERMISSION));

        deleteContents(fs,systemDir);

        break;

      }

    }

 catch (    AccessControlException ace) {

      LOG.warn("Failed to operate on " + JTConfig.JT_SYSTEM_DIR + "("+ systemDir.makeQualified(fs)+ ") because of permissions.");

      LOG.warn("This directory should exist and be owned by the user '" + UserGroupInformation.getCurrentUser() + "'");

      LOG.warn("Bailing out ... ");

      throw ace;

    }

catch (    IOException ie) {

      LOG.info("problem cleaning system directory: " + systemDir.makeQualified(fs),ie);

    }

    Thread.sleep(FS_ACCESS_RETRY_PERIOD);

  }

  if (Thread.currentThread().isInterrupted()) {

    throw new InterruptedException();

  }

  asyncDiskService=new MRAsyncDiskService(FileSystem.getLocal(conf),conf.getLocalDirs());

  asyncDiskService.moveAndDeleteFromEachVolume(SUBDIR);

  jobHistory.initDone(conf,fs);

  final String historyLogDir=jobHistory.getCompletedJobHistoryLocation().toString();

  infoServer.setAttribute("historyLogDir",historyLogDir);

  FileSystem historyFS=getMROwner().doAs(new PrivilegedExceptionAction<FileSystem>(){

    public FileSystem run() throws IOException {

      return new Path(historyLogDir).getFileSystem(conf);

    }

  }

);

  infoServer.setAttribute("fileSys",historyFS);

  this.dnsToSwitchMapping=ReflectionUtils.newInstance(conf.getClass(CommonConfigurationKeys.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY,ScriptBasedMapping.class,DNSToSwitchMapping.class),conf);

  this.numTaskCacheLevels=conf.getInt(JT_TASKCACHE_LEVELS,NetworkTopology.DEFAULT_HOST_LEVEL);

  completedJobStatusStore=new CompletedJobStatusStore(conf,aclsManager);

  plugins=conf.getInstances(JT_PLUGINS,ServicePlugin.class);

  for (  ServicePlugin p : plugins) {

    try {

      p.start(this);

      LOG.info("Started plug-in " + p + " of type "+ p.getClass());

    }

 catch (    Throwable t) {

      LOG.warn("ServicePlugin " + p + " of type "+ p.getClass()+ " could not be started",t);

    }

  }

}

Location: JobTracker.java

Content: 

private synchronized void killJob(JobInProgress job){

  LOG.info("Killing job " + job.getJobID());

  JobStatus prevStatus=(JobStatus)job.getStatus().clone();

  job.kill();

  JobStatus newStatus=(JobStatus)job.getStatus().clone();

  if (prevStatus.getRunState() != newStatus.getRunState() && newStatus.getRunState() == JobStatus.KILLED) {

    JobStatusChangeEvent event=new JobStatusChangeEvent(job,EventType.RUN_STATE_CHANGED,prevStatus,newStatus);

    updateJobInProgressListeners(event);

  }

}

Location: JobTracker.java

Content: 

/** 

 * @see ClientProtocol#killJob(org.apache.hadoop.mapreduce.JobID)

 */

@Override public synchronized void killJob(org.apache.hadoop.mapreduce.JobID jobid) throws IOException {

  killJob(JobID.downgrade(jobid));

}

Location: JobTracker.java

Content: 

/** 

 * @see org.apache.hadoop.mapreduce.protocol.ClientProtocol#killTask(org.apache.hadoop.mapreduce.TaskAttemptID,boolean)

 */

@Override public synchronized boolean killTask(org.apache.hadoop.mapreduce.TaskAttemptID taskid,boolean shouldFail) throws IOException {

  return killTask(TaskAttemptID.downgrade(taskid),shouldFail);

}

Location: JobTracker.java

Content: 

/** 

 * We lost the task tracker!  All task-tracker structures have  already been updated.  Just process the contained tasks and any jobs that might be affected.

 */

void lostTaskTracker(TaskTracker taskTracker){

  String trackerName=taskTracker.getTrackerName();

  LOG.info("Lost tracker '" + trackerName + "'");

synchronized (trackerToJobsToCleanup) {

    trackerToJobsToCleanup.remove(trackerName);

  }

synchronized (trackerToTasksToCleanup) {

    trackerToTasksToCleanup.remove(trackerName);

  }

  Set<TaskAttemptID> lostTasks=trackerToTaskMap.get(trackerName);

  trackerToTaskMap.remove(trackerName);

  if (lostTasks != null) {

    Set<JobInProgress> jobsWithFailures=new HashSet<JobInProgress>();

    for (    TaskAttemptID taskId : lostTasks) {

      TaskInProgress tip=taskidToTIPMap.get(taskId);

      JobInProgress job=tip.getJob();

      if (!tip.isComplete() || (tip.isMapTask() && !tip.isJobSetupTask() && job.desiredReduces() != 0)) {

        if (job.getStatus().getRunState() == JobStatus.RUNNING || job.getStatus().getRunState() == JobStatus.PREP) {

          TaskStatus.State killState=(tip.isRunningTask(taskId) && !tip.isJobSetupTask() && !tip.isJobCleanupTask()) ? TaskStatus.State.KILLED_UNCLEAN : TaskStatus.State.KILLED;

          job.failedTask(tip,taskId,("Lost task tracker: " + trackerName),(tip.isMapTask() ? TaskStatus.Phase.MAP : TaskStatus.Phase.REDUCE),killState,trackerName);

          jobsWithFailures.add(job);

        }

      }

 else {

        markCompletedTaskAttempt(trackerName,taskId);

      }

    }

    for (    JobInProgress job : jobsWithFailures) {

      job.addTrackerTaskFailure(trackerName,taskTracker);

    }

    taskTracker.cancelAllReservations();

    removeMarkedTasks(trackerName);

  }

}

Location: JobTracker.java

Content: 

/** 

 * Mark all 'non-running' jobs of the job for pruning. This function assumes that the JobTracker is locked on entry.

 * @param job the completed job

 */

void markCompletedJob(JobInProgress job){

  for (  TaskInProgress tip : job.getTasks(TaskType.JOB_SETUP)) {

    for (    TaskStatus taskStatus : tip.getTaskStatuses()) {

      if (taskStatus.getRunState() != TaskStatus.State.RUNNING && taskStatus.getRunState() != TaskStatus.State.COMMIT_PENDING && taskStatus.getRunState() != TaskStatus.State.UNASSIGNED) {

        markCompletedTaskAttempt(taskStatus.getTaskTracker(),taskStatus.getTaskID());

      }

    }

  }

  for (  TaskInProgress tip : job.getTasks(TaskType.MAP)) {

    for (    TaskStatus taskStatus : tip.getTaskStatuses()) {

      if (taskStatus.getRunState() != TaskStatus.State.RUNNING && taskStatus.getRunState() != TaskStatus.State.COMMIT_PENDING && taskStatus.getRunState() != TaskStatus.State.FAILED_UNCLEAN && taskStatus.getRunState() != TaskStatus.State.KILLED_UNCLEAN && taskStatus.getRunState() != TaskStatus.State.UNASSIGNED) {

        markCompletedTaskAttempt(taskStatus.getTaskTracker(),taskStatus.getTaskID());

      }

    }

  }

  for (  TaskInProgress tip : job.getTasks(TaskType.REDUCE)) {

    for (    TaskStatus taskStatus : tip.getTaskStatuses()) {

      if (taskStatus.getRunState() != TaskStatus.State.RUNNING && taskStatus.getRunState() != TaskStatus.State.COMMIT_PENDING && taskStatus.getRunState() != TaskStatus.State.FAILED_UNCLEAN && taskStatus.getRunState() != TaskStatus.State.KILLED_UNCLEAN && taskStatus.getRunState() != TaskStatus.State.UNASSIGNED) {

        markCompletedTaskAttempt(taskStatus.getTaskTracker(),taskStatus.getTaskID());

      }

    }

  }

}

Location: JobTracker.java

Content: 

/** 

 * Mark a 'task' for removal later. This function assumes that the JobTracker is locked on entry.

 * @param taskTracker the tasktracker at which the 'task' was running

 * @param taskid completed (success/failure/killed) task

 */

void markCompletedTaskAttempt(String taskTracker,TaskAttemptID taskid){

  Set<TaskAttemptID> taskset=trackerToMarkedTasksMap.get(taskTracker);

  if (taskset == null) {

    taskset=new TreeSet<TaskAttemptID>();

    trackerToMarkedTasksMap.put(taskTracker,taskset);

  }

  taskset.add(taskid);

  if (LOG.isDebugEnabled()) {

    LOG.debug("Marked '" + taskid + "' from '"+ taskTracker+ "'");

  }

}

Location: JobTracker.java

Content: 

/** 

 * Run forever

 */

public void offerService() throws InterruptedException, IOException {

  while (true) {

    try {

      recoveryManager.updateRestartCount();

      break;

    }

 catch (    IOException ioe) {

      LOG.warn("Failed to initialize recovery manager. ",ioe);

      Thread.sleep(FS_ACCESS_RETRY_PERIOD);

      LOG.warn("Retrying...");

    }

  }

  taskScheduler.start();

  recoveryManager.recover();

  refreshHosts();

  startExpireTrackersThread();

  expireLaunchingTaskThread.start();

  if (completedJobStatusStore.isActive()) {

    completedJobsStoreThread=new Thread(completedJobStatusStore,"completedjobsStore-housekeeper");

    completedJobsStoreThread.start();

  }

  this.interTrackerServer.start();

synchronized (this) {

    state=State.RUNNING;

  }

  LOG.info("Starting RUNNING");

  this.interTrackerServer.join();

  LOG.info("Stopped interTrackerServer");

}

Location: JobTracker.java

Content: 

private boolean perTaskMemoryConfigurationSetOnJT(){

  if (limitMaxMemForMapTasks == JobConf.DISABLED_MEMORY_LIMIT || limitMaxMemForReduceTasks == JobConf.DISABLED_MEMORY_LIMIT || memSizeForMapSlotOnJT == JobConf.DISABLED_MEMORY_LIMIT || memSizeForReduceSlotOnJT == JobConf.DISABLED_MEMORY_LIMIT) {

    return false;

  }

  return true;

}

Location: JobTracker.java

Content: 

/** 

 * Process incoming heartbeat messages from the task trackers.

 */

synchronized boolean processHeartbeat(TaskTrackerStatus trackerStatus,boolean initialContact){

  getInstrumentation().heartbeat();

  String trackerName=trackerStatus.getTrackerName();

synchronized (taskTrackers) {

synchronized (trackerExpiryQueue) {

      boolean seenBefore=updateTaskTrackerStatus(trackerName,trackerStatus);

      TaskTracker taskTracker=getTaskTracker(trackerName);

      if (initialContact) {

        if (seenBefore) {

          lostTaskTracker(taskTracker);

        }

      }

 else {

        if (!seenBefore) {

          LOG.warn("Status from unknown Tracker : " + trackerName);

          updateTaskTrackerStatus(trackerName,null);

          return false;

        }

      }

      if (initialContact) {

        if (isBlacklisted(trackerName)) {

          faultyTrackers.incrBlackListedTrackers(1);

        }

        addNewTracker(taskTracker);

      }

    }

  }

  updateTaskStatuses(trackerStatus);

  updateNodeHealthStatus(trackerStatus);

  return true;

}

Location: JobTracker.java

Content: 

private synchronized void refreshHosts() throws IOException {

  LOG.info("Refreshing hosts information");

  Configuration conf=new Configuration();

  hostsReader.updateFileNames(conf.get(JTConfig.JT_HOSTS_FILENAME,""),conf.get(JTConfig.JT_HOSTS_EXCLUDE_FILENAME,""));

  hostsReader.refresh();

  Set<String> excludeSet=new HashSet<String>();

  for (  Map.Entry<String,TaskTracker> eSet : taskTrackers.entrySet()) {

    String trackerName=eSet.getKey();

    TaskTrackerStatus status=eSet.getValue().getStatus();

    if (!inHostsList(status) || inExcludedHostsList(status)) {

      excludeSet.add(status.getHost());

    }

  }

  decommissionNodes(excludeSet);

}

Location: JobTracker.java

Content: 

@Override public void refreshServiceAcl() throws IOException {

  if (!conf.getBoolean(CommonConfigurationKeys.HADOOP_SECURITY_AUTHORIZATION,false)) {

    throw new AuthorizationException("Service Level Authorization not enabled!");

  }

  this.interTrackerServer.refreshServiceAcl(conf,new MapReducePolicyProvider());

}

Location: JobTracker.java

Content: 

public void removeJobInProgressListener(JobInProgressListener listener){

  jobInProgressListeners.remove(listener);

}

Location: JobTracker.java

Content: 

/** 

 * Call  {@link #removeTaskEntry(String)} for each of thejob's tasks. When the job is retiring we can afford to nuke all it's tasks

 * @param job the job about to be 'retired'

 */

synchronized void removeJobTasks(JobInProgress job){

  for (  TaskType type : TaskType.values()) {

    for (    TaskInProgress tip : job.getTasks(type)) {

      for (      TaskAttemptID id : tip.getAllTaskAttemptIDs()) {

        removeTaskEntry(id);

      }

    }

  }

}

Location: JobTracker.java

Content: 

/** 

 * Remove all 'marked' tasks running on a given  {@link TaskTracker}from the  {@link JobTracker}'s data-structures. This function assumes that the JobTracker is locked on entry.

 * @param taskTracker tasktracker whose 'non-running' tasks are to be purged

 */

void removeMarkedTasks(String taskTracker){

  Set<TaskAttemptID> markedTaskSet=trackerToMarkedTasksMap.get(taskTracker);

  if (markedTaskSet != null) {

    for (    TaskAttemptID taskid : markedTaskSet) {

      removeTaskEntry(taskid);

      if (LOG.isDebugEnabled()) {

        LOG.debug("Removed marked completed task '" + taskid + "' from '"+ taskTracker+ "'");

      }

    }

    trackerToMarkedTasksMap.remove(taskTracker);

  }

}

Location: JobTracker.java

Content: 

void removeTaskEntry(TaskAttemptID taskid){

  String tracker=taskidToTrackerMap.remove(taskid);

  if (tracker != null) {

    Set<TaskAttemptID> trackerSet=trackerToTaskMap.get(tracker);

    if (trackerSet != null) {

      trackerSet.remove(taskid);

    }

  }

  if (taskidToTIPMap.remove(taskid) != null) {

    LOG.info("Removing task '" + taskid + "'");

  }

}

Location: JobTracker.java

Content: 

private void removeTracker(TaskTracker tracker){

  lostTaskTracker(tracker);

  String trackerName=tracker.getStatus().getTrackerName();

  String hostName=JobInProgress.convertTrackerNameToHostName(trackerName);

  if (isBlacklisted(trackerName)) {

    LOG.info("Removing " + hostName + " from blacklist");

    faultyTrackers.decrBlackListedTrackers(1);

  }

  updateTaskTrackerStatus(trackerName,null);

  statistics.taskTrackerRemoved(trackerName);

  getInstrumentation().decTrackers(1);

}

Location: JobTracker.java

Content: 

public void reportTaskTrackerError(String taskTracker,String errorClass,String errorMessage) throws IOException {

  LOG.warn("Report from " + taskTracker + ": "+ errorMessage);

}

Location: JobTracker.java

Content: 

public Node resolveAndAddToTopology(String name){

  List<String> tmpList=new ArrayList<String>(1);

  tmpList.add(name);

  List<String> rNameList=dnsToSwitchMapping.resolve(tmpList);

  String rName=rNameList.get(0);

  String networkLoc=NodeBase.normalize(rName);

  return addHostToNodeMapping(name,networkLoc);

}

Location: JobTracker.java

Content: 

public synchronized void retireJob(JobID jobid,String historyFile){

synchronized (jobs) {

    JobInProgress job=jobs.get(jobid);

    if (job != null) {

      JobStatus status=job.getStatus();

      if (historyFile != null) {

        status.setHistoryFile(historyFile);

      }

      job.cleanupLocalizedJobConf(job.getProfile().getJobID());

      boolean retireJob=conf.getBoolean(JT_RETIREJOBS,true);

      if (retireJob) {

        removeJobTasks(job);

        jobs.remove(job.getProfile().getJobID());

        for (        JobInProgressListener l : jobInProgressListeners) {

          l.jobRemoved(job);

        }

        String jobUser=job.getProfile().getUser();

        LOG.info("Retired job with id: '" + job.getProfile().getJobID() + "' of user '"+ jobUser+ "'");

        retireJobs.addToCache(job.getStatus());

      }

    }

  }

}

Location: JobTracker.java

Content: 

public Vector<JobInProgress> runningJobs(){

  Vector<JobInProgress> v=new Vector<JobInProgress>();

  for (Iterator it=jobs.values().iterator(); it.hasNext(); ) {

    JobInProgress jip=(JobInProgress)it.next();

    JobStatus status=jip.getStatus();

    if (status.getRunState() == JobStatus.RUNNING) {

      v.add(jip);

    }

  }

  return v;

}

Location: JobTracker.java

Content: 

public static void setInstrumentationClass(Configuration conf,Class<? extends JobTrackerInstrumentation> t){

  conf.setClass(JT_INSTRUMENTATION,t,JobTrackerInstrumentation.class);

}

Location: JobTracker.java

Content: 

/** 

 * Set the priority of a job

 * @param jobid

 * @param priority

 * @throws IOException

 */

public synchronized void setJobPriority(org.apache.hadoop.mapreduce.JobID jobid,String priority) throws IOException {

  setJobPriority(JobID.downgrade(jobid),priority);

}

Location: JobTracker.java

Content: 

void startExpireTrackersThread(){

  this.expireTrackersThread=new Thread(this.expireTrackers,"expireTrackers");

  this.expireTrackersThread.start();

}

Location: JobTracker.java

Content: 

/** 

 * Start the JobTracker with given configuration. The conf will be modified to reflect the actual ports on which  the JobTracker is up and running if the user passes the port as <code>zero</code>.

 * @param conf configuration for the JobTracker.

 * @throws IOException

 */

public static JobTracker startTracker(JobConf conf) throws IOException, InterruptedException {

  return startTracker(conf,DEFAULT_CLOCK);

}

Location: JobTracker.java

Content: 

static JobTracker startTracker(JobConf conf,Clock clock) throws IOException, InterruptedException {

  return startTracker(conf,clock,generateNewIdentifier());

}

Location: JobTracker.java

Content: 

static JobTracker startTracker(JobConf conf,Clock clock,String identifier) throws IOException, InterruptedException {

  JobTracker result=null;

  while (true) {

    try {

      result=new JobTracker(conf,clock,identifier);

      result.taskScheduler.setTaskTrackerManager(result);

      break;

    }

 catch (    VersionMismatch e) {

      throw e;

    }

catch (    BindException e) {

      throw e;

    }

catch (    UnknownHostException e) {

      throw e;

    }

catch (    AccessControlException ace) {

      throw ace;

    }

catch (    IOException e) {

      LOG.warn("Error starting tracker: " + StringUtils.stringifyException(e));

    }

    Thread.sleep(1000);

  }

  if (result != null) {

    JobEndNotifier.startNotifier();

  }

  return result;

}

Location: JobTracker.java

Content: 

void stopExpireTrackersThread(){

  if (this.expireTrackersThread != null && this.expireTrackersThread.isAlive()) {

    LOG.info("Stopping expireTrackers");

    this.expireTrackersThread.interrupt();

    try {

      this.expireTrackersThread.join();

    }

 catch (    InterruptedException ex) {

      ex.printStackTrace();

    }

  }

}

Location: JobTracker.java

Content: 

public void stopTracker() throws IOException {

  JobEndNotifier.stopNotifier();

  close();

}

Location: JobTracker.java

Content: 

void storeCompletedJob(JobInProgress job){

  completedJobStatusStore.store(job);

}

Location: JobTracker.java

Content: 

/** 

 * Submits either a new job or a job from an earlier run.

 */

private JobStatus submitJob(org.apache.hadoop.mapreduce.JobID jobID,int restartCount,UserGroupInformation ugi,String jobSubmitDir,boolean recovered,Credentials ts) throws IOException, InterruptedException {

  JobID jobId=null;

  JobInfo jobInfo;

synchronized (this) {

    jobId=JobID.downgrade(jobID);

    if (jobs.containsKey(jobId)) {

      return jobs.get(jobId).getStatus();

    }

    jobInfo=new JobInfo(jobId,new Text(ugi.getShortUserName()),new Path(jobSubmitDir));

  }

  JobInProgress job=new JobInProgress(this,this.conf,restartCount,jobInfo,ts);

synchronized (this) {

    try {

      checkQueueValidity(job);

    }

 catch (    IOException ioe) {

      LOG.error("Queue given for job " + job.getJobID() + " is not valid: "+ ioe);

      throw ioe;

    }

    try {

      aclsManager.checkAccess(job,ugi,Operation.SUBMIT_JOB);

    }

 catch (    AccessControlException ace) {

      LOG.warn("Access denied for user " + job.getJobConf().getUser() + ". Ignoring job "+ jobId,ace);

      throw ace;

    }

    try {

      checkMemoryRequirements(job);

    }

 catch (    IOException ioe) {

      throw ioe;

    }

    if (!recovered) {

      Path jobDir=getSystemDirectoryForJob(jobId);

      FileSystem.mkdirs(fs,jobDir,new FsPermission(SYSTEM_DIR_PERMISSION));

      FSDataOutputStream out=fs.create(getSystemFileForJob(jobId));

      jobInfo.write(out);

      out.close();

    }

    return addJob(jobId,job);

  }

}

Location: JobTracker.java

Content: 

/** 

 * JobTracker.submitJob() kicks off a new job.   Create a 'JobInProgress' object, which contains both JobProfile and JobStatus.  Those two sub-objects are sometimes shipped outside of the JobTracker.  But JobInProgress adds info that's useful for the JobTracker alone.

 */

public synchronized org.apache.hadoop.mapreduce.JobStatus submitJob(org.apache.hadoop.mapreduce.JobID jobId,String jobSubmitDir,Credentials ts) throws IOException, InterruptedException {

  return submitJob(JobID.downgrade(jobId),jobSubmitDir,ts);

}

Location: JobTracker.java

Content: 

/** 

 * Get the active and blacklisted task tracker names in the cluster. The first element in the returned list contains the list of active tracker names. The second element in the returned list contains the list of blacklisted tracker names. 

 */

synchronized public List<List<String>> taskTrackerNames(){

  List<String> activeTrackers=new ArrayList<String>();

  List<String> blacklistedTrackers=new ArrayList<String>();

synchronized (taskTrackers) {

    for (    TaskTracker tt : taskTrackers.values()) {

      TaskTrackerStatus status=tt.getStatus();

      if (!faultyTrackers.isBlacklisted(status.getHost())) {

        activeTrackers.add(status.getTrackerName());

      }

 else {

        blacklistedTrackers.add(status.getTrackerName());

      }

    }

  }

  List<List<String>> result=new ArrayList<List<String>>(2);

  result.add(activeTrackers);

  result.add(blacklistedTrackers);

  return result;

}

Location: JobTracker.java

Content: 

/** 

 * Get all the task trackers in the cluster

 * @return {@link Collection} of {@link TaskTrackerStatus} 

 */

public synchronized Collection<TaskTrackerStatus> taskTrackers(){

  Collection<TaskTrackerStatus> ttStatuses;

synchronized (taskTrackers) {

    ttStatuses=new ArrayList<TaskTrackerStatus>(taskTrackers.values().size());

    for (    TaskTracker tt : taskTrackers.values()) {

      ttStatuses.add(tt.getStatus());

    }

  }

  return ttStatuses;

}

Location: JobTracker.java

Content: 

void updateJobInProgressListeners(JobChangeEvent event){

  for (  JobInProgressListener listener : jobInProgressListeners) {

    listener.jobUpdated(event);

  }

}

Location: JobTracker.java

Content: 

private void updateNodeHealthStatus(TaskTrackerStatus trackerStatus){

  TaskTrackerHealthStatus status=trackerStatus.getHealthStatus();

synchronized (faultyTrackers) {

    faultyTrackers.setNodeHealthStatus(trackerStatus.getHost(),status.isNodeHealthy(),status.getHealthReport());

  }

}

Location: JobTracker.java

Content: 

/** 

 * Accept and process a new TaskTracker profile.  We might have known about the TaskTracker previously, or it might be brand-new.  All task-tracker structures have already been updated.  Just process the contained tasks and any jobs that might be affected.

 */

void updateTaskStatuses(TaskTrackerStatus status){

  String trackerName=status.getTrackerName();

  for (  TaskStatus report : status.getTaskReports()) {

    report.setTaskTracker(trackerName);

    TaskAttemptID taskId=report.getTaskID();

    expireLaunchingTasks.removeTask(taskId);

    JobInProgress job=getJob(taskId.getJobID());

    if (job == null) {

synchronized (trackerToJobsToCleanup) {

        Set<JobID> jobs=trackerToJobsToCleanup.get(trackerName);

        if (jobs == null) {

          jobs=new HashSet<JobID>();

          trackerToJobsToCleanup.put(trackerName,jobs);

        }

        jobs.add(taskId.getJobID());

      }

      continue;

    }

    if (!job.inited()) {

synchronized (trackerToTasksToCleanup) {

        Set<TaskAttemptID> tasks=trackerToTasksToCleanup.get(trackerName);

        if (tasks == null) {

          tasks=new HashSet<TaskAttemptID>();

          trackerToTasksToCleanup.put(trackerName,tasks);

        }

        tasks.add(taskId);

      }

      continue;

    }

    TaskInProgress tip=taskidToTIPMap.get(taskId);

    if (tip != null) {

      JobStatus prevStatus=(JobStatus)job.getStatus().clone();

      job.updateTaskStatus(tip,(TaskStatus)report.clone());

      JobStatus newStatus=(JobStatus)job.getStatus().clone();

      if (prevStatus.getRunState() != newStatus.getRunState()) {

        JobStatusChangeEvent event=new JobStatusChangeEvent(job,EventType.RUN_STATE_CHANGED,prevStatus,newStatus);

        updateJobInProgressListeners(event);

      }

    }

 else {

      LOG.info("Serious problem.  While updating status, cannot find taskid " + report.getTaskID());

    }

    List<TaskAttemptID> failedFetchMaps=report.getFetchFailedMaps();

    if (failedFetchMaps != null) {

      for (      TaskAttemptID mapTaskId : failedFetchMaps) {

        TaskInProgress failedFetchMap=taskidToTIPMap.get(mapTaskId);

        if (failedFetchMap != null) {

          String failedFetchTrackerName=getAssignedTracker(mapTaskId);

          if (failedFetchTrackerName == null) {

            failedFetchTrackerName="Lost task tracker";

          }

          failedFetchMap.getJob().fetchFailureNotification(failedFetchMap,mapTaskId,failedFetchTrackerName,taskId,trackerName);

        }

      }

    }

  }

}

Location: JobTracker.java

Content: 

/** 

 * Update the last recorded status for the given task tracker. It assumes that the taskTrackers are locked on entry.

 * @param trackerName The name of the tracker

 * @param status The new status for the task tracker

 * @return Was an old status found?

 */

boolean updateTaskTrackerStatus(String trackerName,TaskTrackerStatus status){

  TaskTracker tt=getTaskTracker(trackerName);

  TaskTrackerStatus oldStatus=(tt == null) ? null : tt.getStatus();

  if (oldStatus != null) {

    totalMaps-=oldStatus.countMapTasks();

    totalReduces-=oldStatus.countReduceTasks();

    occupiedMapSlots-=oldStatus.countOccupiedMapSlots();

    occupiedReduceSlots-=oldStatus.countOccupiedReduceSlots();

    getInstrumentation().decRunningMaps(oldStatus.countMapTasks());

    getInstrumentation().decRunningReduces(oldStatus.countReduceTasks());

    getInstrumentation().decOccupiedMapSlots(oldStatus.countOccupiedMapSlots());

    getInstrumentation().decOccupiedReduceSlots(oldStatus.countOccupiedReduceSlots());

    if (!faultyTrackers.isBlacklisted(oldStatus.getHost())) {

      int mapSlots=oldStatus.getMaxMapSlots();

      totalMapTaskCapacity-=mapSlots;

      int reduceSlots=oldStatus.getMaxReduceSlots();

      totalReduceTaskCapacity-=reduceSlots;

    }

    if (status == null) {

      taskTrackers.remove(trackerName);

      Integer numTaskTrackersInHost=uniqueHostsMap.get(oldStatus.getHost());

      if (numTaskTrackersInHost != null) {

        numTaskTrackersInHost--;

        if (numTaskTrackersInHost > 0) {

          uniqueHostsMap.put(oldStatus.getHost(),numTaskTrackersInHost);

        }

 else {

          uniqueHostsMap.remove(oldStatus.getHost());

        }

      }

    }

  }

  if (status != null) {

    totalMaps+=status.countMapTasks();

    totalReduces+=status.countReduceTasks();

    occupiedMapSlots+=status.countOccupiedMapSlots();

    occupiedReduceSlots+=status.countOccupiedReduceSlots();

    getInstrumentation().addRunningMaps(status.countMapTasks());

    getInstrumentation().addRunningReduces(status.countReduceTasks());

    getInstrumentation().addOccupiedMapSlots(status.countOccupiedMapSlots());

    getInstrumentation().addOccupiedReduceSlots(status.countOccupiedReduceSlots());

    if (!faultyTrackers.isBlacklisted(status.getHost())) {

      int mapSlots=status.getMaxMapSlots();

      totalMapTaskCapacity+=mapSlots;

      int reduceSlots=status.getMaxReduceSlots();

      totalReduceTaskCapacity+=reduceSlots;

    }

    boolean alreadyPresent=false;

    TaskTracker taskTracker=taskTrackers.get(trackerName);

    if (taskTracker != null) {

      alreadyPresent=true;

    }

 else {

      taskTracker=new TaskTracker(trackerName);

    }

    taskTracker.setStatus(status);

    taskTrackers.put(trackerName,taskTracker);

    if (LOG.isDebugEnabled()) {

      int runningMaps=0, runningReduces=0;

      int commitPendingMaps=0, commitPendingReduces=0;

      int unassignedMaps=0, unassignedReduces=0;

      int miscMaps=0, miscReduces=0;

      List<TaskStatus> taskReports=status.getTaskReports();

      for (Iterator<TaskStatus> it=taskReports.iterator(); it.hasNext(); ) {

        TaskStatus ts=it.next();

        boolean isMap=ts.getIsMap();

        TaskStatus.State state=ts.getRunState();

        if (state == TaskStatus.State.RUNNING) {

          if (isMap) {

            ++runningMaps;

          }

 else {

            ++runningReduces;

          }

        }

 else         if (state == TaskStatus.State.UNASSIGNED) {

          if (isMap) {

            ++unassignedMaps;

          }

 else {

            ++unassignedReduces;

          }

        }

 else         if (state == TaskStatus.State.COMMIT_PENDING) {

          if (isMap) {

            ++commitPendingMaps;

          }

 else {

            ++commitPendingReduces;

          }

        }

 else {

          if (isMap) {

            ++miscMaps;

          }

 else {

            ++miscReduces;

          }

        }

      }

      LOG.debug(trackerName + ": Status -" + " running(m) = "+ runningMaps+ " unassigned(m) = "+ unassignedMaps+ " commit_pending(m) = "+ commitPendingMaps+ " misc(m) = "+ miscMaps+ " running(r) = "+ runningReduces+ " unassigned(r) = "+ unassignedReduces+ " commit_pending(r) = "+ commitPendingReduces+ " misc(r) = "+ miscReduces);

    }

    if (!alreadyPresent) {

      Integer numTaskTrackersInHost=uniqueHostsMap.get(status.getHost());

      if (numTaskTrackersInHost == null) {

        numTaskTrackersInHost=0;

      }

      numTaskTrackersInHost++;

      uniqueHostsMap.put(status.getHost(),numTaskTrackersInHost);

    }

  }

  getInstrumentation().setMapSlots(totalMapTaskCapacity);

  getInstrumentation().setReduceSlots(totalReduceTaskCapacity);

  return oldStatus != null;

}

Location: JobTracker.java

Content: 

static boolean validateIdentifier(String id){

  try {

    getDateFormat().parse(id);

    return true;

  }

 catch (  ParseException pe) {

  }

  return false;

}

Location: JobTracker.java

Content: 

static boolean validateJobNumber(String id){

  try {

    Integer.parseInt(id);

    return true;

  }

 catch (  IllegalArgumentException pe) {

  }

  return false;

}

