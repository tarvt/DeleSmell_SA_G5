Location: DistributedCacheEmulator.java

Content: 

/** 

 * Create the list of unique distributed cache files needed for all the simulated jobs and write the list to a special file.

 * @param jsp job story producer for the trace

 * @return exit code

 * @throws IOException

 */

private int buildDistCacheFilesList(JobStoryProducer jsp) throws IOException {

  JobStory jobStory;

  while ((jobStory=jsp.getNextJob()) != null) {

    if (jobStory.getOutcome() == Pre21JobHistoryConstants.Values.SUCCESS && jobStory.getSubmissionTime() >= 0) {

      updateHDFSDistCacheFilesList(jobStory);

    }

  }

  jsp.close();

  return writeDistCacheFilesList();

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * If gridmix needs to emulate distributed cache load, then configure distributed cache files of a simulated job by mapping the original cluster's distributed cache file paths to the simulated cluster's paths and setting these mapped paths in the job configuration of the simulated job. <br> Configure local FS based distributed cache files through the property "tmpfiles" and hdfs based distributed cache files through the property {@link MRJobConfig#CACHE_FILES}.

 * @param conf configuration for the simulated job to be run

 * @param jobConf job configuration of original cluster's job, obtained fromtrace

 * @throws IOException

 */

void configureDistCacheFiles(Configuration conf,JobConf jobConf) throws IOException {

  if (shouldEmulateDistCacheLoad()) {

    String[] files=jobConf.getStrings(MRJobConfig.CACHE_FILES);

    if (files != null) {

      List<String> cacheFiles=new ArrayList<String>();

      List<String> localCacheFiles=new ArrayList<String>();

      String[] visibilities=jobConf.getStrings(MRJobConfig.CACHE_FILE_VISIBILITIES);

      String[] timeStamps=jobConf.getStrings(MRJobConfig.CACHE_FILE_TIMESTAMPS);

      String[] fileSizes=jobConf.getStrings(MRJobConfig.CACHE_FILES_SIZES);

      String user=jobConf.getUser();

      for (int i=0; i < files.length; i++) {

        boolean visibility=(visibilities == null) ? true : Boolean.valueOf(visibilities[i]);

        if (isLocalDistCacheFile(files[i],user,visibility)) {

          String fileId=MD5Hash.digest(files[i] + timeStamps[i]).toString();

          long fileSize=Long.valueOf(fileSizes[i]);

          Path mappedLocalFilePath=PseudoLocalFs.generateFilePath(fileId,fileSize).makeQualified(pseudoLocalFs.getUri(),pseudoLocalFs.getWorkingDirectory());

          pseudoLocalFs.create(mappedLocalFilePath);

          localCacheFiles.add(mappedLocalFilePath.toUri().toString());

        }

 else {

          String mappedPath=mapDistCacheFilePath(files[i],timeStamps[i],visibility,user);

          cacheFiles.add(mappedPath);

        }

      }

      if (cacheFiles.size() > 0) {

        conf.setStrings(MRJobConfig.CACHE_FILES,cacheFiles.toArray(new String[cacheFiles.size()]));

      }

      if (localCacheFiles.size() > 0) {

        conf.setStrings("tmpfiles",localCacheFiles.toArray(new String[localCacheFiles.size()]));

      }

    }

  }

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * Create distributed cache directory where distributed cache files will be created by the MapReduce job  {@link GenerateDistCacheData#JOB_NAME}.

 * @throws IOException

 */

private void createDistCacheDirectory() throws IOException {

  FileSystem fs=FileSystem.get(conf);

  FileSystem.mkdirs(fs,distCachePath,new FsPermission((short)0777));

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * @param conf gridmix configuration

 * @param ioPath &lt;ioPath&gt;/distributedCache/ is the gridmix DistributedCache directory

 */

public DistributedCacheEmulator(Configuration conf,Path ioPath){

  this.conf=conf;

  distCachePath=new Path(ioPath,"distributedCache");

  this.conf.setClass("fs.pseudo.impl",PseudoLocalFs.class,FileSystem.class);

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * @return the distributed cache directory path

 */

Path getDistributedCacheDir(){

  return distCachePath;

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * This is to be called before any other method of DistributedCacheEmulator. <br> Checks if emulation of distributed cache load is needed and is feasible. Sets the flags generateDistCacheData and emulateDistributedCache to the appropriate values. <br> Gridmix does not emulate distributed cache load if <ol><li> the specific gridmix job type doesn't need emulation of distributed cache load OR <li> the trace is coming from a stream instead of file OR <li> the distributed cache dir where distributed cache data is to be generated by gridmix is on local file system OR <li> execute permission is not there for any of the ascendant directories of &lt;ioPath&gt; till root. This is because for emulation of distributed cache load, distributed cache files created under &lt;ioPath/distributedCache/public/&gt; should be considered by hadoop as public distributed cache files. <li> creation of pseudo local file system fails.</ol> <br> For (2), (3), (4) and (5), generation of distributed cache data is also disabled.

 * @param traceIn trace file path. If this is '-', then trace comes from thestream stdin.

 * @param jobCreator job creator of gridmix jobs of a specific type

 * @param generate  true if -generate option was specified

 * @throws IOException

 */

void init(String traceIn,JobCreator jobCreator,boolean generate) throws IOException {

  emulateDistributedCache=jobCreator.canEmulateDistCacheLoad() && conf.getBoolean(GRIDMIX_EMULATE_DISTRIBUTEDCACHE,true);

  generateDistCacheData=generate;

  if (generateDistCacheData || emulateDistributedCache) {

    if ("-".equals(traceIn)) {

      LOG.warn("Gridmix will not emulate Distributed Cache load because " + "the input trace source is a stream instead of file.");

      emulateDistributedCache=generateDistCacheData=false;

    }

 else     if (FileSystem.getLocal(conf).getUri().getScheme().equals(distCachePath.toUri().getScheme())) {

      LOG.warn("Gridmix will not emulate Distributed Cache load because " + "<iopath> provided is on local file system.");

      emulateDistributedCache=generateDistCacheData=false;

    }

 else {

      FileSystem fs=FileSystem.get(conf);

      Path cur=distCachePath.getParent();

      while (cur != null) {

        if (cur.toString().length() > 0) {

          FsPermission perm=fs.getFileStatus(cur).getPermission();

          if (!perm.getOtherAction().and(FsAction.EXECUTE).equals(FsAction.EXECUTE)) {

            LOG.warn("Gridmix will not emulate Distributed Cache load " + "because the ascendant directory (of distributed cache " + "directory) " + cur + " doesn't have execute permission "+ "for others.");

            emulateDistributedCache=generateDistCacheData=false;

            break;

          }

        }

        cur=cur.getParent();

      }

    }

  }

  try {

    pseudoLocalFs=FileSystem.get(new URI("pseudo:///"),conf);

  }

 catch (  URISyntaxException e) {

    LOG.warn("Gridmix will not emulate Distributed Cache load because " + "creation of pseudo local file system failed.");

    e.printStackTrace();

    emulateDistributedCache=generateDistCacheData=false;

    return;

  }

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * Check if the file path provided was constructed by MapReduce for a distributed cache file on local file system.

 * @param filePath path of the distributed cache file

 * @param user job submitter of the job for which &lt;filePath&gt; is adistributed cache file

 * @param visibility <code>true</code> for public distributed cache file

 * @return true if the path provided is of a local file system baseddistributed cache file

 */

static boolean isLocalDistCacheFile(String filePath,String user,boolean visibility){

  return (!visibility && filePath.contains(user + "/.staging"));

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * Map the HDFS based distributed cache file path from original cluster to a unique file name on the simulated cluster. <br> Unique  distributed file names on simulated cluster are generated using original cluster's <li>file path, <li>timestamp and <li> the job-submitter for private distributed cache file. <br> This implies that if on original cluster, a single HDFS file considered as two private distributed cache files for two jobs of different users, then the corresponding simulated jobs will have two different files of the same size in public distributed cache, one for each user. Both these simulated jobs will not share these distributed cache files, thus leading to the same load as seen in the original cluster.

 * @param file distributed cache file path

 * @param timeStamp time stamp of dist cachce file

 * @param isPublic true if this distributed cache file is a publicdistributed cache file

 * @param user job submitter on original cluster

 * @return the mapped path on simulated cluster

 */

private String mapDistCacheFilePath(String file,String timeStamp,boolean isPublic,String user){

  String id=file + timeStamp;

  if (!isPublic) {

    id=id.concat(user);

  }

  return new Path(distCachePath,MD5Hash.digest(id).toString()).toUri().getPath();

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * Create distributed cache directories. Also create a file that contains the list of distributed cache files that will be used as distributed cache files for all the simulated jobs.

 * @param jsp job story producer for the trace

 * @return exit code

 * @throws IOException

 */

int setupGenerateDistCacheData(JobStoryProducer jsp) throws IOException {

  createDistCacheDirectory();

  return buildDistCacheFilesList(jsp);

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * @return true if gridmix should emulate distributed cache load

 */

boolean shouldEmulateDistCacheLoad(){

  return emulateDistributedCache;

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * @return true if gridmix should generate distributed cache data

 */

boolean shouldGenerateDistCacheData(){

  return generateDistCacheData;

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * For the job to be simulated, identify the needed distributed cache files by mapping original cluster's distributed cache file paths to the simulated cluster's paths and add these paths in the map  {@code distCacheFiles}. <br> JobStory should contain distributed cache related properties like <li>  {@link MRJobConfig#CACHE_FILES}<li>  {@link MRJobConfig#CACHE_FILE_VISIBILITIES}<li>  {@link MRJobConfig#CACHE_FILES_SIZES}<li>  {@link MRJobConfig#CACHE_FILE_TIMESTAMPS}<li>  {@link MRJobConfig#CLASSPATH_FILES}<li>  {@link MRJobConfig#CACHE_ARCHIVES}<li>  {@link MRJobConfig#CACHE_ARCHIVES_VISIBILITIES}<li>  {@link MRJobConfig#CACHE_ARCHIVES_SIZES}<li>  {@link MRJobConfig#CACHE_ARCHIVES_TIMESTAMPS}<li>  {@link MRJobConfig#CLASSPATH_ARCHIVES}<li>  {@link MRJobConfig#CACHE_SYMLINK}

 * @param jobdesc JobStory of original job obtained from trace

 * @throws IOException

 */

void updateHDFSDistCacheFilesList(JobStory jobdesc) throws IOException {

  JobConf jobConf=jobdesc.getJobConf();

  String[] files=jobConf.getStrings(MRJobConfig.CACHE_FILES);

  if (files != null) {

    String[] fileSizes=jobConf.getStrings(MRJobConfig.CACHE_FILES_SIZES);

    String[] visibilities=jobConf.getStrings(MRJobConfig.CACHE_FILE_VISIBILITIES);

    String[] timeStamps=jobConf.getStrings(MRJobConfig.CACHE_FILE_TIMESTAMPS);

    FileSystem fs=FileSystem.get(conf);

    String user=jobConf.getUser();

    for (int i=0; i < files.length; i++) {

      boolean visibility=(visibilities == null) ? true : Boolean.valueOf(visibilities[i]);

      if (isLocalDistCacheFile(files[i],user,visibility)) {

        continue;

      }

      String mappedPath=mapDistCacheFilePath(files[i],timeStamps[i],visibility,user);

      if (distCacheFiles.containsKey(mappedPath) || fs.exists(new Path(mappedPath))) {

        continue;

      }

      distCacheFiles.put(mappedPath,Long.valueOf(fileSizes[i]));

    }

  }

}

Location: DistributedCacheEmulator.java

Content: 

/** 

 * Write the list of distributed cache files in the decreasing order of file sizes into the sequence file. This file will be input to the job {@link GenerateDistCacheData}. Also validates if -generate option is missing and distributed cache files are missing.

 * @return exit code

 * @throws IOException

 */

private int writeDistCacheFilesList() throws IOException {

  List dcFiles=new ArrayList(distCacheFiles.entrySet());

  Collections.sort(dcFiles,new Comparator(){

    public int compare(    Object dc1,    Object dc2){

      return ((Comparable)((Map.Entry)(dc2)).getValue()).compareTo(((Map.Entry)(dc1)).getValue());

    }

  }

);

  FileSystem fs=FileSystem.get(conf);

  Path distCacheFilesList=new Path(distCachePath,"_distCacheFiles.txt");

  conf.set(GenerateDistCacheData.GRIDMIX_DISTCACHE_FILE_LIST,distCacheFilesList.toString());

  SequenceFile.Writer src_writer=SequenceFile.createWriter(fs,conf,distCacheFilesList,LongWritable.class,BytesWritable.class,SequenceFile.CompressionType.NONE);

  int fileCount=dcFiles.size();

  long byteCount=0;

  long bytesSync=0;

  for (Iterator it=dcFiles.iterator(); it.hasNext(); ) {

    Map.Entry entry=(Map.Entry)it.next();

    LongWritable fileSize=new LongWritable(Long.valueOf(entry.getValue().toString()));

    BytesWritable filePath=new BytesWritable(entry.getKey().toString().getBytes());

    byteCount+=fileSize.get();

    bytesSync+=fileSize.get();

    if (bytesSync > AVG_BYTES_PER_MAP) {

      src_writer.sync();

      bytesSync=fileSize.get();

    }

    src_writer.append(fileSize,filePath);

  }

  if (src_writer != null) {

    src_writer.close();

  }

  fs.deleteOnExit(distCacheFilesList);

  conf.setInt(GenerateDistCacheData.GRIDMIX_DISTCACHE_FILE_COUNT,fileCount);

  conf.setLong(GenerateDistCacheData.GRIDMIX_DISTCACHE_BYTE_COUNT,byteCount);

  LOG.info("Number of HDFS based distributed cache files to be generated is " + fileCount + ". Total size of HDFS based distributed cache files "+ "to be generated is "+ byteCount);

  if (!shouldGenerateDistCacheData() && fileCount > 0) {

    LOG.error("Missing " + fileCount + " distributed cache files under the "+ " directory\n"+ distCachePath+ "\nthat are needed for gridmix"+ " to emulate distributed cache load. Either use -generate\noption"+ " to generate distributed cache data along with input data OR "+ "disable\ndistributed cache emulation by configuring '"+ DistributedCacheEmulator.GRIDMIX_EMULATE_DISTRIBUTEDCACHE+ "' to false.");

    return MISSING_DIST_CACHE_FILES_ERROR;

  }

  return 0;

}

