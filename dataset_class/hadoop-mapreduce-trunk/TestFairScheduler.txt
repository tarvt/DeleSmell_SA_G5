Location: TestFairScheduler.java

Content: 

private void advanceTime(long time){

  clock.advance(time);

  scheduler.update();

}

Location: TestFairScheduler.java

Content: 

protected void checkAssignment(String taskTrackerName,String... expectedTasks) throws IOException {

  List<Task> tasks=scheduler.assignTasks(tracker(taskTrackerName));

  assertNotNull(tasks);

  System.out.println("Assigned tasks:");

  for (int i=0; i < tasks.size(); i++)   System.out.println("- " + tasks.get(i));

  assertEquals(expectedTasks.length,tasks.size());

  for (int i=0; i < tasks.size(); i++)   assertEquals("assignment " + i,expectedTasks[i],tasks.get(i).toString());

}

Location: TestFairScheduler.java

Content: 

public String getRack(String hostname){

  return hostname.split("\\.")[0];

}

Location: TestFairScheduler.java

Content: 

private void setUpCluster(int numRacks,int numNodesPerRack,boolean assignMultiple){

  conf=new JobConf();

  conf.set("mapred.fairscheduler.allocation.file",ALLOC_FILE);

  conf.set("mapred.fairscheduler.poolnameproperty",POOL_PROPERTY);

  conf.setBoolean("mapred.fairscheduler.assignmultiple",assignMultiple);

  conf.setLong("mapred.fairscheduler.locality.delay.node",5000);

  conf.setLong("mapred.fairscheduler.locality.delay.rack",10000);

  taskTrackerManager=new FakeTaskTrackerManager(numRacks,numNodesPerRack);

  clock=new FakeClock();

  scheduler=new FairScheduler(clock,true);

  scheduler.waitForMapsBeforeLaunchingReduces=false;

  scheduler.setConf(conf);

  scheduler.setTaskTrackerManager(taskTrackerManager);

  scheduler.start();

}

Location: TestFairScheduler.java

Content: 

private JobInProgress submitJobNotInitialized(int state,int maps,int reduces) throws IOException {

  return submitJob(state,maps,reduces,null,null,false);

}

Location: TestFairScheduler.java

Content: 

protected void submitJobs(int number,int state,int maps,int reduces) throws IOException {

  for (int i=0; i < number; i++) {

    submitJob(state,maps,reduces);

  }

}

Location: TestFairScheduler.java

Content: 

private JobInProgress submitJob(int state,int maps,int reduces) throws IOException {

  return submitJob(state,maps,reduces,null,null,true);

}

Location: TestFairScheduler.java

Content: 

private JobInProgress submitJob(int state,int maps,int reduces,String pool) throws IOException {

  return submitJob(state,maps,reduces,pool,null,true);

}

Location: TestFairScheduler.java

Content: 

private JobInProgress submitJob(int state,int maps,int reduces,String pool,String[][] mapInputLocations,boolean initializeJob) throws IOException {

  JobConf jobConf=new JobConf(conf);

  jobConf.setNumMapTasks(maps);

  jobConf.setNumReduceTasks(reduces);

  if (pool != null)   jobConf.set(POOL_PROPERTY,pool);

  JobInProgress job=new FakeJobInProgress(jobConf,taskTrackerManager,mapInputLocations,UtilsForTests.getJobTracker());

  if (initializeJob) {

    taskTrackerManager.initJob(job);

  }

  job.getStatus().setRunState(state);

  taskTrackerManager.submitJob(job);

  job.startTime=clock.time;

  return job;

}

Location: TestFairScheduler.java

Content: 

public void testAllocationFileParsing() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>1</minMaps>");

  out.println("<minReduces>2</minReduces>");

  out.println("</pool>");

  out.println("<pool name=\"poolB\">");

  out.println("<minMaps>2</minMaps>");

  out.println("<minReduces>1</minReduces>");

  out.println("</pool>");

  out.println("<pool name=\"poolC\">");

  out.println("<minMaps>2</minMaps>");

  out.println("</pool>");

  out.println("<pool name=\"poolD\">");

  out.println("<maxRunningJobs>3</maxRunningJobs>");

  out.println("</pool>");

  out.println("<pool name=\"poolE\">");

  out.println("<minSharePreemptionTimeout>60</minSharePreemptionTimeout>");

  out.println("</pool>");

  out.println("<poolMaxJobsDefault>15</poolMaxJobsDefault>");

  out.println("<userMaxJobsDefault>5</userMaxJobsDefault>");

  out.println("<user name=\"user1\">");

  out.println("<maxRunningJobs>10</maxRunningJobs>");

  out.println("</user>");

  out.println("<defaultMinSharePreemptionTimeout>120" + "</defaultMinSharePreemptionTimeout>");

  out.println("<fairSharePreemptionTimeout>300</fairSharePreemptionTimeout>");

  out.println("</allocations>");

  out.close();

  PoolManager poolManager=scheduler.getPoolManager();

  poolManager.reloadAllocs();

  assertEquals(6,poolManager.getPools().size());

  assertEquals(0,poolManager.getAllocation(Pool.DEFAULT_POOL_NAME,TaskType.MAP));

  assertEquals(0,poolManager.getAllocation(Pool.DEFAULT_POOL_NAME,TaskType.REDUCE));

  assertEquals(1,poolManager.getAllocation("poolA",TaskType.MAP));

  assertEquals(2,poolManager.getAllocation("poolA",TaskType.REDUCE));

  assertEquals(2,poolManager.getAllocation("poolB",TaskType.MAP));

  assertEquals(1,poolManager.getAllocation("poolB",TaskType.REDUCE));

  assertEquals(2,poolManager.getAllocation("poolC",TaskType.MAP));

  assertEquals(0,poolManager.getAllocation("poolC",TaskType.REDUCE));

  assertEquals(0,poolManager.getAllocation("poolD",TaskType.MAP));

  assertEquals(0,poolManager.getAllocation("poolD",TaskType.REDUCE));

  assertEquals(0,poolManager.getAllocation("poolE",TaskType.MAP));

  assertEquals(0,poolManager.getAllocation("poolE",TaskType.REDUCE));

  assertEquals(15,poolManager.getPoolMaxJobs(Pool.DEFAULT_POOL_NAME));

  assertEquals(15,poolManager.getPoolMaxJobs("poolA"));

  assertEquals(15,poolManager.getPoolMaxJobs("poolB"));

  assertEquals(15,poolManager.getPoolMaxJobs("poolC"));

  assertEquals(3,poolManager.getPoolMaxJobs("poolD"));

  assertEquals(15,poolManager.getPoolMaxJobs("poolE"));

  assertEquals(10,poolManager.getUserMaxJobs("user1"));

  assertEquals(5,poolManager.getUserMaxJobs("user2"));

  assertEquals(120000,poolManager.getMinSharePreemptionTimeout(Pool.DEFAULT_POOL_NAME));

  assertEquals(120000,poolManager.getMinSharePreemptionTimeout("poolA"));

  assertEquals(120000,poolManager.getMinSharePreemptionTimeout("poolB"));

  assertEquals(120000,poolManager.getMinSharePreemptionTimeout("poolC"));

  assertEquals(120000,poolManager.getMinSharePreemptionTimeout("poolD"));

  assertEquals(120000,poolManager.getMinSharePreemptionTimeout("poolA"));

  assertEquals(60000,poolManager.getMinSharePreemptionTimeout("poolE"));

  assertEquals(300000,poolManager.getFairSharePreemptionTimeout());

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits two jobs with 4 maps and 3 reduces in total to a 4-node cluster. Although the cluster has 2 map slots and 2 reduce slots per node, it should only launch one map and one reduce on each node to balance the load. We check that this happens even if assignMultiple is set to true so the scheduler has the opportunity to launch multiple tasks per heartbeat.

 */

public void testAssignMultipleWithUnderloadedCluster() throws IOException {

  setUpCluster(1,4,true);

  JobInProgress job1=submitJob(JobStatus.RUNNING,2,2);

  advanceTime(100);

  JobInProgress job2=submitJob(JobStatus.RUNNING,2,1);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1","attempt_test_0001_r_000000_0 on tt1");

  assertNull(scheduler.assignTasks(tracker("tt1")));

  checkAssignment("tt2","attempt_test_0002_m_000000_0 on tt2","attempt_test_0002_r_000000_0 on tt2");

  assertNull(scheduler.assignTasks(tracker("tt2")));

  checkAssignment("tt3","attempt_test_0001_m_000001_0 on tt3","attempt_test_0001_r_000001_0 on tt3");

  assertNull(scheduler.assignTasks(tracker("tt3")));

  checkAssignment("tt4","attempt_test_0002_m_000001_0 on tt4");

  assertNull(scheduler.assignTasks(tracker("tt4")));

}

Location: TestFairScheduler.java

Content: 

/** 

 * Tests that max-running-tasks per node are set by assigning load equally accross the cluster in CapBasedLoadManager.

 */

public void testCapBasedLoadManager(){

  CapBasedLoadManager loadMgr=new CapBasedLoadManager();

  assertEquals(1,loadMgr.getCap(1,1,100));

  assertEquals(1,loadMgr.getCap(1,2,100));

  assertEquals(1,loadMgr.getCap(1,10,100));

  assertEquals(1,loadMgr.getCap(200,1,100));

  assertEquals(1,loadMgr.getCap(1,5,100));

  assertEquals(3,loadMgr.getCap(50,5,100));

  assertEquals(5,loadMgr.getCap(100,5,100));

  assertEquals(5,loadMgr.getCap(200,5,100));

}

Location: TestFairScheduler.java

Content: 

/** 

 * Test a combination of pool job limits and user job limits, the latter specified through both the userMaxJobsDefaults (for some users) and user-specific &lt;user&gt; elements in the allocations file. 

 */

public void testComplexJobLimits() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<maxRunningJobs>1</maxRunningJobs>");

  out.println("</pool>");

  out.println("<user name=\"user1\">");

  out.println("<maxRunningJobs>1</maxRunningJobs>");

  out.println("</user>");

  out.println("<user name=\"user2\">");

  out.println("<maxRunningJobs>10</maxRunningJobs>");

  out.println("</user>");

  out.println("<userMaxJobsDefault>2</userMaxJobsDefault>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  job1.getJobConf().set(JobContext.USER_NAME,"user1");

  JobInfo info1=scheduler.infos.get(job1);

  advanceTime(10);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10);

  job2.getJobConf().set(JobContext.USER_NAME,"user1");

  JobInfo info2=scheduler.infos.get(job2);

  advanceTime(10);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10);

  job3.getJobConf().set(JobContext.USER_NAME,"user2");

  JobInfo info3=scheduler.infos.get(job3);

  advanceTime(10);

  JobInProgress job4=submitJob(JobStatus.RUNNING,10,10);

  job4.getJobConf().set(JobContext.USER_NAME,"user2");

  JobInfo info4=scheduler.infos.get(job4);

  advanceTime(10);

  JobInProgress job5=submitJob(JobStatus.RUNNING,10,10);

  job5.getJobConf().set(JobContext.USER_NAME,"user2");

  JobInfo info5=scheduler.infos.get(job5);

  advanceTime(10);

  JobInProgress job6=submitJob(JobStatus.RUNNING,10,10);

  job6.getJobConf().set(JobContext.USER_NAME,"user3");

  JobInfo info6=scheduler.infos.get(job6);

  advanceTime(10);

  JobInProgress job7=submitJob(JobStatus.RUNNING,10,10);

  job7.getJobConf().set(JobContext.USER_NAME,"user3");

  JobInfo info7=scheduler.infos.get(job7);

  advanceTime(10);

  JobInProgress job8=submitJob(JobStatus.RUNNING,10,10);

  job8.getJobConf().set(JobContext.USER_NAME,"user3");

  JobInfo info8=scheduler.infos.get(job8);

  advanceTime(10);

  JobInProgress job9=submitJob(JobStatus.RUNNING,10,10,"poolA");

  job9.getJobConf().set(JobContext.USER_NAME,"user4");

  JobInfo info9=scheduler.infos.get(job9);

  advanceTime(10);

  JobInProgress job10=submitJob(JobStatus.RUNNING,10,10,"poolA");

  job10.getJobConf().set(JobContext.USER_NAME,"user4");

  JobInfo info10=scheduler.infos.get(job10);

  advanceTime(10);

  assertEquals(0.33,info1.mapSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info1.reduceSchedulable.getFairShare(),0.1);

  assertEquals(0.0,info2.mapSchedulable.getFairShare());

  assertEquals(0.0,info2.reduceSchedulable.getFairShare());

  assertEquals(0.33,info3.mapSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info3.reduceSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info4.mapSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info4.reduceSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info5.mapSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info5.reduceSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info6.mapSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info6.reduceSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info7.mapSchedulable.getFairShare(),0.1);

  assertEquals(0.33,info7.reduceSchedulable.getFairShare(),0.1);

  assertEquals(0.0,info8.mapSchedulable.getFairShare());

  assertEquals(0.0,info8.reduceSchedulable.getFairShare());

  assertEquals(2.0,info9.mapSchedulable.getFairShare(),0.1);

  assertEquals(2.0,info9.reduceSchedulable.getFairShare(),0.1);

  assertEquals(0.0,info10.mapSchedulable.getFairShare());

  assertEquals(0.0,info10.reduceSchedulable.getFairShare());

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test exercises delay scheduling at the node level. We submit a job with data on rack1.node2 and check that it doesn't get assigned on earlier nodes. A second job with no locality info should get assigned instead. TaskTracker names in this test map to nodes as follows: - tt1 = rack1.node1 - tt2 = rack1.node2 - tt3 = rack2.node1 - tt4 = rack2.node2

 */

public void testDelaySchedulingAtNodeLevel() throws IOException {

  setUpCluster(2,2,true);

  scheduler.assignMultiple=true;

  JobInProgress job1=submitJob(JobStatus.RUNNING,1,0,"pool1",new String[][]{{"rack2.node2"}},true);

  JobInfo info1=scheduler.infos.get(job1);

  advanceTime(100);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,0);

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1","attempt_test_0002_m_000001_0 on tt1");

  checkAssignment("tt2","attempt_test_0002_m_000002_0 on tt2","attempt_test_0002_m_000003_0 on tt2");

  checkAssignment("tt3","attempt_test_0002_m_000004_0 on tt3","attempt_test_0002_m_000005_0 on tt3");

  checkAssignment("tt4","attempt_test_0001_m_000000_0 on tt4","attempt_test_0002_m_000006_0 on tt4");

  assertEquals(info1.lastMapLocalityLevel,LocalityLevel.NODE);

  assertEquals(info1.timeWaitedForLocalMap,0);

  assertEquals(info1.skippedAtLastHeartbeat,false);

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits a job and causes it to exceed its node-level delay, and thus to go on to launch a rack-local task. We submit one job with data on rack2.node4 and check that it does not get assigned on any of the other nodes until 10 seconds (the delay configured in setUpCluster) pass. Finally, after some delay, we let the job assign local tasks and check that it has returned to waiting for node locality. TaskTracker names in this test map to nodes as follows: - tt1 = rack1.node1 - tt2 = rack1.node2 - tt3 = rack2.node1 - tt4 = rack2.node2

 */

public void testDelaySchedulingAtRackLevel() throws IOException {

  setUpCluster(2,2,true);

  scheduler.assignMultiple=true;

  JobInProgress job1=submitJob(JobStatus.RUNNING,4,0,"pool1",new String[][]{{"rack2.node2"},{"rack2.node2"},{"rack2.node2"},{"rack2.node2"}},true);

  JobInfo info1=scheduler.infos.get(job1);

  advanceTime(100);

  JobInProgress job2=submitJob(JobStatus.RUNNING,20,0);

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1","attempt_test_0002_m_000001_0 on tt1");

  checkAssignment("tt2","attempt_test_0002_m_000002_0 on tt2","attempt_test_0002_m_000003_0 on tt2");

  checkAssignment("tt3","attempt_test_0002_m_000004_0 on tt3","attempt_test_0002_m_000005_0 on tt3");

  advanceTime(6000);

  taskTrackerManager.finishTask("tt1","attempt_test_0002_m_000000_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0002_m_000002_0");

  taskTrackerManager.finishTask("tt3","attempt_test_0002_m_000004_0");

  advanceTime(100);

  checkAssignment("tt1","attempt_test_0002_m_000006_0 on tt1");

  checkAssignment("tt2","attempt_test_0002_m_000007_0 on tt2");

  checkAssignment("tt3","attempt_test_0001_m_000000_0 on tt3");

  assertEquals(info1.lastMapLocalityLevel,LocalityLevel.RACK);

  assertEquals(info1.timeWaitedForLocalMap,0);

  assertEquals(info1.skippedAtLastHeartbeat,false);

  checkAssignment("tt4","attempt_test_0001_m_000001_0 on tt4","attempt_test_0001_m_000002_0 on tt4");

  assertEquals(info1.lastMapLocalityLevel,LocalityLevel.NODE);

  assertEquals(info1.timeWaitedForLocalMap,0);

  assertEquals(info1.skippedAtLastHeartbeat,false);

  taskTrackerManager.finishTask("tt1","attempt_test_0002_m_000001_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0002_m_000003_0");

  taskTrackerManager.finishTask("tt3","attempt_test_0002_m_000005_0");

  advanceTime(100);

  checkAssignment("tt1","attempt_test_0002_m_000008_0 on tt1");

  checkAssignment("tt2","attempt_test_0002_m_000009_0 on tt2");

  checkAssignment("tt3","attempt_test_0002_m_000010_0 on tt3");

  advanceTime(100);

  taskTrackerManager.finishTask("tt4","attempt_test_0001_m_000001_0");

  advanceTime(100);

  checkAssignment("tt4","attempt_test_0001_m_000003_0 on tt4");

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits a job and causes it to exceed its node-level delay, then its rack-level delay. It should then launch tasks off-rack. However, once the job gets a rack-local slot it should stay in-rack, and once it gets a node-local slot it should stay in-node. For simplicity, we don't submit a second job in this test. TaskTracker names in this test map to nodes as follows: - tt1 = rack1.node1 - tt2 = rack1.node2 - tt3 = rack2.node1 - tt4 = rack2.node2

 */

public void testDelaySchedulingOffRack() throws IOException {

  setUpCluster(2,2,true);

  scheduler.assignMultiple=true;

  JobInProgress job1=submitJob(JobStatus.RUNNING,8,0,"pool1",new String[][]{{"rack2.node2"},{"rack2.node2"},{"rack2.node2"},{"rack2.node2"},{"rack2.node2"},{"rack2.node2"},{"rack2.node2"},{"rack2.node2"}},true);

  JobInfo info1=scheduler.infos.get(job1);

  advanceTime(100);

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

  assertNull(scheduler.assignTasks(tracker("tt3")));

  advanceTime(6000);

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

  advanceTime(100);

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

  advanceTime(100);

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

  assertEquals(info1.lastMapLocalityLevel,LocalityLevel.NODE);

  assertEquals(info1.timeWaitedForLocalMap,6200);

  assertEquals(info1.skippedAtLastHeartbeat,true);

  advanceTime(11000);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1","attempt_test_0001_m_000001_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2","attempt_test_0001_m_000003_0 on tt2");

  assertEquals(info1.lastMapLocalityLevel,LocalityLevel.ANY);

  assertEquals(info1.timeWaitedForLocalMap,0);

  assertEquals(info1.skippedAtLastHeartbeat,false);

  checkAssignment("tt3","attempt_test_0001_m_000004_0 on tt3","attempt_test_0001_m_000005_0 on tt3");

  assertEquals(info1.lastMapLocalityLevel,LocalityLevel.RACK);

  assertEquals(info1.timeWaitedForLocalMap,0);

  assertEquals(info1.skippedAtLastHeartbeat,false);

  taskTrackerManager.finishTask("tt1","attempt_test_0001_m_000001_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0001_m_000003_0");

  advanceTime(100);

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

  taskTrackerManager.finishTask("tt3","attempt_test_0001_m_000004_0");

  advanceTime(100);

  checkAssignment("tt3","attempt_test_0001_m_000006_0 on tt3");

  checkAssignment("tt4","attempt_test_0001_m_000007_0 on tt4");

  assertEquals(info1.lastMapLocalityLevel,LocalityLevel.NODE);

  assertEquals(info1.timeWaitedForLocalMap,0);

  assertEquals(info1.skippedAtLastHeartbeat,false);

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test runs on a 4-node (8-slot) cluster to allow 3 pools with fair shares greater than 2 slots to coexist (which makes the half-fair-share  of each pool more than 1 so that fair share preemption can kick in).  The test first starts job 1, which takes 6 map slots and 6 reduce slots, in pool 1.  We then submit job 2 in pool 2, which takes 2 slots of each type. Finally, we submit a third job, job 3 in pool3, which gets no slots.  At this point the fair share of each pool will be 8/3 ~= 2.7 slots.  Pool 1 will be above its fair share, pool 2 will be below it but at half fair share, and pool 3 will be below half fair share. Therefore pool 3  should preempt a task (after a timeout) but pools 1 and 2 shouldn't. 

 */

public void testFairSharePreemption() throws Exception {

  setUpCluster(1,4,false);

  scheduler.preemptionEnabled=true;

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<fairSharePreemptionTimeout>60</fairSharePreemptionTimeout>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool pool1=scheduler.getPoolManager().getPool("pool1");

  Pool pool2=scheduler.getPoolManager().getPool("pool2");

  Pool pool3=scheduler.getPoolManager().getPool("pool3");

  JobInProgress job1=submitJob(JobStatus.RUNNING,6,6,"pool1");

  advanceTime(100);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000001_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000001_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000003_0 on tt2");

  advanceTime(100);

  checkAssignment("tt3","attempt_test_0001_m_000004_0 on tt3");

  checkAssignment("tt3","attempt_test_0001_r_000004_0 on tt3");

  checkAssignment("tt3","attempt_test_0001_m_000005_0 on tt3");

  checkAssignment("tt3","attempt_test_0001_r_000005_0 on tt3");

  advanceTime(100);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"pool2");

  advanceTime(100);

  checkAssignment("tt4","attempt_test_0002_m_000000_0 on tt4");

  checkAssignment("tt4","attempt_test_0002_r_000000_0 on tt4");

  checkAssignment("tt4","attempt_test_0002_m_000001_0 on tt4");

  checkAssignment("tt4","attempt_test_0002_r_000001_0 on tt4");

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10,"pool3");

  advanceTime(59000);

  assertEquals(0,scheduler.tasksToPreempt(pool2.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool2.getReduceSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool3.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool3.getReduceSchedulable(),clock.getTime()));

  advanceTime(2000);

  assertEquals(0,scheduler.tasksToPreempt(pool2.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool2.getReduceSchedulable(),clock.getTime()));

  assertEquals(2,scheduler.tasksToPreempt(pool3.getMapSchedulable(),clock.getTime()));

  assertEquals(2,scheduler.tasksToPreempt(pool3.getReduceSchedulable(),clock.getTime()));

  scheduler.preemptTasksIfNecessary();

  scheduler.update();

  assertEquals(4,job1.runningMaps());

  assertEquals(4,job1.runningReduces());

  checkAssignment("tt3","attempt_test_0003_m_000000_0 on tt3");

  checkAssignment("tt3","attempt_test_0003_r_000000_0 on tt3");

  checkAssignment("tt3","attempt_test_0003_m_000001_0 on tt3");

  checkAssignment("tt3","attempt_test_0003_r_000001_0 on tt3");

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

  assertNull(scheduler.assignTasks(tracker("tt3")));

  assertNull(scheduler.assignTasks(tracker("tt4")));

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test runs on a 3-node (6-slot) cluster to allow 3 pools with fair shares equal 2 slots to coexist (which makes the half-fair-share  of each pool equal to 1 so that fair share preemption can kick in).  The test first starts job 1, which takes 3 map slots and 0 reduce slots, in pool 1.  We then submit job 2 in pool 2, which takes 3 map slots and zero reduce slots. Finally, we submit a third job, job 3 in pool3, which gets no slots.  At this point the fair share of each pool will be 6/3 = 2 slots.  Pool 1 and 2 will be above their fair share and pool 3 will be below half fair share.  Therefore pool 3 should preempt tasks from both pool 1 & 2 (after a timeout) but  pools 1 and 2 shouldn't. 

 */

public void testFairSharePreemptionFromMultiplePools() throws Exception {

  setUpCluster(1,3,false);

  scheduler.preemptionEnabled=true;

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<fairSharePreemptionTimeout>60</fairSharePreemptionTimeout>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool pool1=scheduler.getPoolManager().getPool("pool1");

  Pool pool2=scheduler.getPoolManager().getPool("pool2");

  Pool pool3=scheduler.getPoolManager().getPool("pool3");

  JobInProgress job1=submitJob(JobStatus.RUNNING,12,0,"pool1");

  advanceTime(100);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000001_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2");

  advanceTime(100);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,0,"pool2");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0002_m_000000_0 on tt2");

  checkAssignment("tt3","attempt_test_0002_m_000001_0 on tt3");

  advanceTime(100);

  checkAssignment("tt3","attempt_test_0002_m_000002_0 on tt3");

  advanceTime(100);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,0,"pool3");

  advanceTime(59000);

  assertEquals(0,scheduler.tasksToPreempt(pool2.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool2.getReduceSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool3.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool3.getReduceSchedulable(),clock.getTime()));

  advanceTime(2000);

  assertEquals(0,scheduler.tasksToPreempt(pool2.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool2.getReduceSchedulable(),clock.getTime()));

  assertEquals(2,scheduler.tasksToPreempt(pool3.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool3.getReduceSchedulable(),clock.getTime()));

  scheduler.preemptTasksIfNecessary();

  scheduler.update();

  assertEquals(2,job2.runningMaps());

  assertEquals(2,job1.runningMaps());

  checkAssignment("tt2","attempt_test_0003_m_000000_0 on tt2");

  checkAssignment("tt3","attempt_test_0003_m_000001_0 on tt3");

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

  assertNull(scheduler.assignTasks(tracker("tt3")));

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits a job that takes all 2 slots in a pool has both a min share of 2 slots with minshare timeout of 5s, and then a second job in default pool with a fair share timeout of 5s. After 60 seconds, this pool will be starved of fair share (2 slots of each type), and we test that it does not kill more than 2 tasks of each type.

 */

public void testFairSharePreemptionWithShortTimeout() throws Exception {

  scheduler.preemptionEnabled=true;

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<fairSharePreemptionTimeout>5</fairSharePreemptionTimeout>");

  out.println("<pool name=\"pool1\">");

  out.println("<minMaps>2</minMaps>");

  out.println("<minReduces>2</minReduces>");

  out.println("<minSharePreemptionTimeout>5</minSharePreemptionTimeout>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool pool1=scheduler.getPoolManager().getPool("pool1");

  Pool defaultPool=scheduler.getPoolManager().getPool("default");

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10,"pool1");

  JobInfo info1=scheduler.infos.get(job1);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000001_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000001_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000003_0 on tt2");

  advanceTime(10000);

  assertEquals(4,info1.mapSchedulable.getRunningTasks());

  assertEquals(4,info1.reduceSchedulable.getRunningTasks());

  assertEquals(4.0,info1.mapSchedulable.getFairShare());

  assertEquals(4.0,info1.reduceSchedulable.getFairShare());

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"default");

  clock.advance(6000);

  assertEquals(4,info1.mapSchedulable.getRunningTasks());

  assertEquals(4,info1.reduceSchedulable.getRunningTasks());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(0,scheduler.tasksToPreempt(pool1.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(pool1.getReduceSchedulable(),clock.getTime()));

  assertEquals(2,scheduler.tasksToPreempt(defaultPool.getMapSchedulable(),clock.getTime()));

  assertEquals(2,scheduler.tasksToPreempt(defaultPool.getReduceSchedulable(),clock.getTime()));

  scheduler.preemptTasksIfNecessary();

  scheduler.update();

  assertEquals(2,job1.runningMaps());

  assertEquals(2,job1.runningReduces());

  checkAssignment("tt2","attempt_test_0002_m_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits 2 large jobs each to 2 pools, one of which is set to FIFO mode through the global defaultPoolSchedulingMode setting, and one of which is set to fair mode. We check that the scheduler assigns tasks only to the first job in the FIFO pool but to both jobs in the fair sharing pool.

 */

public void testFifoAndFairPools() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<defaultPoolSchedulingMode>fifo</defaultPoolSchedulingMode>");

  out.println("<pool name=\"poolB\">");

  out.println("<schedulingMode>fair</schedulingMode>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10,"poolA");

  advanceTime(10);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  advanceTime(10);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10,"poolB");

  advanceTime(10);

  JobInProgress job4=submitJob(JobStatus.RUNNING,10,10,"poolB");

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0004_m_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0004_r_000000_0 on tt2");

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits four jobs in the default pool, which is set to FIFO mode: - job1, with 1 map and 1 reduce - job2, with 3 maps and 3 reduces - job3, with 1 map, 1 reduce, and priority set to HIGH - job4, with 3 maps and 3 reduces We check that the scheduler assigns tasks first to job3 (because it is high priority), then to job1, then to job2.

 */

public void testFifoPool() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"default\">");

  out.println("<schedulingMode>fifo</schedulingMode>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,1,1);

  advanceTime(10);

  JobInProgress job2=submitJob(JobStatus.RUNNING,3,3);

  advanceTime(10);

  JobInProgress job3=submitJob(JobStatus.RUNNING,1,1);

  job3.setPriority(JobPriority.HIGH);

  advanceTime(10);

  JobInProgress job4=submitJob(JobStatus.RUNNING,3,3);

  checkAssignment("tt1","attempt_test_0003_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0002_m_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

}

Location: TestFairScheduler.java

Content: 

/** 

 * We submit two jobs such that one has 2x the priority of the other to  a cluster of 3 nodes, wait for 100 ms, and check that the weights/shares  the high-priority job gets 4 tasks while the normal-priority job gets 2.

 */

public void testJobsWithPriorities() throws IOException {

  setUpCluster(1,3,false);

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info1=scheduler.infos.get(job1);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info2=scheduler.infos.get(job2);

  job2.setPriority(JobPriority.HIGH);

  scheduler.update();

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(2.0,info1.mapSchedulable.getFairShare(),0.1);

  assertEquals(2.0,info1.reduceSchedulable.getFairShare(),0.1);

  assertEquals(0,info2.mapSchedulable.getRunningTasks());

  assertEquals(0,info2.reduceSchedulable.getRunningTasks());

  assertEquals(10,info2.mapSchedulable.getDemand());

  assertEquals(10,info2.reduceSchedulable.getDemand());

  assertEquals(4.0,info2.mapSchedulable.getFairShare(),0.1);

  assertEquals(4.0,info2.reduceSchedulable.getFairShare(),0.1);

  advanceTime(100);

  System.out.println("HEREEEE");

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0002_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000001_0 on tt2");

  checkAssignment("tt3","attempt_test_0002_m_000002_0 on tt3");

  checkAssignment("tt3","attempt_test_0002_r_000002_0 on tt3");

  checkAssignment("tt3","attempt_test_0002_m_000003_0 on tt3");

  checkAssignment("tt3","attempt_test_0002_r_000003_0 on tt3");

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test begins by submitting two jobs with 10 maps and reduces each. The first job is submitted 100ms after the second, to make it get slots first deterministically. We then assign a wave of tasks and check that they are given alternately to job1, job2, job1, job2, etc. We finish these tasks and assign a second wave, which should continue to be allocated in this manner.

 */

public void testLargeJobs() throws IOException {

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info1=scheduler.infos.get(job1);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(4.0,info1.mapSchedulable.getFairShare());

  assertEquals(4.0,info1.reduceSchedulable.getFairShare());

  advanceTime(100);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info2=scheduler.infos.get(job2);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(0,info2.mapSchedulable.getRunningTasks());

  assertEquals(0,info2.reduceSchedulable.getRunningTasks());

  assertEquals(10,info2.mapSchedulable.getDemand());

  assertEquals(10,info2.reduceSchedulable.getDemand());

  assertEquals(2.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

  assertEquals(2,info1.mapSchedulable.getRunningTasks());

  assertEquals(2,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(2,info2.mapSchedulable.getRunningTasks());

  assertEquals(2,info2.reduceSchedulable.getRunningTasks());

  assertEquals(10,info2.mapSchedulable.getDemand());

  assertEquals(10,info2.reduceSchedulable.getDemand());

  taskTrackerManager.finishTask("tt1","attempt_test_0001_m_000000_0");

  taskTrackerManager.finishTask("tt1","attempt_test_0002_m_000000_0");

  taskTrackerManager.finishTask("tt1","attempt_test_0001_r_000000_0");

  taskTrackerManager.finishTask("tt1","attempt_test_0002_r_000000_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0001_m_000001_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0002_m_000001_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0001_r_000001_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0002_r_000001_0");

  advanceTime(200);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(0,info2.mapSchedulable.getRunningTasks());

  assertEquals(0,info2.reduceSchedulable.getRunningTasks());

  checkAssignment("tt1","attempt_test_0001_m_000002_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000002_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_m_000002_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_r_000002_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_m_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000003_0 on tt2");

  assertEquals(2,info1.mapSchedulable.getRunningTasks());

  assertEquals(2,info1.reduceSchedulable.getRunningTasks());

  assertEquals(8,info1.mapSchedulable.getDemand());

  assertEquals(8,info1.reduceSchedulable.getDemand());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(2,info2.mapSchedulable.getRunningTasks());

  assertEquals(2,info2.reduceSchedulable.getRunningTasks());

  assertEquals(8,info2.mapSchedulable.getDemand());

  assertEquals(8,info2.reduceSchedulable.getDemand());

  assertEquals(2.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

}

Location: TestFairScheduler.java

Content: 

/** 

 * A copy of testLargeJobs that enables the assignMultiple feature to launch multiple tasks per heartbeat. Results should be the same as testLargeJobs.

 */

public void testLargeJobsWithAssignMultiple() throws IOException {

  setUpCluster(1,2,true);

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info1=scheduler.infos.get(job1);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(4.0,info1.mapSchedulable.getFairShare());

  assertEquals(4.0,info1.reduceSchedulable.getFairShare());

  advanceTime(100);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info2=scheduler.infos.get(job2);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(0,info2.mapSchedulable.getRunningTasks());

  assertEquals(0,info2.reduceSchedulable.getRunningTasks());

  assertEquals(10,info2.mapSchedulable.getDemand());

  assertEquals(10,info2.reduceSchedulable.getDemand());

  assertEquals(2.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1","attempt_test_0001_r_000000_0 on tt1","attempt_test_0002_m_000000_0 on tt1","attempt_test_0002_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2","attempt_test_0001_r_000001_0 on tt2","attempt_test_0002_m_000001_0 on tt2","attempt_test_0002_r_000001_0 on tt2");

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

  assertEquals(2,info1.mapSchedulable.getRunningTasks());

  assertEquals(2,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(2,info2.mapSchedulable.getRunningTasks());

  assertEquals(2,info2.reduceSchedulable.getRunningTasks());

  assertEquals(10,info2.mapSchedulable.getDemand());

  assertEquals(10,info2.reduceSchedulable.getDemand());

  taskTrackerManager.finishTask("tt1","attempt_test_0001_m_000000_0");

  taskTrackerManager.finishTask("tt1","attempt_test_0002_m_000000_0");

  taskTrackerManager.finishTask("tt1","attempt_test_0001_r_000000_0");

  taskTrackerManager.finishTask("tt1","attempt_test_0002_r_000000_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0001_m_000001_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0002_m_000001_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0001_r_000001_0");

  taskTrackerManager.finishTask("tt2","attempt_test_0002_r_000001_0");

  advanceTime(200);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(0,info2.mapSchedulable.getRunningTasks());

  assertEquals(0,info2.reduceSchedulable.getRunningTasks());

  checkAssignment("tt1","attempt_test_0001_m_000002_0 on tt1","attempt_test_0001_r_000002_0 on tt1","attempt_test_0002_m_000002_0 on tt1","attempt_test_0002_r_000002_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000003_0 on tt2","attempt_test_0001_r_000003_0 on tt2","attempt_test_0002_m_000003_0 on tt2","attempt_test_0002_r_000003_0 on tt2");

  assertEquals(2,info1.mapSchedulable.getRunningTasks());

  assertEquals(2,info1.reduceSchedulable.getRunningTasks());

  assertEquals(8,info1.mapSchedulable.getDemand());

  assertEquals(8,info1.reduceSchedulable.getDemand());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(2,info2.mapSchedulable.getRunningTasks());

  assertEquals(2,info2.reduceSchedulable.getRunningTasks());

  assertEquals(8,info2.mapSchedulable.getDemand());

  assertEquals(8,info2.reduceSchedulable.getDemand());

  assertEquals(2.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test starts by submitting three large jobs: - job1 in the default pool, at time 0 - job2 in poolA, with an allocation of 2 maps / 2 reduces, at time 200 - job3 in poolA, with an allocation of 2 maps / 2 reduces, at time 300 After this, we start assigning tasks. The first two tasks of each type should be assigned to job2 and job3 since they are in a pool with an allocation guarantee, but the next two slots should be assigned to job 3 because the pool will no longer be needy.

 */

public void testLargeJobsWithExcessCapacity() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>2</minMaps>");

  out.println("<minReduces>2</minReduces>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool poolA=scheduler.getPoolManager().getPool("poolA");

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info1=scheduler.infos.get(job1);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(4.0,info1.mapSchedulable.getFairShare());

  assertEquals(4.0,info1.reduceSchedulable.getFairShare());

  advanceTime(200);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  JobInfo info2=scheduler.infos.get(job2);

  assertEquals(2,poolA.getMapSchedulable().getMinShare());

  assertEquals(2,poolA.getReduceSchedulable().getMinShare());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(2.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

  advanceTime(100);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10,"poolA");

  JobInfo info3=scheduler.infos.get(job3);

  assertEquals(2,poolA.getMapSchedulable().getMinShare());

  assertEquals(2,poolA.getReduceSchedulable().getMinShare());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(1.0,info2.mapSchedulable.getFairShare());

  assertEquals(1.0,info2.reduceSchedulable.getFairShare());

  assertEquals(1.0,info3.mapSchedulable.getFairShare());

  assertEquals(1.0,info3.reduceSchedulable.getFairShare());

  advanceTime(100);

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000001_0 on tt2");

}

Location: TestFairScheduler.java

Content: 

/** 

 * A copy of testLargeJobsWithExcessCapacity that enables assigning multiple tasks per heartbeat. Results should match testLargeJobsWithExcessCapacity.

 */

public void testLargeJobsWithExcessCapacityAndAssignMultiple() throws Exception {

  setUpCluster(1,2,true);

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>2</minMaps>");

  out.println("<minReduces>2</minReduces>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool poolA=scheduler.getPoolManager().getPool("poolA");

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info1=scheduler.infos.get(job1);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(4.0,info1.mapSchedulable.getFairShare());

  assertEquals(4.0,info1.reduceSchedulable.getFairShare());

  advanceTime(200);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  JobInfo info2=scheduler.infos.get(job2);

  assertEquals(2,poolA.getMapSchedulable().getMinShare());

  assertEquals(2,poolA.getReduceSchedulable().getMinShare());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(2.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

  advanceTime(100);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10,"poolA");

  JobInfo info3=scheduler.infos.get(job3);

  assertEquals(2,poolA.getMapSchedulable().getMinShare());

  assertEquals(2,poolA.getReduceSchedulable().getMinShare());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(1.0,info2.mapSchedulable.getFairShare());

  assertEquals(1.0,info2.reduceSchedulable.getFairShare());

  assertEquals(1.0,info3.mapSchedulable.getFairShare());

  assertEquals(1.0,info3.reduceSchedulable.getFairShare());

  advanceTime(100);

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1","attempt_test_0002_r_000000_0 on tt1","attempt_test_0003_m_000000_0 on tt1","attempt_test_0003_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000000_0 on tt2","attempt_test_0001_r_000000_0 on tt2","attempt_test_0001_m_000001_0 on tt2","attempt_test_0001_r_000001_0 on tt2");

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test starts by submitting three large jobs: - job1 in the default pool, at time 0 - job2 in poolA, with an allocation of 1 map / 2 reduces, at time 200 - job3 in poolB, with an allocation of 2 maps / 1 reduce, at time 300 We then assign tasks to all slots. The maps should be assigned in the order job2, job3, job 3, job1 because jobs 3 and 2 have guaranteed slots (1 and 2 respectively). Job2 comes before job3 when they are both at 0 slots because it has an earlier start time. In a similar manner, reduces should be assigned as job2, job3, job2, job1.

 */

public void testLargeJobsWithPools() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>1</minMaps>");

  out.println("<minReduces>2</minReduces>");

  out.println("</pool>");

  out.println("<pool name=\"poolB\">");

  out.println("<minMaps>2</minMaps>");

  out.println("<minReduces>1</minReduces>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool defaultPool=scheduler.getPoolManager().getPool("default");

  Pool poolA=scheduler.getPoolManager().getPool("poolA");

  Pool poolB=scheduler.getPoolManager().getPool("poolB");

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info1=scheduler.infos.get(job1);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(4.0,info1.mapSchedulable.getFairShare());

  assertEquals(4.0,info1.reduceSchedulable.getFairShare());

  advanceTime(200);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  JobInfo info2=scheduler.infos.get(job2);

  advanceTime(100);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10,"poolB");

  JobInfo info3=scheduler.infos.get(job3);

  assertEquals(0,defaultPool.getMapSchedulable().getMinShare());

  assertEquals(0,defaultPool.getReduceSchedulable().getMinShare());

  assertEquals(1.0,info1.mapSchedulable.getFairShare());

  assertEquals(1.0,info1.reduceSchedulable.getFairShare());

  assertEquals(1,poolA.getMapSchedulable().getMinShare());

  assertEquals(2,poolA.getReduceSchedulable().getMinShare());

  assertEquals(1.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

  assertEquals(2,poolB.getMapSchedulable().getMinShare());

  assertEquals(1,poolB.getReduceSchedulable().getMinShare());

  assertEquals(2.0,info3.mapSchedulable.getFairShare());

  assertEquals(1.0,info3.reduceSchedulable.getFairShare());

  advanceTime(100);

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0003_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000000_0 on tt2");

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits a job that takes all 4 slots, and then a second job in a pool that has both a min share of 2 slots with a 60s timeout and a fair share timeout of 60s. After 60 seconds, this pool will be starved of both min share (2 slots of each type) and fair share (2 slots of each type), and we test that it does not kill more than 2 tasks of each type in total.

 */

public void testMinAndFairSharePreemption() throws Exception {

  scheduler.preemptionEnabled=true;

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>2</minMaps>");

  out.println("<minReduces>2</minReduces>");

  out.println("<minSharePreemptionTimeout>60</minSharePreemptionTimeout>");

  out.println("</pool>");

  out.println("<fairSharePreemptionTimeout>60</fairSharePreemptionTimeout>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool poolA=scheduler.getPoolManager().getPool("poolA");

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000001_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000001_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000003_0 on tt2");

  advanceTime(10000);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  advanceTime(10000);

  assertEquals(0,scheduler.tasksToPreempt(poolA.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(poolA.getReduceSchedulable(),clock.getTime()));

  advanceTime(49000);

  assertEquals(0,scheduler.tasksToPreempt(poolA.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(poolA.getReduceSchedulable(),clock.getTime()));

  advanceTime(2000);

  assertEquals(2,scheduler.tasksToPreempt(poolA.getMapSchedulable(),clock.getTime()));

  assertEquals(2,scheduler.tasksToPreempt(poolA.getReduceSchedulable(),clock.getTime()));

  scheduler.preemptTasksIfNecessary();

  scheduler.update();

  assertEquals(2,job1.runningMaps());

  assertEquals(2,job1.runningReduces());

  checkAssignment("tt2","attempt_test_0002_m_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test starts by launching a job in the default pool that takes all the slots in the cluster. We then submit a job in a pool with min share of 2 maps and 1 reduce task. After the min share preemption timeout, this pool should be allowed to preempt tasks. 

 */

public void testMinSharePreemption() throws Exception {

  scheduler.preemptionEnabled=true;

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>2</minMaps>");

  out.println("<minReduces>1</minReduces>");

  out.println("<minSharePreemptionTimeout>60</minSharePreemptionTimeout>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool poolA=scheduler.getPoolManager().getPool("poolA");

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000001_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000001_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000003_0 on tt2");

  advanceTime(10000);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  advanceTime(10000);

  assertEquals(0,scheduler.tasksToPreempt(poolA.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(poolA.getReduceSchedulable(),clock.getTime()));

  advanceTime(49000);

  assertEquals(0,scheduler.tasksToPreempt(poolA.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(poolA.getReduceSchedulable(),clock.getTime()));

  advanceTime(2000);

  assertEquals(2,scheduler.tasksToPreempt(poolA.getMapSchedulable(),clock.getTime()));

  assertEquals(1,scheduler.tasksToPreempt(poolA.getReduceSchedulable(),clock.getTime()));

  scheduler.preemptTasksIfNecessary();

  scheduler.update();

  assertEquals(2,job1.runningMaps());

  assertEquals(3,job1.runningReduces());

  checkAssignment("tt2","attempt_test_0002_m_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000000_0 on tt2");

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test starts by launching a job in the default pool that takes all the slots in the cluster. We then submit a job in a pool with min share of 3 maps and 3 reduce tasks, but which only actually needs 1 map and 2 reduces. We check that this pool does not prempt more than this many tasks despite its min share being higher. 

 */

public void testMinSharePreemptionWithSmallJob() throws Exception {

  scheduler.preemptionEnabled=true;

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>3</minMaps>");

  out.println("<minReduces>3</minReduces>");

  out.println("<minSharePreemptionTimeout>60</minSharePreemptionTimeout>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool poolA=scheduler.getPoolManager().getPool("poolA");

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000001_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000001_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000003_0 on tt2");

  advanceTime(10000);

  JobInProgress job2=submitJob(JobStatus.RUNNING,1,2,"poolA");

  advanceTime(59000);

  assertEquals(0,scheduler.tasksToPreempt(poolA.getMapSchedulable(),clock.getTime()));

  assertEquals(0,scheduler.tasksToPreempt(poolA.getReduceSchedulable(),clock.getTime()));

  advanceTime(2000);

  assertEquals(1,scheduler.tasksToPreempt(poolA.getMapSchedulable(),clock.getTime()));

  assertEquals(2,scheduler.tasksToPreempt(poolA.getReduceSchedulable(),clock.getTime()));

  scheduler.preemptTasksIfNecessary();

  scheduler.update();

  assertEquals(3,job1.runningMaps());

  assertEquals(2,job1.runningReduces());

  checkAssignment("tt2","attempt_test_0002_r_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_m_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits 2 large jobs each to 2 pools, which are both set to FIFO mode through the global defaultPoolSchedulingMode setting. We check that the scheduler assigns tasks only to the first job within each pool, but alternates between the pools to give each pool a fair share.

 */

public void testMultipleFifoPools() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<defaultPoolSchedulingMode>fifo</defaultPoolSchedulingMode>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10,"poolA");

  advanceTime(10);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  advanceTime(10);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10,"poolB");

  advanceTime(10);

  JobInProgress job4=submitJob(JobStatus.RUNNING,10,10,"poolB");

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0003_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0003_r_000001_0 on tt2");

}

Location: TestFairScheduler.java

Content: 

/** 

 * This is a copy of testMinAndFairSharePreemption that turns preemption off and verifies that no tasks get killed.

 */

public void testNoPreemptionIfDisabled() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>2</minMaps>");

  out.println("<minReduces>2</minReduces>");

  out.println("<minSharePreemptionTimeout>60</minSharePreemptionTimeout>");

  out.println("</pool>");

  out.println("<fairSharePreemptionTimeout>60</fairSharePreemptionTimeout>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000001_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000001_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000003_0 on tt2");

  advanceTime(10000);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  advanceTime(61000);

  scheduler.preemptTasksIfNecessary();

  scheduler.update();

  assertEquals(4,job1.runningMaps());

  assertEquals(4,job1.runningReduces());

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

}

Location: TestFairScheduler.java

Content: 

/** 

 * This is a copy of testMinAndFairSharePreemption that turns preemption on but also turns on mapred.fairscheduler.preemption.only.log (the "dry run" parameter for testing out preemption) and verifies that no tasks get killed.

 */

public void testNoPreemptionIfOnlyLogging() throws Exception {

  scheduler.preemptionEnabled=true;

  scheduler.onlyLogPreemption=true;

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>2</minMaps>");

  out.println("<minReduces>2</minReduces>");

  out.println("<minSharePreemptionTimeout>60</minSharePreemptionTimeout>");

  out.println("</pool>");

  out.println("<fairSharePreemptionTimeout>60</fairSharePreemptionTimeout>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000001_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000001_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000003_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000003_0 on tt2");

  advanceTime(10000);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  advanceTime(61000);

  scheduler.preemptTasksIfNecessary();

  scheduler.update();

  assertEquals(4,job1.runningMaps());

  assertEquals(4,job1.runningReduces());

  assertNull(scheduler.assignTasks(tracker("tt1")));

  assertNull(scheduler.assignTasks(tracker("tt2")));

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test uses the mapred.fairscheduler.pool property to assign jobs to pools.

 */

public void testPoolAssignment() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"default\">");

  out.println("<schedulingMode>fair</schedulingMode>");

  out.println("</pool>");

  out.println("<pool name=\"poolA\">");

  out.println("<schedulingMode>fair</schedulingMode>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  Pool defaultPool=scheduler.getPoolManager().getPool("default");

  Pool poolA=scheduler.getPoolManager().getPool("poolA");

  JobInProgress job1=submitJob(JobStatus.RUNNING,1,3);

  assertEquals(1,defaultPool.getMapSchedulable().getDemand());

  assertEquals(3,defaultPool.getReduceSchedulable().getDemand());

  assertEquals(0,poolA.getMapSchedulable().getDemand());

  assertEquals(0,poolA.getReduceSchedulable().getDemand());

  JobInProgress job2=submitJob(JobStatus.RUNNING,5,7);

  assertEquals(6,defaultPool.getMapSchedulable().getDemand());

  assertEquals(10,defaultPool.getReduceSchedulable().getDemand());

  assertEquals(0,poolA.getMapSchedulable().getDemand());

  assertEquals(0,poolA.getReduceSchedulable().getDemand());

  scheduler.getPoolManager().setPool(job2,"poolA");

  assertEquals("poolA",scheduler.getPoolManager().getPoolName(job2));

  defaultPool.getMapSchedulable().updateDemand();

  defaultPool.getReduceSchedulable().updateDemand();

  poolA.getMapSchedulable().updateDemand();

  poolA.getReduceSchedulable().updateDemand();

  assertEquals(1,defaultPool.getMapSchedulable().getDemand());

  assertEquals(3,defaultPool.getReduceSchedulable().getDemand());

  assertEquals(5,poolA.getMapSchedulable().getDemand());

  assertEquals(7,poolA.getReduceSchedulable().getDemand());

  JobConf jobConf=new JobConf(conf);

  jobConf.setNumMapTasks(11);

  jobConf.setNumReduceTasks(13);

  jobConf.set(POOL_PROPERTY,"nonsense");

  jobConf.set(EXPLICIT_POOL_PROPERTY,"poolA");

  JobInProgress job3=new FakeJobInProgress(jobConf,taskTrackerManager,null,UtilsForTests.getJobTracker());

  job3.initTasks();

  job3.getStatus().setRunState(JobStatus.RUNNING);

  taskTrackerManager.submitJob(job3);

  assertEquals(1,defaultPool.getMapSchedulable().getDemand());

  assertEquals(3,defaultPool.getReduceSchedulable().getDemand());

  assertEquals(16,poolA.getMapSchedulable().getDemand());

  assertEquals(20,poolA.getReduceSchedulable().getDemand());

  JobConf jobConf2=new JobConf(conf);

  jobConf2.setNumMapTasks(17);

  jobConf2.setNumReduceTasks(19);

  jobConf2.set(POOL_PROPERTY,"poolA");

  JobInProgress job4=new FakeJobInProgress(jobConf2,taskTrackerManager,null,UtilsForTests.getJobTracker());

  job4.initTasks();

  job4.getStatus().setRunState(JobStatus.RUNNING);

  taskTrackerManager.submitJob(job4);

  assertEquals(1,defaultPool.getMapSchedulable().getDemand());

  assertEquals(3,defaultPool.getReduceSchedulable().getDemand());

  assertEquals(33,poolA.getMapSchedulable().getDemand());

  assertEquals(39,poolA.getReduceSchedulable().getDemand());

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test starts by submitting four jobs in the default pool. However, the maxRunningJobs limit for this pool has been set to two. We should see only the first two jobs get scheduled, each with half the total slots.

 */

public void testPoolMaxJobs() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"default\">");

  out.println("<maxRunningJobs>2</maxRunningJobs>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJobNotInitialized(JobStatus.PREP,10,10);

  assertTrue(((FakeJobInProgress)job1).inited());

  job1.getStatus().setRunState(JobStatus.RUNNING);

  JobInfo info1=scheduler.infos.get(job1);

  advanceTime(10);

  JobInProgress job2=submitJobNotInitialized(JobStatus.PREP,10,10);

  assertTrue(((FakeJobInProgress)job2).inited());

  job2.getStatus().setRunState(JobStatus.RUNNING);

  JobInfo info2=scheduler.infos.get(job2);

  advanceTime(10);

  JobInProgress job3=submitJobNotInitialized(JobStatus.PREP,10,10);

  JobInfo info3=scheduler.infos.get(job3);

  advanceTime(10);

  JobInProgress job4=submitJobNotInitialized(JobStatus.PREP,10,10);

  JobInfo info4=scheduler.infos.get(job4);

  assertTrue(((FakeJobInProgress)job1).inited());

  assertTrue(((FakeJobInProgress)job2).inited());

  assertFalse(((FakeJobInProgress)job3).inited());

  assertFalse(((FakeJobInProgress)job4).inited());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(2.0,info1.reduceSchedulable.getFairShare());

  assertEquals(2.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

  assertEquals(0.0,info3.mapSchedulable.getFairShare());

  assertEquals(0.0,info3.reduceSchedulable.getFairShare());

  assertEquals(0.0,info4.mapSchedulable.getFairShare());

  assertEquals(0.0,info4.reduceSchedulable.getFairShare());

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_r_000000_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

}

Location: TestFairScheduler.java

Content: 

public void testPoolMaxMapsReduces() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolLimited\">");

  out.println("<weight>1.0</weight>");

  out.println("<maxMaps>2</maxMaps>");

  out.println("<maxReduces>1</maxReduces>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,5,"poolLimited");

  advanceTime(10);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,5);

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0002_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000002_0 on tt2");

  Pool limited=scheduler.getPoolManager().getPool("poolLimited");

  assertEquals(2,limited.getSchedulable(TaskType.MAP).getRunningTasks());

  assertEquals(1,limited.getSchedulable(TaskType.REDUCE).getRunningTasks());

  Pool defaultPool=scheduler.getPoolManager().getPool("default");

  assertEquals(2,defaultPool.getSchedulable(TaskType.MAP).getRunningTasks());

  assertEquals(3,defaultPool.getSchedulable(TaskType.REDUCE).getRunningTasks());

  assertEquals(2,job1.runningMapTasks);

  assertEquals(1,job1.runningReduceTasks);

  assertEquals(2,job2.runningMapTasks);

  assertEquals(3,job2.runningReduceTasks);

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits jobs in three pools: poolA, which has a weight of 2.0; poolB, which has a weight of 0.5; and the default pool, which should have a weight of 1.0. It then checks that the map and reduce fair shares are given out accordingly. We then submit a second job to pool B and check that each gets half of the pool (weight of 0.25).

 */

public void testPoolWeights() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<weight>2.0</weight>");

  out.println("</pool>");

  out.println("<pool name=\"poolB\">");

  out.println("<weight>0.5</weight>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info1=scheduler.infos.get(job1);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10,"poolA");

  JobInfo info2=scheduler.infos.get(job2);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10,"poolB");

  JobInfo info3=scheduler.infos.get(job3);

  advanceTime(10);

  assertEquals(1.14,info1.mapSchedulable.getFairShare(),0.01);

  assertEquals(1.14,info1.reduceSchedulable.getFairShare(),0.01);

  assertEquals(2.28,info2.mapSchedulable.getFairShare(),0.01);

  assertEquals(2.28,info2.reduceSchedulable.getFairShare(),0.01);

  assertEquals(0.57,info3.mapSchedulable.getFairShare(),0.01);

  assertEquals(0.57,info3.reduceSchedulable.getFairShare(),0.01);

  JobInProgress job4=submitJob(JobStatus.RUNNING,10,10,"poolB");

  JobInfo info4=scheduler.infos.get(job4);

  advanceTime(10);

  assertEquals(1.14,info1.mapSchedulable.getFairShare(),0.01);

  assertEquals(1.14,info1.reduceSchedulable.getFairShare(),0.01);

  assertEquals(2.28,info2.mapSchedulable.getFairShare(),0.01);

  assertEquals(2.28,info2.reduceSchedulable.getFairShare(),0.01);

  assertEquals(0.28,info3.mapSchedulable.getFairShare(),0.01);

  assertEquals(0.28,info3.reduceSchedulable.getFairShare(),0.01);

  assertEquals(0.28,info4.mapSchedulable.getFairShare(),0.01);

  assertEquals(0.28,info4.reduceSchedulable.getFairShare(),0.01);

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test submits jobs in two pools, poolA and poolB. None of the jobs in poolA have maps, but this should not affect their reduce share.

 */

public void testPoolWeightsWhenNoMaps() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<weight>2.0</weight>");

  out.println("</pool>");

  out.println("<pool name=\"poolB\">");

  out.println("<weight>1.0</weight>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,0,10,"poolA");

  JobInfo info1=scheduler.infos.get(job1);

  JobInProgress job2=submitJob(JobStatus.RUNNING,0,10,"poolA");

  JobInfo info2=scheduler.infos.get(job2);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10,"poolB");

  JobInfo info3=scheduler.infos.get(job3);

  advanceTime(10);

  assertEquals(0,info1.mapSchedulable.getFairShare(),0.01);

  assertEquals(1.33,info1.reduceSchedulable.getFairShare(),0.01);

  assertEquals(0,info2.mapSchedulable.getFairShare(),0.01);

  assertEquals(1.33,info2.reduceSchedulable.getFairShare(),0.01);

  assertEquals(4,info3.mapSchedulable.getFairShare(),0.01);

  assertEquals(1.33,info3.reduceSchedulable.getFairShare(),0.01);

}

Location: TestFairScheduler.java

Content: 

public void testSizeBasedWeight() throws Exception {

  scheduler.sizeBasedWeight=true;

  JobInProgress job1=submitJob(JobStatus.RUNNING,2,10);

  JobInProgress job2=submitJob(JobStatus.RUNNING,20,1);

  assertTrue(scheduler.infos.get(job2).mapSchedulable.getFairShare() > scheduler.infos.get(job1).mapSchedulable.getFairShare());

  assertTrue(scheduler.infos.get(job1).reduceSchedulable.getFairShare() > scheduler.infos.get(job2).reduceSchedulable.getFairShare());

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test starts by submitting two jobs at time 0: - job1 in the default pool - job2, with 1 map and 1 reduce, in poolA, which has an alloc of 4 maps and 4 reduces When we assign the slots, job2 should only get 1 of each type of task.

 */

public void testSmallJobInLargePool() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<pool name=\"poolA\">");

  out.println("<minMaps>4</minMaps>");

  out.println("<minReduces>4</minReduces>");

  out.println("</pool>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  JobInfo info1=scheduler.infos.get(job1);

  JobInProgress job2=submitJob(JobStatus.RUNNING,1,1,"poolA");

  JobInfo info2=scheduler.infos.get(job2);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(10,info1.mapSchedulable.getDemand());

  assertEquals(10,info1.reduceSchedulable.getDemand());

  assertEquals(3.0,info1.mapSchedulable.getFairShare());

  assertEquals(3.0,info1.reduceSchedulable.getFairShare());

  assertEquals(0,info2.mapSchedulable.getRunningTasks());

  assertEquals(0,info2.reduceSchedulable.getRunningTasks());

  assertEquals(1,info2.mapSchedulable.getDemand());

  assertEquals(1,info2.reduceSchedulable.getDemand());

  assertEquals(1.0,info2.mapSchedulable.getFairShare());

  assertEquals(1.0,info2.reduceSchedulable.getFairShare());

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000002_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000002_0 on tt2");

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test contains two jobs with fewer required tasks than there are slots. We check that all tasks are assigned, but job 1 gets them first because it was submitted earlier.

 */

public void testSmallJobs() throws IOException {

  JobInProgress job1=submitJob(JobStatus.RUNNING,2,1);

  JobInfo info1=scheduler.infos.get(job1);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(2,info1.mapSchedulable.getDemand());

  assertEquals(1,info1.reduceSchedulable.getDemand());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(1.0,info1.reduceSchedulable.getFairShare());

  advanceTime(100);

  JobInProgress job2=submitJob(JobStatus.RUNNING,1,2);

  JobInfo info2=scheduler.infos.get(job2);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(2,info1.mapSchedulable.getDemand());

  assertEquals(1,info1.reduceSchedulable.getDemand());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(1.0,info1.reduceSchedulable.getFairShare());

  assertEquals(0,info2.mapSchedulable.getRunningTasks());

  assertEquals(0,info2.reduceSchedulable.getRunningTasks());

  assertEquals(1,info2.mapSchedulable.getDemand());

  assertEquals(2,info2.reduceSchedulable.getDemand());

  assertEquals(1.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0002_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0002_r_000001_0 on tt2");

  assertNull(scheduler.assignTasks(tracker("tt2")));

  assertEquals(2,info1.mapSchedulable.getRunningTasks());

  assertEquals(1,info1.reduceSchedulable.getRunningTasks());

  assertEquals(2,info1.mapSchedulable.getDemand());

  assertEquals(1,info1.reduceSchedulable.getDemand());

  assertEquals(1,info2.mapSchedulable.getRunningTasks());

  assertEquals(2,info2.reduceSchedulable.getRunningTasks());

  assertEquals(1,info2.mapSchedulable.getDemand());

  assertEquals(2,info2.reduceSchedulable.getDemand());

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test is identical to testSmallJobs but sets assignMultiple to true so that multiple tasks can be assigned per heartbeat.

 */

public void testSmallJobsWithAssignMultiple() throws IOException {

  setUpCluster(1,2,true);

  JobInProgress job1=submitJob(JobStatus.RUNNING,2,1);

  JobInfo info1=scheduler.infos.get(job1);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(2,info1.mapSchedulable.getDemand());

  assertEquals(1,info1.reduceSchedulable.getDemand());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(1.0,info1.reduceSchedulable.getFairShare());

  advanceTime(100);

  JobInProgress job2=submitJob(JobStatus.RUNNING,1,2);

  JobInfo info2=scheduler.infos.get(job2);

  assertEquals(0,info1.mapSchedulable.getRunningTasks());

  assertEquals(0,info1.reduceSchedulable.getRunningTasks());

  assertEquals(2,info1.mapSchedulable.getDemand());

  assertEquals(1,info1.reduceSchedulable.getDemand());

  assertEquals(2.0,info1.mapSchedulable.getFairShare());

  assertEquals(1.0,info1.reduceSchedulable.getFairShare());

  assertEquals(0,info2.mapSchedulable.getRunningTasks());

  assertEquals(0,info2.reduceSchedulable.getRunningTasks());

  assertEquals(1,info2.mapSchedulable.getDemand());

  assertEquals(2,info2.reduceSchedulable.getDemand());

  assertEquals(1.0,info2.mapSchedulable.getFairShare());

  assertEquals(2.0,info2.reduceSchedulable.getFairShare());

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1","attempt_test_0001_r_000000_0 on tt1","attempt_test_0002_m_000000_0 on tt1","attempt_test_0002_r_000000_0 on tt1");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2","attempt_test_0002_r_000001_0 on tt2");

  assertNull(scheduler.assignTasks(tracker("tt2")));

  assertEquals(2,info1.mapSchedulable.getRunningTasks());

  assertEquals(1,info1.reduceSchedulable.getRunningTasks());

  assertEquals(2,info1.mapSchedulable.getDemand());

  assertEquals(1,info1.reduceSchedulable.getDemand());

  assertEquals(1,info2.mapSchedulable.getRunningTasks());

  assertEquals(2,info2.reduceSchedulable.getRunningTasks());

  assertEquals(1,info2.mapSchedulable.getDemand());

  assertEquals(2,info2.reduceSchedulable.getDemand());

}

Location: TestFairScheduler.java

Content: 

/** 

 * This test starts by submitting two jobs by user "user1" to the default pool, and two jobs by "user2". We set user1's job limit to 1. We should see one job from user1 and two from user2. 

 */

public void testUserMaxJobs() throws Exception {

  PrintWriter out=new PrintWriter(new FileWriter(ALLOC_FILE));

  out.println("<?xml version=\"1.0\"?>");

  out.println("<allocations>");

  out.println("<user name=\"user1\">");

  out.println("<maxRunningJobs>1</maxRunningJobs>");

  out.println("</user>");

  out.println("</allocations>");

  out.close();

  scheduler.getPoolManager().reloadAllocs();

  JobInProgress job1=submitJob(JobStatus.RUNNING,10,10);

  job1.getJobConf().set(JobContext.USER_NAME,"user1");

  JobInfo info1=scheduler.infos.get(job1);

  advanceTime(10);

  JobInProgress job2=submitJob(JobStatus.RUNNING,10,10);

  job2.getJobConf().set(JobContext.USER_NAME,"user1");

  JobInfo info2=scheduler.infos.get(job2);

  advanceTime(10);

  JobInProgress job3=submitJob(JobStatus.RUNNING,10,10);

  job3.getJobConf().set(JobContext.USER_NAME,"user2");

  JobInfo info3=scheduler.infos.get(job3);

  advanceTime(10);

  JobInProgress job4=submitJob(JobStatus.RUNNING,10,10);

  job4.getJobConf().set(JobContext.USER_NAME,"user2");

  JobInfo info4=scheduler.infos.get(job4);

  assertEquals(1.33,info1.mapSchedulable.getFairShare(),0.1);

  assertEquals(1.33,info1.reduceSchedulable.getFairShare(),0.1);

  assertEquals(0.0,info2.mapSchedulable.getFairShare());

  assertEquals(0.0,info2.reduceSchedulable.getFairShare());

  assertEquals(1.33,info3.mapSchedulable.getFairShare(),0.1);

  assertEquals(1.33,info3.reduceSchedulable.getFairShare(),0.1);

  assertEquals(1.33,info4.mapSchedulable.getFairShare(),0.1);

  assertEquals(1.33,info4.reduceSchedulable.getFairShare(),0.1);

  checkAssignment("tt1","attempt_test_0001_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0001_r_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_m_000000_0 on tt1");

  checkAssignment("tt1","attempt_test_0003_r_000000_0 on tt1");

  advanceTime(100);

  checkAssignment("tt2","attempt_test_0004_m_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0004_r_000000_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_m_000001_0 on tt2");

  checkAssignment("tt2","attempt_test_0001_r_000001_0 on tt2");

}

Location: TestFairScheduler.java

Content: 

protected TaskTracker tracker(String taskTrackerName){

  return taskTrackerManager.getTaskTracker(taskTrackerName);

}

