Location: TestReduceFetch.java

Content: 

/** 

 * Verify that all segments are read from disk

 * @throws Exception might be thrown

 */

public void testReduceFromDisk() throws Exception {

  final int MAP_TASKS=8;

  JobConf job=mrCluster.createJobConf();

  job.set(JobContext.REDUCE_INPUT_BUFFER_PERCENT,"0.0");

  job.setNumMapTasks(MAP_TASKS);

  job.set(JobConf.MAPRED_REDUCE_TASK_JAVA_OPTS,"-Xmx128m");

  job.setLong(JobContext.REDUCE_MEMORY_TOTAL_BYTES,128 << 20);

  job.set(JobContext.SHUFFLE_INPUT_BUFFER_PERCENT,"0.05");

  job.setInt(JobContext.IO_SORT_FACTOR,2);

  job.setInt(JobContext.REDUCE_MERGE_INMEM_THRESHOLD,4);

  Counters c=runJob(job);

  final long spill=c.findCounter(TaskCounter.SPILLED_RECORDS).getCounter();

  final long out=c.findCounter(TaskCounter.MAP_OUTPUT_RECORDS).getCounter();

  assertTrue("Expected all records spilled during reduce (" + spill + ")",spill >= 2 * out);

  assertTrue("Expected intermediate merges (" + spill + ")",spill >= 2 * out + (out / MAP_TASKS));

}

Location: TestReduceFetch.java

Content: 

/** 

 * Verify that no segment hits disk.

 * @throws Exception might be thrown

 */

public void testReduceFromMem() throws Exception {

  final int MAP_TASKS=3;

  JobConf job=mrCluster.createJobConf();

  job.set(JobContext.REDUCE_INPUT_BUFFER_PERCENT,"1.0");

  job.set(JobContext.SHUFFLE_INPUT_BUFFER_PERCENT,"1.0");

  job.setLong(JobContext.REDUCE_MEMORY_TOTAL_BYTES,128 << 20);

  job.setNumMapTasks(MAP_TASKS);

  Counters c=runJob(job);

  final long spill=c.findCounter(TaskCounter.SPILLED_RECORDS).getCounter();

  final long out=c.findCounter(TaskCounter.MAP_OUTPUT_RECORDS).getCounter();

  assertEquals("Spilled records: " + spill,out,spill);

}

