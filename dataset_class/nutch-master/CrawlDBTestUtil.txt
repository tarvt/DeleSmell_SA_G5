Location: CrawlDBTestUtil.java

Content: 

/** 

 * For now we need to manually construct our Configuration, because we need to override the default one and it is currently not possible to use dynamically set values.

 * @return

 */

public static Reducer<Text,CrawlDatum,Text,CrawlDatum>.Context createContext(){

  DummyContext context=new DummyContext();

  Configuration conf=context.getConfiguration();

  conf.addResource("nutch-default.xml");

  conf.addResource("crawl-tests.xml");

  return (Reducer<Text,CrawlDatum,Text,CrawlDatum>.Context)context;

}

Location: CrawlDBTestUtil.java

Content: 

/** 

 * Creates synthetic crawldb

 * @param fs filesystem where db will be created

 * @param crawldb path were db will be created

 * @param init urls to be inserted, objects are of type URLCrawlDatum

 * @throws Exception

 */

public static void createCrawlDb(Configuration conf,FileSystem fs,Path crawldb,List<URLCrawlDatum> init) throws Exception {

  LOG.trace("* creating crawldb: " + crawldb);

  Path dir=new Path(crawldb,CrawlDb.CURRENT_NAME);

  Option wKeyOpt=MapFile.Writer.keyClass(Text.class);

  org.apache.hadoop.io.SequenceFile.Writer.Option wValueOpt=SequenceFile.Writer.valueClass(CrawlDatum.class);

  MapFile.Writer writer=new MapFile.Writer(conf,new Path(dir,"part-r-00000"),wKeyOpt,wValueOpt);

  Iterator<URLCrawlDatum> it=init.iterator();

  while (it.hasNext()) {

    URLCrawlDatum row=it.next();

    LOG.info("adding:" + row.url.toString());

    writer.append(new Text(row.url),row.datum);

  }

  writer.close();

}

Location: CrawlDBTestUtil.java

Content: 

/** 

 * Generate seedlist

 * @throws IOException

 */

public static void generateSeedList(FileSystem fs,Path urlPath,List<String> urls) throws IOException {

  generateSeedList(fs,urlPath,urls,new ArrayList<String>());

}

Location: CrawlDBTestUtil.java

Content: 

/** 

 * Generate seedlist

 * @throws IOException

 */

public static void generateSeedList(FileSystem fs,Path urlPath,List<String> urls,List<String> metadata) throws IOException {

  FSDataOutputStream out;

  Path file=new Path(urlPath,"urls.txt");

  fs.mkdirs(urlPath);

  out=fs.create(file);

  Iterator<String> urls_i=urls.iterator();

  Iterator<String> metadata_i=metadata.iterator();

  String url;

  String md;

  while (urls_i.hasNext()) {

    url=urls_i.next();

    out.writeBytes(url);

    if (metadata_i.hasNext()) {

      md=metadata_i.next();

      out.writeBytes(md);

    }

    out.writeBytes("\n");

  }

  out.flush();

  out.close();

}

Location: CrawlDBTestUtil.java

Content: 

/** 

 * Creates a new JettyServer with one static root context

 * @param port port to listen to

 * @param staticContent folder where static content lives

 * @throws UnknownHostException

 */

public static Server getServer(int port,String staticContent) throws UnknownHostException {

  Server webServer=new org.mortbay.jetty.Server();

  SocketConnector listener=new SocketConnector();

  listener.setPort(port);

  listener.setHost("127.0.0.1");

  webServer.addConnector(listener);

  ContextHandler staticContext=new ContextHandler();

  staticContext.setContextPath("/");

  staticContext.setResourceBase(staticContent);

  staticContext.addHandler(new ResourceHandler());

  webServer.addHandler(staticContext);

  return webServer;

}

