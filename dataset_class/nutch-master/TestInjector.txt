Location: TestInjector.java

Content: 

private List<String> readCrawldb() throws IOException {

  Path dbfile=new Path(crawldbPath,CrawlDb.CURRENT_NAME + "/part-r-00000/data");

  System.out.println("reading:" + dbfile);

  Option rFile=SequenceFile.Reader.file(dbfile);

  @SuppressWarnings("resource") SequenceFile.Reader reader=new SequenceFile.Reader(conf,rFile);

  ArrayList<String> read=new ArrayList<String>();

  READ:   do {

    Text key=new Text();

    CrawlDatum value=new CrawlDatum();

    if (!reader.next(key,value))     break READ;

    read.add(key.toString());

  }

 while (true);

  return read;

}

Location: TestInjector.java

Content: 

private HashMap<String,CrawlDatum> readCrawldbRecords() throws IOException {

  Path dbfile=new Path(crawldbPath,CrawlDb.CURRENT_NAME + "/part-r-00000/data");

  System.out.println("reading:" + dbfile);

  Option rFile=SequenceFile.Reader.file(dbfile);

  @SuppressWarnings("resource") SequenceFile.Reader reader=new SequenceFile.Reader(conf,rFile);

  HashMap<String,CrawlDatum> read=new HashMap<String,CrawlDatum>();

  READ:   do {

    Text key=new Text();

    CrawlDatum value=new CrawlDatum();

    if (!reader.next(key,value))     break READ;

    read.put(key.toString(),value);

  }

 while (true);

  return read;

}

Location: TestInjector.java

Content: 

@Test public void testInject() throws IOException, ClassNotFoundException, InterruptedException {

  ArrayList<String> urls=new ArrayList<String>();

  ArrayList<String> metadata=new ArrayList<String>();

  for (int i=0; i < 100; i++) {

    urls.add("http://zzz.com/" + i + ".html");

    metadata.add("\tnutch.score=2." + i + "\tnutch.fetchInterval=171717\tkey=value");

  }

  CrawlDBTestUtil.generateSeedList(fs,urlPath,urls,metadata);

  Injector injector=new Injector(conf);

  injector.inject(crawldbPath,urlPath);

  List<String> read=readCrawldb();

  Collections.sort(read);

  Collections.sort(urls);

  Assert.assertEquals(urls.size(),read.size());

  Assert.assertTrue(read.containsAll(urls));

  Assert.assertTrue(urls.containsAll(read));

  ArrayList<String> urls2=new ArrayList<String>();

  for (int i=0; i < 100; i++) {

    urls2.add("http://xxx.com/" + i + ".html");

    urls2.add("http://zzz.com/" + i + ".html");

  }

  CrawlDBTestUtil.generateSeedList(fs,urlPath,urls2);

  injector=new Injector(conf);

  conf.setBoolean("db.injector.update",true);

  injector.inject(crawldbPath,urlPath);

  urls.addAll(urls2);

  read=readCrawldb();

  Collections.sort(read);

  Collections.sort(urls);

  Assert.assertEquals(urls.size() - 100,read.size());

  Assert.assertTrue(read.containsAll(urls));

  Assert.assertTrue(urls.containsAll(read));

  Map<String,CrawlDatum> records=readCrawldbRecords();

  Text writableKey=new Text("key");

  Text writableValue=new Text("value");

  for (  String url : urls) {

    if (url.indexOf("http://zzz") == 0) {

      Assert.assertTrue(records.get(url).getFetchInterval() == 171717);

      Assert.assertTrue(records.get(url).getScore() != 1.0);

      Assert.assertEquals(writableValue,records.get(url).getMetaData().get(writableKey));

    }

  }

}

