Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 * Checks the merged segment and removes the stuff again.

 * @param the test directory

 * @param the merged segment

 * @return the final status

 */

protected byte checkMergedSegment(Path testDir,Path mergedSegment) throws Exception {

  MapFile.Reader[] readers=MapFileOutputFormat.getReaders(new Path(mergedSegment,CrawlDatum.FETCH_DIR_NAME),conf);

  Text key=new Text();

  CrawlDatum value=new CrawlDatum();

  byte finalStatus=0x0;

  for (  MapFile.Reader reader : readers) {

    while (reader.next(key,value)) {

      LOG.info("Reading status for: " + key.toString() + " > "+ CrawlDatum.getStatusName(value.getStatus()));

      if (CrawlDatum.hasFetchStatus(value) && key.toString().equals("http://nutch.apache.org/")) {

        finalStatus=value.getStatus();

      }

    }

    reader.close();

  }

  fs.delete(testDir,true);

  LOG.info("Final fetch status for: http://nutch.apache.org/ > " + CrawlDatum.getStatusName(finalStatus));

  return finalStatus;

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 * Create a segment with the specified status.

 * @param the segment's paths

 * @param the status of the record, ignored if redirect is true

 * @param whether we're doing a redirect as well

 */

protected void createSegment(Path segment,byte status,boolean redirect) throws Exception {

  if (redirect) {

    createSegment(segment,status,false,true);

  }

 else {

    createSegment(segment,status,true,false);

  }

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

protected void createSegment(Path segment,byte status,boolean fetch,boolean redirect) throws Exception {

  LOG.info("\nSegment: " + segment.toString());

  String url="http://nutch.apache.org/";

  String redirectUrl="http://nutch.apache.org/i_redirect_to_the_root/";

  CrawlDatum value=new CrawlDatum();

  Path crawlFetchPath=new Path(new Path(segment,CrawlDatum.FETCH_DIR_NAME),"part-00000");

  Option wKeyOpt=MapFile.Writer.keyClass(Text.class);

  org.apache.hadoop.io.SequenceFile.Writer.Option wValueOpt=SequenceFile.Writer.valueClass(CrawlDatum.class);

  MapFile.Writer writer=new MapFile.Writer(conf,crawlFetchPath,wKeyOpt,wValueOpt);

  if (redirect) {

    LOG.info(url + " > " + CrawlDatum.getStatusName(CrawlDatum.STATUS_LINKED));

    value=new CrawlDatum();

    value.setStatus(CrawlDatum.STATUS_LINKED);

    writer.append(new Text(url),value);

  }

  if (fetch) {

    LOG.info(url + " > " + CrawlDatum.getStatusName(status));

    value.setStatus(status);

    writer.append(new Text(url),value);

  }

  if (redirect) {

    LOG.info(redirectUrl + " > " + CrawlDatum.getStatusName(CrawlDatum.STATUS_FETCH_REDIR_TEMP));

    value.setStatus(CrawlDatum.STATUS_FETCH_REDIR_TEMP);

    writer.append(new Text(redirectUrl),value);

  }

  writer.close();

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 * Execute a sequence of creating segments, merging them and checking the final output

 * @param status to start with

 * @param status to end with

 * @param number of rounds

 * @param whether redirects are injected randomly

 * @return the CrawlDatum status

 */

protected byte executeSequence(byte firstStatus,byte lastStatus,int rounds,boolean redirect) throws Exception {

  Path testDir=new Path(conf.get("hadoop.tmp.dir"),"merge-" + System.currentTimeMillis());

  DecimalFormat df=new DecimalFormat("0000000");

  Path[] segmentPaths=new Path[rounds];

  for (int i=0; i < rounds; i++) {

    String segmentName=df.format(i);

    segmentPaths[i]=new Path(testDir,segmentName);

  }

  createSegment(segmentPaths[0],firstStatus,false);

  for (int i=1; i < rounds - 1; i++) {

    byte status=(byte)(rnd.nextInt(6) + 0x21);

    boolean addRedirect=redirect ? rnd.nextBoolean() : false;

    boolean addFetch=addRedirect ? rnd.nextBoolean() : true;

    createSegment(segmentPaths[i],status,addFetch,addRedirect);

  }

  createSegment(segmentPaths[rounds - 1],lastStatus,true,redirect ? rnd.nextBoolean() : false);

  Path mergedSegment=merge(testDir,segmentPaths);

  return checkMergedSegment(testDir,mergedSegment);

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 * Merge some segments!

 * @param the test directory

 * @param the segments to merge

 * @return Path to the merged segment

 */

protected Path merge(Path testDir,Path[] segments) throws Exception {

  Path out=new Path(testDir,"out");

  SegmentMerger merger=new SegmentMerger(conf);

  merger.merge(out,segments,false,false,-1);

  FileStatus[] stats=fs.listStatus(out);

  Assert.assertEquals(1,stats.length);

  return stats[0].getPath();

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 * Check a fixed sequence!

 */

@Test public void testEndsWithRedirect() throws Exception {

  Path testDir=new Path(conf.get("hadoop.tmp.dir"),"merge-" + System.currentTimeMillis());

  Path segment1=new Path(testDir,"00001");

  Path segment2=new Path(testDir,"00002");

  createSegment(segment1,CrawlDatum.STATUS_FETCH_SUCCESS,false);

  createSegment(segment2,CrawlDatum.STATUS_FETCH_SUCCESS,true);

  Path mergedSegment=merge(testDir,new Path[]{segment1,segment2});

  Byte status=Byte.valueOf(status=checkMergedSegment(testDir,mergedSegment));

  Assert.assertEquals(Byte.valueOf(CrawlDatum.STATUS_FETCH_SUCCESS),status);

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 * Check a fixed sequence!

 */

@Test public void testFixedSequence() throws Exception {

  Path testDir=new Path(conf.get("hadoop.tmp.dir"),"merge-" + System.currentTimeMillis());

  Path segment1=new Path(testDir,"00001");

  Path segment2=new Path(testDir,"00002");

  Path segment3=new Path(testDir,"00003");

  createSegment(segment1,CrawlDatum.STATUS_FETCH_GONE,false);

  createSegment(segment2,CrawlDatum.STATUS_FETCH_GONE,true);

  createSegment(segment3,CrawlDatum.STATUS_FETCH_SUCCESS,false);

  Path mergedSegment=merge(testDir,new Path[]{segment1,segment2,segment3});

  Byte status=Byte.valueOf(status=checkMergedSegment(testDir,mergedSegment));

  Assert.assertEquals(Byte.valueOf(CrawlDatum.STATUS_FETCH_SUCCESS),status);

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 */

@Test public void testMostlyRedirects() throws Exception {

  Path testDir=new Path(conf.get("hadoop.tmp.dir"),"merge-" + System.currentTimeMillis());

  Path segment1=new Path(testDir,"20140110114943");

  Path segment2=new Path(testDir,"20140110114832");

  Path segment3=new Path(testDir,"20140110114558");

  Path segment4=new Path(testDir,"20140110114930");

  Path segment5=new Path(testDir,"20140110114545");

  Path segment6=new Path(testDir,"20140110114507");

  Path segment7=new Path(testDir,"20140110114903");

  Path segment8=new Path(testDir,"20140110114724");

  createSegment(segment1,CrawlDatum.STATUS_FETCH_SUCCESS,true);

  createSegment(segment2,CrawlDatum.STATUS_FETCH_SUCCESS,true);

  createSegment(segment3,CrawlDatum.STATUS_FETCH_SUCCESS,true);

  createSegment(segment4,CrawlDatum.STATUS_FETCH_SUCCESS,true);

  createSegment(segment5,CrawlDatum.STATUS_FETCH_SUCCESS,true);

  createSegment(segment6,CrawlDatum.STATUS_FETCH_SUCCESS,false);

  createSegment(segment7,CrawlDatum.STATUS_FETCH_SUCCESS,true);

  createSegment(segment8,CrawlDatum.STATUS_FETCH_SUCCESS,true);

  Path mergedSegment=merge(testDir,new Path[]{segment1,segment2,segment3,segment4,segment5,segment6,segment7,segment8});

  Byte status=Byte.valueOf(status=checkMergedSegment(testDir,mergedSegment));

  Assert.assertEquals(Byte.valueOf(CrawlDatum.STATUS_FETCH_SUCCESS),status);

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 */

@Test public void testRandomizedSequences() throws Exception {

  for (int i=0; i < rnd.nextInt(16) + 16; i++) {

    byte expectedStatus=(byte)(rnd.nextInt(6) + 0x21);

    while (expectedStatus == CrawlDatum.STATUS_FETCH_RETRY || expectedStatus == CrawlDatum.STATUS_FETCH_NOTMODIFIED) {

      expectedStatus=(byte)(rnd.nextInt(6) + 0x21);

    }

    byte randomStatus=(byte)(rnd.nextInt(6) + 0x21);

    int rounds=rnd.nextInt(16) + 32;

    boolean withRedirects=rnd.nextBoolean();

    byte resultStatus=executeSequence(randomStatus,expectedStatus,rounds,withRedirects);

    Assert.assertEquals("Expected status = " + CrawlDatum.getStatusName(expectedStatus) + ", but got "+ CrawlDatum.getStatusName(resultStatus)+ " when merging "+ rounds+ " segments"+ (withRedirects ? " with redirects" : ""),expectedStatus,resultStatus);

  }

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 */

@Test public void testRandomTestSequenceWithRedirects() throws Exception {

  Assert.assertEquals(Byte.valueOf(CrawlDatum.STATUS_FETCH_SUCCESS),Byte.valueOf(executeSequence(CrawlDatum.STATUS_FETCH_GONE,CrawlDatum.STATUS_FETCH_SUCCESS,128,true)));

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 * Check a fixed sequence!

 */

@Test public void testRedirFetchInOneSegment() throws Exception {

  Path testDir=new Path(conf.get("hadoop.tmp.dir"),"merge-" + System.currentTimeMillis());

  Path segment=new Path(testDir,"00001");

  createSegment(segment,CrawlDatum.STATUS_FETCH_SUCCESS,true,true);

  Path mergedSegment=merge(testDir,new Path[]{segment});

  Byte status=Byte.valueOf(status=checkMergedSegment(testDir,mergedSegment));

  Assert.assertEquals(Byte.valueOf(CrawlDatum.STATUS_FETCH_SUCCESS),status);

}

Location: TestSegmentMergerCrawlDatums.java

Content: 

/** 

 */

@Test public void testSingleRandomSequence() throws Exception {

  Assert.assertEquals(Byte.valueOf(CrawlDatum.STATUS_FETCH_SUCCESS),Byte.valueOf(executeSequence(CrawlDatum.STATUS_FETCH_GONE,CrawlDatum.STATUS_FETCH_SUCCESS,256,false)));

}

