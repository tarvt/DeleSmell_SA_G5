Location: AtomicBTreePartition.java

Content: 

private long[] addAllWithSizeDeltaInternal(RowUpdater updater,PartitionUpdate update,UpdateTransaction indexer){

  Holder current=ref;

  updater.ref=current;

  updater.reset();

  if (!update.deletionInfo().getPartitionDeletion().isLive())   indexer.onPartitionDeletion(update.deletionInfo().getPartitionDeletion());

  if (update.deletionInfo().hasRanges())   update.deletionInfo().rangeIterator(false).forEachRemaining(indexer::onRangeTombstone);

  DeletionInfo deletionInfo;

  if (update.deletionInfo().mayModify(current.deletionInfo)) {

    if (updater.inputDeletionInfoCopy == null)     updater.inputDeletionInfoCopy=update.deletionInfo().copy(HeapAllocator.instance);

    deletionInfo=current.deletionInfo.mutableCopy().add(updater.inputDeletionInfoCopy);

    updater.allocated(deletionInfo.unsharedHeapSize() - current.deletionInfo.unsharedHeapSize());

  }

 else {

    deletionInfo=current.deletionInfo;

  }

  RegularAndStaticColumns columns=update.columns().mergeTo(current.columns);

  Row newStatic=update.staticRow();

  Row staticRow=newStatic.isEmpty() ? current.staticRow : (current.staticRow.isEmpty() ? updater.apply(newStatic) : updater.apply(current.staticRow,newStatic));

  Object[] tree=BTree.update(current.tree,update.metadata().comparator,update,update.rowCount(),updater);

  EncodingStats newStats=current.stats.mergeWith(update.stats());

  if (tree != null && refUpdater.compareAndSet(this,current,new Holder(columns,tree,deletionInfo,staticRow,newStats))) {

    updater.finish();

    return new long[]{updater.dataSize,updater.colUpdateTimeDelta};

  }

 else {

    return null;

  }

}

Location: AtomicBTreePartition.java

Content: 

/** 

 * Adds a given update to this in-memtable partition.

 * @return an array containing first the difference in size seen after merging the updates, and second the minimumtime detla between updates.

 */

public long[] addAllWithSizeDelta(final PartitionUpdate update,OpOrder.Group writeOp,UpdateTransaction indexer){

  RowUpdater updater=new RowUpdater(this,allocator,writeOp,indexer);

  try {

    boolean shouldLock=shouldLock(writeOp);

    indexer.start();

    while (true) {

      if (shouldLock) {

synchronized (this) {

          long[] result=addAllWithSizeDeltaInternal(updater,update,indexer);

          if (result != null)           return result;

        }

      }

 else {

        long[] result=addAllWithSizeDeltaInternal(updater,update,indexer);

        if (result != null)         return result;

        shouldLock=shouldLock(updater.heapSize,writeOp);

      }

    }

  }

  finally {

    indexer.commit();

  }

}

Location: AtomicBTreePartition.java

Content: 

public AtomicBTreePartition(TableMetadataRef metadata,DecoratedKey partitionKey,MemtableAllocator allocator){

  super(partitionKey);

  this.metadata=metadata;

  this.allocator=allocator;

  this.ref=EMPTY;

}

Location: AtomicBTreePartition.java

Content: 

private static int avoidReservedValues(int wasteTracker){

  if (wasteTracker == TRACKER_NEVER_WASTED || wasteTracker == TRACKER_PESSIMISTIC_LOCKING)   return wasteTracker + 1;

  return wasteTracker;

}

Location: AtomicBTreePartition.java

Content: 

@Override public Row getRow(Clustering<?> clustering){

  return allocator.ensureOnHeap().applyToRow(super.getRow(clustering));

}

Location: AtomicBTreePartition.java

Content: 

private boolean lockIfOldest(OpOrder.Group writeOp){

  if (!writeOp.isOldestLiveGroup()) {

    Thread.yield();

    if (!writeOp.isOldestLiveGroup())     return false;

  }

  return true;

}

Location: AtomicBTreePartition.java

Content: 

private boolean shouldLock(long addWaste,OpOrder.Group writeOp){

  if (!updateWastedAllocationTracker(addWaste))   return false;

  return lockIfOldest(writeOp);

}

Location: AtomicBTreePartition.java

Content: 

private boolean shouldLock(OpOrder.Group writeOp){

  if (!useLock())   return false;

  return lockIfOldest(writeOp);

}

Location: AtomicBTreePartition.java

Content: 

@Override public UnfilteredRowIterator unfilteredIterator(){

  return allocator.ensureOnHeap().applyToPartition(super.unfilteredIterator());

}

Location: AtomicBTreePartition.java

Content: 

@Override public UnfilteredRowIterator unfilteredIterator(ColumnFilter selection,NavigableSet<Clustering<?>> clusteringsInQueryOrder,boolean reversed){

  return allocator.ensureOnHeap().applyToPartition(super.unfilteredIterator(selection,clusteringsInQueryOrder,reversed));

}

Location: AtomicBTreePartition.java

Content: 

@Override public UnfilteredRowIterator unfilteredIterator(ColumnFilter selection,Slices slices,boolean reversed){

  return allocator.ensureOnHeap().applyToPartition(super.unfilteredIterator(selection,slices,reversed));

}

Location: AtomicBTreePartition.java

Content: 

@Override public UnfilteredRowIterator unfilteredIterator(Holder current,ColumnFilter selection,Slices slices,boolean reversed){

  return allocator.ensureOnHeap().applyToPartition(super.unfilteredIterator(current,selection,slices,reversed));

}

Location: AtomicBTreePartition.java

Content: 

/** 

 * Update the wasted allocation tracker state based on newly wasted allocation information

 * @param wastedBytes the number of bytes wasted by this thread

 * @return true if the caller should now proceed with pessimistic locking because the waste limit has been reached

 */

private boolean updateWastedAllocationTracker(long wastedBytes){

  if (wastedBytes < EXCESS_WASTE_BYTES) {

    int wastedAllocation=((int)(wastedBytes + ALLOCATION_GRANULARITY_BYTES - 1)) / ALLOCATION_GRANULARITY_BYTES;

    int oldTrackerValue;

    while (TRACKER_PESSIMISTIC_LOCKING != (oldTrackerValue=wasteTracker)) {

      int time=(int)(System.nanoTime() >>> CLOCK_SHIFT);

      int delta=oldTrackerValue - time;

      if (oldTrackerValue == TRACKER_NEVER_WASTED || delta >= 0 || delta < -EXCESS_WASTE_OFFSET)       delta=-EXCESS_WASTE_OFFSET;

      delta+=wastedAllocation;

      if (delta >= 0)       break;

      if (wasteTrackerUpdater.compareAndSet(this,oldTrackerValue,avoidReservedValues(time + delta)))       return false;

    }

  }

  wasteTrackerUpdater.set(this,TRACKER_PESSIMISTIC_LOCKING);

  return true;

}

Location: AtomicBTreePartition.java

Content: 

public boolean useLock(){

  return wasteTracker == TRACKER_PESSIMISTIC_LOCKING;

}

